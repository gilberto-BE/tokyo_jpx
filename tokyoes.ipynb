{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2a4ce10c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T11:03:13.472188Z",
     "iopub.status.busy": "2022-07-02T11:03:13.471835Z",
     "iopub.status.idle": "2022-07-02T11:03:23.49579Z",
     "shell.execute_reply": "2022-07-02T11:03:23.495051Z",
     "shell.execute_reply.started": "2022-07-02T11:03:13.47213Z"
    },
    "papermill": {
     "duration": 0.024651,
     "end_time": "2022-07-04T10:58:24.220809",
     "exception": false,
     "start_time": "2022-07-04T10:58:24.196158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "!pip install tokyo-jpx --upgrade #--find-links=file:///kaggle/input/tokyo-jpx/tokyo-jpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95208f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T10:58:24.272488Z",
     "iopub.status.busy": "2022-07-04T10:58:24.271311Z",
     "iopub.status.idle": "2022-07-04T10:58:25.050387Z",
     "shell.execute_reply": "2022-07-04T10:58:25.051002Z",
     "shell.execute_reply.started": "2022-07-04T10:39:20.697602Z"
    },
    "papermill": {
     "duration": 0.806757,
     "end_time": "2022-07-04T10:58:25.051325",
     "exception": false,
     "start_time": "2022-07-04T10:58:24.244568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo_jpx-0.0.28-py3-none-any.whl\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../input/tokyo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53bf7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T10:58:25.103904Z",
     "iopub.status.busy": "2022-07-04T10:58:25.102826Z",
     "iopub.status.idle": "2022-07-04T10:58:25.131668Z",
     "shell.execute_reply": "2022-07-04T10:58:25.132263Z",
     "shell.execute_reply.started": "2022-07-04T10:39:21.520273Z"
    },
    "papermill": {
     "duration": 0.057028,
     "end_time": "2022-07-04T10:58:25.132454",
     "exception": false,
     "start_time": "2022-07-04T10:58:25.075426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jpx_tokyo_market_prediction\n",
    "env = jpx_tokyo_market_prediction.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a934fe74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T10:58:25.185807Z",
     "iopub.status.busy": "2022-07-04T10:58:25.185108Z",
     "iopub.status.idle": "2022-07-04T10:58:25.932693Z",
     "shell.execute_reply": "2022-07-04T10:58:25.931968Z",
     "shell.execute_reply.started": "2022-07-04T10:39:21.53476Z"
    },
    "papermill": {
     "duration": 0.776282,
     "end_time": "2022-07-04T10:58:25.932841",
     "exception": false,
     "start_time": "2022-07-04T10:58:25.156559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo_jpx-0.0.28-py3-none-any.whl\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! ls ../input/tokyo4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7926ecc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T10:58:25.994418Z",
     "iopub.status.busy": "2022-07-04T10:58:25.988085Z",
     "iopub.status.idle": "2022-07-04T10:58:36.355094Z",
     "shell.execute_reply": "2022-07-04T10:58:36.354239Z",
     "shell.execute_reply.started": "2022-07-04T10:39:22.316574Z"
    },
    "papermill": {
     "duration": 10.397783,
     "end_time": "2022-07-04T10:58:36.355259",
     "exception": false,
     "start_time": "2022-07-04T10:58:25.957476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/tokyo4/\r\n",
      "Processing /kaggle/input/tokyo4/tokyo_jpx-0.0.28-py3-none-any.whl\r\n",
      "Installing collected packages: tokyo-jpx\r\n",
      "Successfully installed tokyo-jpx-0.0.28\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tokyo-jpx --upgrade --no-index --find-links=file:///kaggle/input/tokyo4/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938b172a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T10:58:36.417427Z",
     "iopub.status.busy": "2022-07-04T10:58:36.416695Z",
     "iopub.status.idle": "2022-07-04T10:58:40.225739Z",
     "shell.execute_reply": "2022-07-04T10:58:40.226306Z",
     "shell.execute_reply.started": "2022-07-04T10:39:31.945699Z"
    },
    "papermill": {
     "duration": 3.845177,
     "end_time": "2022-07-04T10:58:40.226482",
     "exception": false,
     "start_time": "2022-07-04T10:58:36.381305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "# pl.utilities.seed.seed_everything(seed=42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from preprocessing.preprocess import (\n",
    "    show_df, \n",
    "    date_features, \n",
    "    preprocess, \n",
    "    ToTorch, \n",
    "    get_loader, \n",
    "    ts_split,\n",
    "    cont_cat_split,\n",
    "    dataloader_by_stock,\n",
    "    get_data\n",
    ") \n",
    "from models.dl import NeuralNetwork\n",
    "from train.trainer import Trainer, plot_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "\n",
    "from preprocessing.preprocess import (\n",
    "    show_df, \n",
    "    date_features, \n",
    "    preprocess, \n",
    "    ToTorch, \n",
    "    get_loader, \n",
    "    get_predict_loader,\n",
    "    ts_split,\n",
    "    cont_cat_split,\n",
    "    dataloader_by_stock,\n",
    "    get_data,\n",
    "    dataloader_test_by_stock\n",
    ")\n",
    "from metrics.metrics import calc_spread_return_sharpe\n",
    "from predictions.predict import run_pred_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c609a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T10:58:40.280940Z",
     "iopub.status.busy": "2022-07-04T10:58:40.280096Z",
     "iopub.status.idle": "2022-07-04T10:59:09.066290Z",
     "shell.execute_reply": "2022-07-04T10:59:09.066885Z",
     "shell.execute_reply.started": "2022-07-04T10:39:33.64127Z"
    },
    "papermill": {
     "duration": 28.815196,
     "end_time": "2022-07-04T10:59:09.067078",
     "exception": false,
     "start_time": "2022-07-04T10:58:40.251882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.head(10):\n",
      "            Section/Products  33SectorName  17SectorName  Universe0  \\\n",
      "Date                                                                  \n",
      "2017-01-04                 0             6             8          0   \n",
      "2017-01-05                 0             6             8          0   \n",
      "2017-01-06                 0             6             8          0   \n",
      "2017-01-10                 0             6             8          0   \n",
      "2017-01-11                 0             6             8          0   \n",
      "2017-01-12                 0             6             8          0   \n",
      "2017-01-13                 0             6             8          0   \n",
      "2017-01-16                 0             6             8          0   \n",
      "2017-01-17                 0             6             8          0   \n",
      "2017-01-18                 0             6             8          0   \n",
      "\n",
      "            MarketCapitalization  SecuritiesCode          RowId    Open  \\\n",
      "Date                                                                      \n",
      "2017-01-04          3.365911e+10            1301  20170104_1301  2734.0   \n",
      "2017-01-05          3.365911e+10            1301  20170105_1301  2743.0   \n",
      "2017-01-06          3.365911e+10            1301  20170106_1301  2734.0   \n",
      "2017-01-10          3.365911e+10            1301  20170110_1301  2745.0   \n",
      "2017-01-11          3.365911e+10            1301  20170111_1301  2748.0   \n",
      "2017-01-12          3.365911e+10            1301  20170112_1301  2745.0   \n",
      "2017-01-13          3.365911e+10            1301  20170113_1301  2707.0   \n",
      "2017-01-16          3.365911e+10            1301  20170116_1301  2725.0   \n",
      "2017-01-17          3.365911e+10            1301  20170117_1301  2702.0   \n",
      "2017-01-18          3.365911e+10            1301  20170118_1301  2689.0   \n",
      "\n",
      "              High     Low   Close  Volume  AdjustmentFactor  \\\n",
      "Date                                                           \n",
      "2017-01-04  2755.0  2730.0  2742.0   31400               1.0   \n",
      "2017-01-05  2747.0  2735.0  2738.0   17900               1.0   \n",
      "2017-01-06  2744.0  2720.0  2740.0   19900               1.0   \n",
      "2017-01-10  2754.0  2735.0  2748.0   24200               1.0   \n",
      "2017-01-11  2752.0  2737.0  2745.0    9300               1.0   \n",
      "2017-01-12  2747.0  2703.0  2731.0   28700               1.0   \n",
      "2017-01-13  2730.0  2707.0  2722.0   19400               1.0   \n",
      "2017-01-16  2725.0  2696.0  2704.0   20100               1.0   \n",
      "2017-01-17  2704.0  2682.0  2686.0   18400               1.0   \n",
      "2017-01-18  2695.0  2681.0  2694.0   12100               1.0   \n",
      "\n",
      "            ExpectedDividend  SupervisionFlag    Target  \n",
      "Date                                                     \n",
      "2017-01-04               NaN            False  0.000730  \n",
      "2017-01-05               NaN            False  0.002920  \n",
      "2017-01-06               NaN            False -0.001092  \n",
      "2017-01-10               NaN            False -0.005100  \n",
      "2017-01-11               NaN            False -0.003295  \n",
      "2017-01-12               NaN            False -0.006613  \n",
      "2017-01-13               NaN            False -0.006657  \n",
      "2017-01-16               NaN            False  0.002978  \n",
      "2017-01-17               NaN            False  0.001856  \n",
      "2017-01-18               NaN            False  0.014079  \n",
      "CAT_FEATURES: 7\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = \"/kaggle/input/jpx-tokyo-stock-exchange-prediction/\"\n",
    "FOLDER = \"train_files\"\n",
    "train_df = get_data(folder=FOLDER, root_path=ROOT_PATH)\n",
    "UNITS = 256\n",
    "BLOCKS = 8\n",
    "STACKS = 4\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "weight_decay = 0.1\n",
    "EPOCHS = 1\n",
    "\n",
    "\"\"\"\n",
    "SUBTRACT:\n",
    "*) 3 FROM CONTINUOUS COLS BECAUSE OF POOLING\n",
    "*) 1 FROM CAT_FEATURES TO MAKE MATRICES MATCH AFTER TORCH.CAT\n",
    "\"\"\"\n",
    "CONT_COLS=['Close', 'Open', 'High', 'Low', 'MarketCapitalization',         \n",
    "           # 'NetSales', 'EquityToAssetRatio', 'TotalAssets', 'Profit', \n",
    "           # 'OperatingProfit', 'EarningsPerShare', 'Equity', \n",
    "           # 'BookValuePerShare', 'ResultDividendPerShare1stQuarter', \n",
    "           # 'ResultDividendPerShare2ndQuarter', 'ResultDividendPerShare3rdQuarter',\n",
    "           # 'ResultDividendPerShareFiscalYearEnd', 'ResultDividendPerShareAnnual'\n",
    "          ]\n",
    "TS_IN_FEATURES = len(CONT_COLS)\n",
    "CAT_FEATURES = 4 + 4 - 1 # TEXT_COLS = ['Section/Products', '33SectorName', '17SectorName', 'Universe0']\n",
    "print('CAT_FEATURES:', CAT_FEATURES)\n",
    "EMBEDDING_DIM = 300\n",
    "NO_EMBEDDING = 2000 #2 * len(df_train_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d5d27",
   "metadata": {
    "papermill": {
     "duration": 0.027452,
     "end_time": "2022-07-04T10:59:09.121137",
     "exception": false,
     "start_time": "2022-07-04T10:59:09.093685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2918ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T10:59:09.181217Z",
     "iopub.status.busy": "2022-07-04T10:59:09.180444Z",
     "iopub.status.idle": "2022-07-04T10:59:09.182629Z",
     "shell.execute_reply": "2022-07-04T10:59:09.183102Z",
     "shell.execute_reply.started": "2022-07-04T10:40:02.619039Z"
    },
    "papermill": {
     "duration": 0.035688,
     "end_time": "2022-07-04T10:59:09.183341",
     "exception": false,
     "start_time": "2022-07-04T10:59:09.147653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create model\n",
    "def create_model():\n",
    "    model = None\n",
    "    model = NeuralNetwork(\n",
    "        in_features=TS_IN_FEATURES - 3, \n",
    "        units=UNITS,\n",
    "        out_features=1, \n",
    "        categorical_dim=CAT_FEATURES,\n",
    "        no_embedding=NO_EMBEDDING, \n",
    "        emb_dim=EMBEDDING_DIM,\n",
    "        n_blocks=BLOCKS,\n",
    "        n_stacks=STACKS,\n",
    "        dropout=0.1,\n",
    "        pooling_sizes=3\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84910fc2",
   "metadata": {
    "papermill": {
     "duration": 0.026508,
     "end_time": "2022-07-04T10:59:09.240248",
     "exception": false,
     "start_time": "2022-07-04T10:59:09.213740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train a random choice of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfb5150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T10:59:09.306061Z",
     "iopub.status.busy": "2022-07-04T10:59:09.304991Z",
     "iopub.status.idle": "2022-07-04T15:53:34.274341Z",
     "shell.execute_reply": "2022-07-04T15:53:34.275495Z",
     "shell.execute_reply.started": "2022-07-04T10:40:02.626581Z"
    },
    "papermill": {
     "duration": 17665.008309,
     "end_time": "2022-07-04T15:53:34.275761",
     "exception": false,
     "start_time": "2022-07-04T10:59:09.267452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu-device\n",
      "[3457 6779 6586 ... 8355 4100 4550]\n",
      "Stock-iteratation: 0\n",
      "Start training for stock: 3457\n",
      "\n",
      "                    Average train loss: 0.09603780746459961 | \n",
      "                    Train-Mae: 0.1952623426914215 |\n",
      "\n",
      "                    Average val loss: 0.019600143656134605|\n",
      "                    Val-Mae: 0.0976792722940445\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1\n",
      "Start training for stock: 6779\n",
      "\n",
      "                    Average train loss: 0.009846925735473633 | \n",
      "                    Train-Mae: 0.08867450803518295 |\n",
      "\n",
      "                    Average val loss: 0.013137013651430607|\n",
      "                    Val-Mae: 0.07061263173818588\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 2\n",
      "Start training for stock: 6586\n",
      "\n",
      "                    Average train loss: 0.0004234632849693298 | \n",
      "                    Train-Mae: 0.0836116224527359 |\n",
      "\n",
      "                    Average val loss: 0.475541353225708|\n",
      "                    Val-Mae: 0.10979721695184708\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 3\n",
      "Start training for stock: 4676\n",
      "\n",
      "                    Average train loss: 0.00021472662687301635 | \n",
      "                    Train-Mae: 0.10565189272165298 |\n",
      "\n",
      "                    Average val loss: 0.009430266916751862|\n",
      "                    Val-Mae: 0.02045702561736107\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 4\n",
      "Start training for stock: 8909\n",
      "\n",
      "                    Average train loss: 0.0004089430347084999 | \n",
      "                    Train-Mae: 0.0378480963408947 |\n",
      "\n",
      "                    Average val loss: 0.0005713573191314936|\n",
      "                    Val-Mae: 0.019947919994592667\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 5\n",
      "Start training for stock: 6745\n",
      "\n",
      "                    Average train loss: 0.0005825736001133919 | \n",
      "                    Train-Mae: 0.0414111502468586 |\n",
      "\n",
      "                    Average val loss: 0.04703817889094353|\n",
      "                    Val-Mae: 0.04434845969080925\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 6\n",
      "Start training for stock: 8016\n",
      "\n",
      "                    Average train loss: 0.006727091073989868 | \n",
      "                    Train-Mae: 0.0749504417181015 |\n",
      "\n",
      "                    Average val loss: 0.3960675299167633|\n",
      "                    Val-Mae: 0.08533798903226852\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 7\n",
      "Start training for stock: 7181\n",
      "\n",
      "                    Average train loss: 0.027161774635314943 | \n",
      "                    Train-Mae: 0.039175767451524734 |\n",
      "\n",
      "                    Average val loss: 0.023830756545066833|\n",
      "                    Val-Mae: 0.027356501668691635\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 8\n",
      "Start training for stock: 9434\n",
      "\n",
      "                    Average train loss: 0.0042632856965065 | \n",
      "                    Train-Mae: 0.045373160392045975 |\n",
      "\n",
      "                    Average val loss: 0.5141909122467041|\n",
      "                    Val-Mae: 0.09716332703828812\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 9\n",
      "Start training for stock: 1605\n",
      "\n",
      "                    Average train loss: 0.03912500143051147 | \n",
      "                    Train-Mae: 0.08897116780281067 |\n",
      "\n",
      "                    Average val loss: 0.024036625400185585|\n",
      "                    Val-Mae: 0.03627460449934006\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 10\n",
      "Start training for stock: 6994\n",
      "\n",
      "                    Average train loss: 0.006782991886138916 | \n",
      "                    Train-Mae: 0.062244705855846405 |\n",
      "\n",
      "                    Average val loss: 0.0023239371366798878|\n",
      "                    Val-Mae: 0.026809724047780037\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 11\n",
      "Start training for stock: 8043\n",
      "\n",
      "                    Average train loss: 0.004804392158985138 | \n",
      "                    Train-Mae: 0.11114339530467987 |\n",
      "\n",
      "                    Average val loss: 0.39159026741981506|\n",
      "                    Val-Mae: 0.12404406815767288\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 12\n",
      "Start training for stock: 2742\n",
      "\n",
      "                    Average train loss: 0.017627100944519043 | \n",
      "                    Train-Mae: 0.11606530100107193 |\n",
      "\n",
      "                    Average val loss: 0.0029896656051278114|\n",
      "                    Val-Mae: 0.021031390875577927\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 13\n",
      "Start training for stock: 2432\n",
      "\n",
      "                    Average train loss: 0.0039265424013137816 | \n",
      "                    Train-Mae: 0.05253345146775246 |\n",
      "\n",
      "                    Average val loss: 0.019105954095721245|\n",
      "                    Val-Mae: 0.030440134927630424\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 14\n",
      "Start training for stock: 4641\n",
      "\n",
      "                    Average train loss: 0.0018658174574375153 | \n",
      "                    Train-Mae: 0.04090781509876251 |\n",
      "\n",
      "                    Average val loss: 0.01387342531234026|\n",
      "                    Val-Mae: 0.021922647953033447\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 15\n",
      "Start training for stock: 9612\n",
      "\n",
      "                    Average train loss: 0.00034498639404773713 | \n",
      "                    Train-Mae: 0.0383458249270916 |\n",
      "\n",
      "                    Average val loss: 0.09579277783632278|\n",
      "                    Val-Mae: 0.04067499563097954\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 16\n",
      "Start training for stock: 3677\n",
      "\n",
      "                    Average train loss: 0.004057269990444184 | \n",
      "                    Train-Mae: 0.08744153380393982 |\n",
      "\n",
      "                    Average val loss: 0.011569048278033733|\n",
      "                    Val-Mae: 0.024944275617599487\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 17\n",
      "Start training for stock: 9788\n",
      "\n",
      "                    Average train loss: 7.474996615201234e-05 | \n",
      "                    Train-Mae: 0.09818421304225922 |\n",
      "\n",
      "                    Average val loss: 0.5930006504058838|\n",
      "                    Val-Mae: 0.09037302434444427\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 18\n",
      "Start training for stock: 8050\n",
      "\n",
      "                    Average train loss: 0.010731672048568725 | \n",
      "                    Train-Mae: 0.04298220947384834 |\n",
      "\n",
      "                    Average val loss: 0.05298258364200592|\n",
      "                    Val-Mae: 0.038343288004398346\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 19\n",
      "Start training for stock: 6820\n",
      "\n",
      "                    Average train loss: 0.04380582332611084 | \n",
      "                    Train-Mae: 0.1102384701371193 |\n",
      "\n",
      "                    Average val loss: 0.023455588147044182|\n",
      "                    Val-Mae: 0.027237046509981155\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 20\n",
      "Start training for stock: 9631\n",
      "\n",
      "                    Average train loss: 0.0002436268702149391 | \n",
      "                    Train-Mae: 0.055634062737226486 |\n",
      "\n",
      "                    Average val loss: 0.020373502746224403|\n",
      "                    Val-Mae: 0.03140324354171753\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 21\n",
      "Start training for stock: 6914\n",
      "\n",
      "                    Average train loss: 0.011024211645126342 | \n",
      "                    Train-Mae: 0.03616426885128021 |\n",
      "\n",
      "                    Average val loss: 0.006448308937251568|\n",
      "                    Val-Mae: 0.029713965952396393\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 22\n",
      "Start training for stock: 4933\n",
      "\n",
      "                    Average train loss: 0.0026550403237342833 | \n",
      "                    Train-Mae: 0.07637850940227509 |\n",
      "\n",
      "                    Average val loss: 0.005442730616778135|\n",
      "                    Val-Mae: 0.03634960949420929\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 23\n",
      "Start training for stock: 8158\n",
      "\n",
      "                    Average train loss: 0.0019017599523067474 | \n",
      "                    Train-Mae: 0.03354579582810402 |\n",
      "\n",
      "                    Average val loss: 0.0006219192873686552|\n",
      "                    Val-Mae: 0.01637076586484909\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 24\n",
      "Start training for stock: 6463\n",
      "\n",
      "                    Average train loss: 0.00016735004261136054 | \n",
      "                    Train-Mae: 0.04168935492634773 |\n",
      "\n",
      "                    Average val loss: 0.011558540165424347|\n",
      "                    Val-Mae: 0.0227764081209898\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 25\n",
      "Start training for stock: 7327\n",
      "\n",
      "                    Average train loss: 0.00023408887907862662 | \n",
      "                    Train-Mae: 0.054727908223867416 |\n",
      "\n",
      "                    Average val loss: 0.0050282166339457035|\n",
      "                    Val-Mae: 0.023735836148262024\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 26\n",
      "Start training for stock: 3835\n",
      "\n",
      "                    Average train loss: 0.0017011524736881257 | \n",
      "                    Train-Mae: 0.07310212403535843 |\n",
      "\n",
      "                    Average val loss: 0.009839911013841629|\n",
      "                    Val-Mae: 0.03668581321835518\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 27\n",
      "Start training for stock: 6632\n",
      "\n",
      "                    Average train loss: 0.0010264151543378829 | \n",
      "                    Train-Mae: 0.038519587367773056 |\n",
      "\n",
      "                    Average val loss: 0.004282520618289709|\n",
      "                    Val-Mae: 0.029430123046040535\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 28\n",
      "Start training for stock: 3941\n",
      "\n",
      "                    Average train loss: 0.0002148812636733055 | \n",
      "                    Train-Mae: 0.05255360156297684 |\n",
      "\n",
      "                    Average val loss: 0.0009151956764981151|\n",
      "                    Val-Mae: 0.017697980627417564\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 29\n",
      "Start training for stock: 9733\n",
      "\n",
      "                    Average train loss: 0.009439944624900817 | \n",
      "                    Train-Mae: 0.15618380904197693 |\n",
      "\n",
      "                    Average val loss: 0.05813716724514961|\n",
      "                    Val-Mae: 0.11545643955469131\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 30\n",
      "Start training for stock: 6963\n",
      "\n",
      "                    Average train loss: 0.00032671988010406493 | \n",
      "                    Train-Mae: 0.09629106521606445 |\n",
      "\n",
      "                    Average val loss: 0.0019880840554833412|\n",
      "                    Val-Mae: 0.032778747379779816\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 31\n",
      "Start training for stock: 6486\n",
      "\n",
      "                    Average train loss: 4.0594725869596e-05 | \n",
      "                    Train-Mae: 0.08457760512828827 |\n",
      "\n",
      "                    Average val loss: 0.050519175827503204|\n",
      "                    Val-Mae: 0.053594935685396194\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 32\n",
      "Start training for stock: 9746\n",
      "\n",
      "                    Average train loss: 0.0012777353823184966 | \n",
      "                    Train-Mae: 0.10998484492301941 |\n",
      "\n",
      "                    Average val loss: 0.31314870715141296|\n",
      "                    Val-Mae: 0.10977520793676376\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 33\n",
      "Start training for stock: 8890\n",
      "\n",
      "                    Average train loss: 0.018048018217086792 | \n",
      "                    Train-Mae: 0.04762847721576691 |\n",
      "\n",
      "                    Average val loss: 0.020240673795342445|\n",
      "                    Val-Mae: 0.030054664239287376\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 34\n",
      "Start training for stock: 6371\n",
      "\n",
      "                    Average train loss: 0.0009219280630350113 | \n",
      "                    Train-Mae: 0.036143168807029724 |\n",
      "\n",
      "                    Average val loss: 0.009546665474772453|\n",
      "                    Val-Mae: 0.02516184374690056\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 35\n",
      "Start training for stock: 3569\n",
      "\n",
      "                    Average train loss: 0.0004850321263074875 | \n",
      "                    Train-Mae: 0.06082968786358833 |\n",
      "\n",
      "                    Average val loss: 0.2892700731754303|\n",
      "                    Val-Mae: 0.0647985115647316\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 36\n",
      "Start training for stock: 6287\n",
      "\n",
      "                    Average train loss: 0.000562279000878334 | \n",
      "                    Train-Mae: 0.058135077357292175 |\n",
      "\n",
      "                    Average val loss: 0.020356355234980583|\n",
      "                    Val-Mae: 0.02693198435008526\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 37\n",
      "Start training for stock: 2282\n",
      "\n",
      "                    Average train loss: 0.00011966772377490998 | \n",
      "                    Train-Mae: 0.055556975305080414 |\n",
      "\n",
      "                    Average val loss: 0.08716988563537598|\n",
      "                    Val-Mae: 0.044138211756944656\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 38\n",
      "Start training for stock: 3880\n",
      "\n",
      "                    Average train loss: 0.0015858639776706695 | \n",
      "                    Train-Mae: 0.09080509096384048 |\n",
      "\n",
      "                    Average val loss: 0.6405572891235352|\n",
      "                    Val-Mae: 0.08847783505916595\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 39\n",
      "Start training for stock: 6194\n",
      "\n",
      "                    Average train loss: 0.009792870283126831 | \n",
      "                    Train-Mae: 0.03818632662296295 |\n",
      "\n",
      "                    Average val loss: 0.014375779777765274|\n",
      "                    Val-Mae: 0.03835422545671463\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 40\n",
      "Start training for stock: 1726\n",
      "\n",
      "                    Average train loss: 0.0002699553407728672 | \n",
      "                    Train-Mae: 0.059480931609869 |\n",
      "\n",
      "                    Average val loss: 0.05347146466374397|\n",
      "                    Val-Mae: 0.033997587859630585\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 41\n",
      "Start training for stock: 7239\n",
      "\n",
      "                    Average train loss: 0.0030666589736938477 | \n",
      "                    Train-Mae: 0.05501939356327057 |\n",
      "\n",
      "                    Average val loss: 0.08846817165613174|\n",
      "                    Val-Mae: 0.04209495708346367\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 42\n",
      "Start training for stock: 6923\n",
      "\n",
      "                    Average train loss: 0.0018397291004657746 | \n",
      "                    Train-Mae: 0.07582946866750717 |\n",
      "\n",
      "                    Average val loss: 0.0424022413790226|\n",
      "                    Val-Mae: 0.030634943395853043\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 43\n",
      "Start training for stock: 1518\n",
      "\n",
      "                    Average train loss: 2.1721331868320704e-05 | \n",
      "                    Train-Mae: 0.0599813349545002 |\n",
      "\n",
      "                    Average val loss: 0.1403941959142685|\n",
      "                    Val-Mae: 0.05739183723926544\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 44\n",
      "Start training for stock: 8253\n",
      "\n",
      "                    Average train loss: 0.0018041585385799408 | \n",
      "                    Train-Mae: 0.05058704689145088 |\n",
      "\n",
      "                    Average val loss: 0.015066293999552727|\n",
      "                    Val-Mae: 0.027393609285354614\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 45\n",
      "Start training for stock: 3978\n",
      "\n",
      "                    Average train loss: 9.841984137892723e-05 | \n",
      "                    Train-Mae: 0.04967460036277771 |\n",
      "\n",
      "                    Average val loss: 0.005580574739724398|\n",
      "                    Val-Mae: 0.026701513677835464\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 46\n",
      "Start training for stock: 3222\n",
      "\n",
      "                    Average train loss: 0.0063599514961242675 | \n",
      "                    Train-Mae: 0.08442491292953491 |\n",
      "\n",
      "                    Average val loss: 0.8559122085571289|\n",
      "                    Val-Mae: 0.10165788978338242\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 47\n",
      "Start training for stock: 2915\n",
      "\n",
      "                    Average train loss: 0.03133810997009277 | \n",
      "                    Train-Mae: 0.06779041141271591 |\n",
      "\n",
      "                    Average val loss: 0.0004217581881675869|\n",
      "                    Val-Mae: 0.014657730236649513\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 48\n",
      "Start training for stock: 9048\n",
      "\n",
      "                    Average train loss: 0.006057372093200683 | \n",
      "                    Train-Mae: 0.04679400101304054 |\n",
      "\n",
      "                    Average val loss: 0.0007840669713914394|\n",
      "                    Val-Mae: 0.018277045339345932\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 49\n",
      "Start training for stock: 6592\n",
      "\n",
      "                    Average train loss: 0.015353044271469116 | \n",
      "                    Train-Mae: 0.07653681933879852 |\n",
      "\n",
      "                    Average val loss: 0.036087051033973694|\n",
      "                    Val-Mae: 0.03011435642838478\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 50\n",
      "Start training for stock: 8057\n",
      "\n",
      "                    Average train loss: 0.0006063215434551239 | \n",
      "                    Train-Mae: 0.06855764240026474 |\n",
      "\n",
      "                    Average val loss: 0.001483132946304977|\n",
      "                    Val-Mae: 0.02054256945848465\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 51\n",
      "Start training for stock: 7240\n",
      "\n",
      "                    Average train loss: 0.0167678701877594 | \n",
      "                    Train-Mae: 0.04828652739524841 |\n",
      "\n",
      "                    Average val loss: 0.16772808134555817|\n",
      "                    Val-Mae: 0.054301731288433075\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 52\n",
      "Start training for stock: 1934\n",
      "\n",
      "                    Average train loss: 0.014444078207015992 | \n",
      "                    Train-Mae: 0.03691030666232109 |\n",
      "\n",
      "                    Average val loss: 0.0299297533929348|\n",
      "                    Val-Mae: 0.027439352124929428\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 53\n",
      "Start training for stock: 4202\n",
      "\n",
      "                    Average train loss: 0.007844759821891785 | \n",
      "                    Train-Mae: 0.04796871542930603 |\n",
      "\n",
      "                    Average val loss: 0.0019921453204005957|\n",
      "                    Val-Mae: 0.01692761294543743\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 54\n",
      "Start training for stock: 2874\n",
      "\n",
      "                    Average train loss: 0.0013511449098587037 | \n",
      "                    Train-Mae: 0.027787618339061737 |\n",
      "\n",
      "                    Average val loss: 0.011905902996659279|\n",
      "                    Val-Mae: 0.020393526181578636\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 55\n",
      "Start training for stock: 5959\n",
      "\n",
      "                    Average train loss: 0.011915354728698731 | \n",
      "                    Train-Mae: 0.06861957162618637 |\n",
      "\n",
      "                    Average val loss: 0.037762079387903214|\n",
      "                    Val-Mae: 0.027818074449896812\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 56\n",
      "Start training for stock: 3800\n",
      "\n",
      "                    Average train loss: 0.00739987313747406 | \n",
      "                    Train-Mae: 0.12731368839740753 |\n",
      "\n",
      "                    Average val loss: 0.009835493750870228|\n",
      "                    Val-Mae: 0.018798062577843666\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 57\n",
      "Start training for stock: 9042\n",
      "\n",
      "                    Average train loss: 0.020343172550201415 | \n",
      "                    Train-Mae: 0.03376412391662598 |\n",
      "\n",
      "                    Average val loss: 0.12920673191547394|\n",
      "                    Val-Mae: 0.04484401270747185\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 58\n",
      "Start training for stock: 6282\n",
      "\n",
      "                    Average train loss: 3.311000531539321e-05 | \n",
      "                    Train-Mae: 0.037040457129478455 |\n",
      "\n",
      "                    Average val loss: 0.06700856983661652|\n",
      "                    Val-Mae: 0.03246140480041504\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 59\n",
      "Start training for stock: 8068\n",
      "\n",
      "                    Average train loss: 0.002343493700027466 | \n",
      "                    Train-Mae: 0.06431183218955994 |\n",
      "\n",
      "                    Average val loss: 0.00030473314109258354|\n",
      "                    Val-Mae: 0.01184269692748785\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 60\n",
      "Start training for stock: 5192\n",
      "\n",
      "                    Average train loss: 0.0074237996339797975 | \n",
      "                    Train-Mae: 0.04651281610131264 |\n",
      "\n",
      "                    Average val loss: 0.0036985022015869617|\n",
      "                    Val-Mae: 0.017575155943632126\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 61\n",
      "Start training for stock: 7989\n",
      "\n",
      "                    Average train loss: 0.002278890609741211 | \n",
      "                    Train-Mae: 0.03577597439289093 |\n",
      "\n",
      "                    Average val loss: 0.0029709767550230026|\n",
      "                    Val-Mae: 0.01935880444943905\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 62\n",
      "Start training for stock: 6501\n",
      "\n",
      "                    Average train loss: 0.00024009512737393379 | \n",
      "                    Train-Mae: 0.04858265444636345 |\n",
      "\n",
      "                    Average val loss: 0.02606578730046749|\n",
      "                    Val-Mae: 0.037818342447280884\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 63\n",
      "Start training for stock: 7421\n",
      "\n",
      "                    Average train loss: 0.0067599302530288695 | \n",
      "                    Train-Mae: 0.06216096132993698 |\n",
      "\n",
      "                    Average val loss: 0.010971193201839924|\n",
      "                    Val-Mae: 0.02400265820324421\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 64\n",
      "Start training for stock: 1821\n",
      "\n",
      "                    Average train loss: 0.0018899966776371002 | \n",
      "                    Train-Mae: 0.048803504556417465 |\n",
      "\n",
      "                    Average val loss: 0.0006713322945870459|\n",
      "                    Val-Mae: 0.021350029855966568\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 65\n",
      "Start training for stock: 4922\n",
      "\n",
      "                    Average train loss: 0.00818186640739441 | \n",
      "                    Train-Mae: 0.064407579600811 |\n",
      "\n",
      "                    Average val loss: 0.008862541057169437|\n",
      "                    Val-Mae: 0.03124120831489563\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 66\n",
      "Start training for stock: 5901\n",
      "\n",
      "                    Average train loss: 0.00010922094807028771 | \n",
      "                    Train-Mae: 0.04192838445305824 |\n",
      "\n",
      "                    Average val loss: 0.0036533763632178307|\n",
      "                    Val-Mae: 0.02320561185479164\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 67\n",
      "Start training for stock: 6861\n",
      "\n",
      "                    Average train loss: 0.0018973755836486817 | \n",
      "                    Train-Mae: 0.07642526179552078 |\n",
      "\n",
      "                    Average val loss: 0.2188093215227127|\n",
      "                    Val-Mae: 0.06603963673114777\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 68\n",
      "Start training for stock: 3926\n",
      "\n",
      "                    Average train loss: 0.010474075078964234 | \n",
      "                    Train-Mae: 0.0408211275935173 |\n",
      "\n",
      "                    Average val loss: 0.006848467513918877|\n",
      "                    Val-Mae: 0.035682860761880875\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 69\n",
      "Start training for stock: 3191\n",
      "\n",
      "                    Average train loss: 0.021298482418060302 | \n",
      "                    Train-Mae: 0.03429606184363365 |\n",
      "\n",
      "                    Average val loss: 0.011987273581326008|\n",
      "                    Val-Mae: 0.019693057984113693\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 70\n",
      "Start training for stock: 2830\n",
      "\n",
      "                    Average train loss: 0.011140149831771851 | \n",
      "                    Train-Mae: 0.038368117064237595 |\n",
      "\n",
      "                    Average val loss: 0.05232914909720421|\n",
      "                    Val-Mae: 0.02876080386340618\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 71\n",
      "Start training for stock: 5449\n",
      "\n",
      "                    Average train loss: 0.0006153933703899383 | \n",
      "                    Train-Mae: 0.047255974262952805 |\n",
      "\n",
      "                    Average val loss: 0.0010206400183960795|\n",
      "                    Val-Mae: 0.02009570226073265\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 72\n",
      "Start training for stock: 9319\n",
      "\n",
      "                    Average train loss: 0.000368775837123394 | \n",
      "                    Train-Mae: 0.07865161448717117 |\n",
      "\n",
      "                    Average val loss: 0.1020205169916153|\n",
      "                    Val-Mae: 0.04451048746705055\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 73\n",
      "Start training for stock: 8600\n",
      "\n",
      "                    Average train loss: 8.686846122145653e-05 | \n",
      "                    Train-Mae: 0.07001429796218872 |\n",
      "\n",
      "                    Average val loss: 0.0006853064987808466|\n",
      "                    Val-Mae: 0.014918760396540165\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 74\n",
      "Start training for stock: 3134\n",
      "\n",
      "                    Average train loss: 0.00015574701130390166 | \n",
      "                    Train-Mae: 0.07769778370857239 |\n",
      "\n",
      "                    Average val loss: 0.020878657698631287|\n",
      "                    Val-Mae: 0.034777816385030746\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 75\n",
      "Start training for stock: 8233\n",
      "\n",
      "                    Average train loss: 0.0005815425887703895 | \n",
      "                    Train-Mae: 0.036135297268629074 |\n",
      "\n",
      "                    Average val loss: 0.04027232527732849|\n",
      "                    Val-Mae: 0.037790995091199875\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 76\n",
      "Start training for stock: 2201\n",
      "\n",
      "                    Average train loss: 0.001674802601337433 | \n",
      "                    Train-Mae: 0.029488973319530487 |\n",
      "\n",
      "                    Average val loss: 0.004507414996623993|\n",
      "                    Val-Mae: 0.018412897363305092\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 77\n",
      "Start training for stock: 2384\n",
      "\n",
      "                    Average train loss: 0.00032568059861660004 | \n",
      "                    Train-Mae: 0.03733476623892784 |\n",
      "\n",
      "                    Average val loss: 0.06532041728496552|\n",
      "                    Val-Mae: 0.047988321632146835\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 78\n",
      "Start training for stock: 8928\n",
      "\n",
      "                    Average train loss: 0.000577729046344757 | \n",
      "                    Train-Mae: 0.03312622383236885 |\n",
      "\n",
      "                    Average val loss: 0.005946420133113861|\n",
      "                    Val-Mae: 0.018755007535219193\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 79\n",
      "Start training for stock: 7943\n",
      "\n",
      "                    Average train loss: 0.0010007540881633759 | \n",
      "                    Train-Mae: 0.058277130126953125 |\n",
      "\n",
      "                    Average val loss: 0.0017559839179739356|\n",
      "                    Val-Mae: 0.019535116851329803\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 80\n",
      "Start training for stock: 5946\n",
      "\n",
      "                    Average train loss: 0.0023128287494182586 | \n",
      "                    Train-Mae: 0.04613056033849716 |\n",
      "\n",
      "                    Average val loss: 0.12640486657619476|\n",
      "                    Val-Mae: 0.04342477768659592\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 81\n",
      "Start training for stock: 2009\n",
      "\n",
      "                    Average train loss: 0.033126251697540285 | \n",
      "                    Train-Mae: 0.08095461130142212 |\n",
      "\n",
      "                    Average val loss: 0.004353431519120932|\n",
      "                    Val-Mae: 0.0180563572794199\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 82\n",
      "Start training for stock: 3391\n",
      "\n",
      "                    Average train loss: 0.01515813946723938 | \n",
      "                    Train-Mae: 0.08910945802927017 |\n",
      "\n",
      "                    Average val loss: 0.023438559845089912|\n",
      "                    Val-Mae: 0.02739996649324894\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 83\n",
      "Start training for stock: 6706\n",
      "\n",
      "                    Average train loss: 0.000633099377155304 | \n",
      "                    Train-Mae: 0.06234413757920265 |\n",
      "\n",
      "                    Average val loss: 0.01807965151965618|\n",
      "                    Val-Mae: 0.03241725265979767\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 84\n",
      "Start training for stock: 8585\n",
      "\n",
      "                    Average train loss: 0.0038090547919273376 | \n",
      "                    Train-Mae: 0.030379027128219604 |\n",
      "\n",
      "                    Average val loss: 0.01147808600217104|\n",
      "                    Val-Mae: 0.02616111747920513\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 85\n",
      "Start training for stock: 2790\n",
      "\n",
      "                    Average train loss: 0.0047640356421470645 | \n",
      "                    Train-Mae: 0.06498274207115173 |\n",
      "\n",
      "                    Average val loss: 0.21494612097740173|\n",
      "                    Val-Mae: 0.06000296398997307\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 86\n",
      "Start training for stock: 8802\n",
      "\n",
      "                    Average train loss: 0.018077090978622437 | \n",
      "                    Train-Mae: 0.10732957720756531 |\n",
      "\n",
      "                    Average val loss: 0.23957383632659912|\n",
      "                    Val-Mae: 0.05213696509599686\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 87\n",
      "Start training for stock: 2782\n",
      "\n",
      "                    Average train loss: 0.01730678677558899 | \n",
      "                    Train-Mae: 0.026242483407258987 |\n",
      "\n",
      "                    Average val loss: 0.0043407706543803215|\n",
      "                    Val-Mae: 0.01749633438885212\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 88\n",
      "Start training for stock: 3857\n",
      "\n",
      "                    Average train loss: 0.00021753530949354173 | \n",
      "                    Train-Mae: 0.05056470260024071 |\n",
      "\n",
      "                    Average val loss: 0.0012132785050198436|\n",
      "                    Val-Mae: 0.017372170463204384\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 89\n",
      "Start training for stock: 3003\n",
      "\n",
      "                    Average train loss: 0.006382130384445191 | \n",
      "                    Train-Mae: 0.06094092130661011 |\n",
      "\n",
      "                    Average val loss: 0.01752081885933876|\n",
      "                    Val-Mae: 0.024468759074807167\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 90\n",
      "Start training for stock: 1861\n",
      "\n",
      "                    Average train loss: 0.004163077175617218 | \n",
      "                    Train-Mae: 0.06435850262641907 |\n",
      "\n",
      "                    Average val loss: 0.04310959205031395|\n",
      "                    Val-Mae: 0.0383015014231205\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 91\n",
      "Start training for stock: 6266\n",
      "\n",
      "                    Average train loss: 0.02381307363510132 | \n",
      "                    Train-Mae: 0.05307301878929138 |\n",
      "\n",
      "                    Average val loss: 0.0012465032050386071|\n",
      "                    Val-Mae: 0.023469872772693634\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 92\n",
      "Start training for stock: 2229\n",
      "\n",
      "                    Average train loss: 0.00170065775513649 | \n",
      "                    Train-Mae: 0.036379702389240265 |\n",
      "\n",
      "                    Average val loss: 0.029116732999682426|\n",
      "                    Val-Mae: 0.02812112681567669\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 93\n",
      "Start training for stock: 7729\n",
      "\n",
      "                    Average train loss: 0.005325694680213928 | \n",
      "                    Train-Mae: 0.03913426771759987 |\n",
      "\n",
      "                    Average val loss: 0.0018432621145620942|\n",
      "                    Val-Mae: 0.02058771625161171\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 94\n",
      "Start training for stock: 8130\n",
      "\n",
      "                    Average train loss: 0.0008090303838253021 | \n",
      "                    Train-Mae: 0.0584024153649807 |\n",
      "\n",
      "                    Average val loss: 0.014036692678928375|\n",
      "                    Val-Mae: 0.02407083660364151\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 95\n",
      "Start training for stock: 9997\n",
      "\n",
      "                    Average train loss: 0.0027433326840400696 | \n",
      "                    Train-Mae: 0.06525411456823349 |\n",
      "\n",
      "                    Average val loss: 0.009659851901233196|\n",
      "                    Val-Mae: 0.02857518009841442\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 96\n",
      "Start training for stock: 9722\n",
      "\n",
      "                    Average train loss: 0.0008069122582674026 | \n",
      "                    Train-Mae: 0.06837183237075806 |\n",
      "\n",
      "                    Average val loss: 0.0034111954737454653|\n",
      "                    Val-Mae: 0.031912561506032944\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 97\n",
      "Start training for stock: 1942\n",
      "\n",
      "                    Average train loss: 0.001886528730392456 | \n",
      "                    Train-Mae: 0.042523518204689026 |\n",
      "\n",
      "                    Average val loss: 0.08223318308591843|\n",
      "                    Val-Mae: 0.040108490735292435\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 98\n",
      "Start training for stock: 9424\n",
      "\n",
      "                    Average train loss: 0.0006763049215078354 | \n",
      "                    Train-Mae: 0.04853363335132599 |\n",
      "\n",
      "                    Average val loss: 0.1408667415380478|\n",
      "                    Val-Mae: 0.05772402882575989\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 99\n",
      "Start training for stock: 2792\n",
      "\n",
      "                    Average train loss: 0.0011454262584447861 | \n",
      "                    Train-Mae: 0.03808731958270073 |\n",
      "\n",
      "                    Average val loss: 0.02669265680015087|\n",
      "                    Val-Mae: 0.026234079152345657\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 100\n",
      "Start training for stock: 9936\n",
      "\n",
      "                    Average train loss: 7.414176594465971e-05 | \n",
      "                    Train-Mae: 0.05429951101541519 |\n",
      "\n",
      "                    Average val loss: 0.0009031170629896224|\n",
      "                    Val-Mae: 0.009896094910800457\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 101\n",
      "Start training for stock: 7011\n",
      "\n",
      "                    Average train loss: 0.001285056620836258 | \n",
      "                    Train-Mae: 0.033090151846408844 |\n",
      "\n",
      "                    Average val loss: 0.010230339132249355|\n",
      "                    Val-Mae: 0.023205844685435295\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 102\n",
      "Start training for stock: 4045\n",
      "\n",
      "                    Average train loss: 0.0015708406269550324 | \n",
      "                    Train-Mae: 0.048669490963220596 |\n",
      "\n",
      "                    Average val loss: 0.00073945865733549|\n",
      "                    Val-Mae: 0.015099389478564262\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 103\n",
      "Start training for stock: 8008\n",
      "\n",
      "                    Average train loss: 0.008746055364608764 | \n",
      "                    Train-Mae: 0.03449081629514694 |\n",
      "\n",
      "                    Average val loss: 0.03294048085808754|\n",
      "                    Val-Mae: 0.02952634170651436\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 104\n",
      "Start training for stock: 1803\n",
      "\n",
      "                    Average train loss: 0.006739932894706726 | \n",
      "                    Train-Mae: 0.02650216966867447 |\n",
      "\n",
      "                    Average val loss: 0.0003646675613708794|\n",
      "                    Val-Mae: 0.013457991182804108\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 105\n",
      "Start training for stock: 5698\n",
      "\n",
      "                    Average train loss: 0.00307906836271286 | \n",
      "                    Train-Mae: 0.039522796869277954 |\n",
      "\n",
      "                    Average val loss: 0.00961329136043787|\n",
      "                    Val-Mae: 0.04961143806576729\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 106\n",
      "Start training for stock: 6572\n",
      "\n",
      "                    Average train loss: 0.001404101401567459 | \n",
      "                    Train-Mae: 0.0264122411608696 |\n",
      "\n",
      "                    Average val loss: 0.002994155278429389|\n",
      "                    Val-Mae: 0.023221919313073158\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 107\n",
      "Start training for stock: 8237\n",
      "\n",
      "                    Average train loss: 5.153422709554434e-05 | \n",
      "                    Train-Mae: 0.05342097580432892 |\n",
      "\n",
      "                    Average val loss: 0.01079540140926838|\n",
      "                    Val-Mae: 0.03311416879296303\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 108\n",
      "Start training for stock: 7030\n",
      "\n",
      "                    Average train loss: 0.0012402500957250594 | \n",
      "                    Train-Mae: 0.03653743863105774 |\n",
      "\n",
      "                    Average val loss: 0.010859627276659012|\n",
      "                    Val-Mae: 0.03484673425555229\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 109\n",
      "Start training for stock: 5423\n",
      "\n",
      "                    Average train loss: 0.004762734472751618 | \n",
      "                    Train-Mae: 0.09525778889656067 |\n",
      "\n",
      "                    Average val loss: 0.3806073069572449|\n",
      "                    Val-Mae: 0.08066140860319138\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 110\n",
      "Start training for stock: 3377\n",
      "\n",
      "                    Average train loss: 0.0003550749644637108 | \n",
      "                    Train-Mae: 0.05068338289856911 |\n",
      "\n",
      "                    Average val loss: 0.6968322396278381|\n",
      "                    Val-Mae: 0.14673051238059998\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 111\n",
      "Start training for stock: 9233\n",
      "\n",
      "                    Average train loss: 0.002101415544748306 | \n",
      "                    Train-Mae: 0.0434846468269825 |\n",
      "\n",
      "                    Average val loss: 0.019189320504665375|\n",
      "                    Val-Mae: 0.024490222334861755\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 112\n",
      "Start training for stock: 6125\n",
      "\n",
      "                    Average train loss: 0.0009974126517772674 | \n",
      "                    Train-Mae: 0.03544618934392929 |\n",
      "\n",
      "                    Average val loss: 0.020476998761296272|\n",
      "                    Val-Mae: 0.04304179176688194\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 113\n",
      "Start training for stock: 6418\n",
      "\n",
      "                    Average train loss: 0.0026559999585151674 | \n",
      "                    Train-Mae: 0.03217419236898422 |\n",
      "\n",
      "                    Average val loss: 0.0008480826509185135|\n",
      "                    Val-Mae: 0.020005764439702034\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 114\n",
      "Start training for stock: 8041\n",
      "\n",
      "                    Average train loss: 0.0031620532274246214 | \n",
      "                    Train-Mae: 0.037260349839925766 |\n",
      "\n",
      "                    Average val loss: 0.006415828596800566|\n",
      "                    Val-Mae: 0.022821476683020592\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 115\n",
      "Start training for stock: 4475\n",
      "\n",
      "                    Average train loss: 0.00025491248816251756 | \n",
      "                    Train-Mae: 0.052948784083127975 |\n",
      "\n",
      "                    Average val loss: 0.003605555510148406|\n",
      "                    Val-Mae: 0.04517558962106705\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 116\n",
      "Start training for stock: 9708\n",
      "\n",
      "                    Average train loss: 0.012965164184570312 | \n",
      "                    Train-Mae: 0.031693920493125916 |\n",
      "\n",
      "                    Average val loss: 0.1326344609260559|\n",
      "                    Val-Mae: 0.04448823258280754\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 117\n",
      "Start training for stock: 1938\n",
      "\n",
      "                    Average train loss: 0.001165996491909027 | \n",
      "                    Train-Mae: 0.09202133119106293 |\n",
      "\n",
      "                    Average val loss: 0.0018740876112133265|\n",
      "                    Val-Mae: 0.02352752722799778\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 118\n",
      "Start training for stock: 4559\n",
      "\n",
      "                    Average train loss: 0.0016336682438850402 | \n",
      "                    Train-Mae: 0.048919130116701126 |\n",
      "\n",
      "                    Average val loss: 0.09927923232316971|\n",
      "                    Val-Mae: 0.03874055668711662\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 119\n",
      "Start training for stock: 1413\n",
      "\n",
      "                    Average train loss: 0.0017351281642913818 | \n",
      "                    Train-Mae: 0.037528324872255325 |\n",
      "\n",
      "                    Average val loss: 0.006051663774996996|\n",
      "                    Val-Mae: 0.019503027200698853\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 120\n",
      "Start training for stock: 5310\n",
      "\n",
      "                    Average train loss: 0.0005600928515195847 | \n",
      "                    Train-Mae: 0.033736735582351685 |\n",
      "\n",
      "                    Average val loss: 0.013847709633409977|\n",
      "                    Val-Mae: 0.029477400705218315\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 121\n",
      "Start training for stock: 1379\n",
      "\n",
      "                    Average train loss: 0.008175477981567383 | \n",
      "                    Train-Mae: 0.03852420672774315 |\n",
      "\n",
      "                    Average val loss: 0.22633317112922668|\n",
      "                    Val-Mae: 0.04778171703219414\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 122\n",
      "Start training for stock: 6448\n",
      "\n",
      "                    Average train loss: 0.010317363739013673 | \n",
      "                    Train-Mae: 0.04581695795059204 |\n",
      "\n",
      "                    Average val loss: 0.0013042837381362915|\n",
      "                    Val-Mae: 0.01898047886788845\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 123\n",
      "Start training for stock: 2301\n",
      "\n",
      "                    Average train loss: 0.0012282666563987732 | \n",
      "                    Train-Mae: 0.05352717638015747 |\n",
      "\n",
      "                    Average val loss: 0.0011470813769847155|\n",
      "                    Val-Mae: 0.017960501834750175\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 124\n",
      "Start training for stock: 8168\n",
      "\n",
      "                    Average train loss: 0.007540807723999023 | \n",
      "                    Train-Mae: 0.048154816031455994 |\n",
      "\n",
      "                    Average val loss: 0.10040775686502457|\n",
      "                    Val-Mae: 0.04070635139942169\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 125\n",
      "Start training for stock: 6503\n",
      "\n",
      "                    Average train loss: 3.816390642896295e-05 | \n",
      "                    Train-Mae: 0.040657490491867065 |\n",
      "\n",
      "                    Average val loss: 0.15284237265586853|\n",
      "                    Val-Mae: 0.04710755497217178\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 126\n",
      "Start training for stock: 6073\n",
      "\n",
      "                    Average train loss: 0.0020147225260734557 | \n",
      "                    Train-Mae: 0.07604127377271652 |\n",
      "\n",
      "                    Average val loss: 0.05068652704358101|\n",
      "                    Val-Mae: 0.025683334097266197\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 127\n",
      "Start training for stock: 7482\n",
      "\n",
      "                    Average train loss: 0.001576218456029892 | \n",
      "                    Train-Mae: 0.06789250671863556 |\n",
      "\n",
      "                    Average val loss: 0.01036903727799654|\n",
      "                    Val-Mae: 0.02332841418683529\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 128\n",
      "Start training for stock: 4825\n",
      "\n",
      "                    Average train loss: 0.004415879249572754 | \n",
      "                    Train-Mae: 0.05118302255868912 |\n",
      "\n",
      "                    Average val loss: 0.00329603417776525|\n",
      "                    Val-Mae: 0.029991555958986282\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 129\n",
      "Start training for stock: 6740\n",
      "\n",
      "                    Average train loss: 0.002274076044559479 | \n",
      "                    Train-Mae: 0.029946662485599518 |\n",
      "\n",
      "                    Average val loss: 0.000797869695816189|\n",
      "                    Val-Mae: 0.020852334797382355\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 130\n",
      "Start training for stock: 5011\n",
      "\n",
      "                    Average train loss: 0.0001575981080532074 | \n",
      "                    Train-Mae: 0.04915885627269745 |\n",
      "\n",
      "                    Average val loss: 0.0018091025995090604|\n",
      "                    Val-Mae: 0.016293786466121674\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 131\n",
      "Start training for stock: 2221\n",
      "\n",
      "                    Average train loss: 0.00020211735740303992 | \n",
      "                    Train-Mae: 0.03555707633495331 |\n",
      "\n",
      "                    Average val loss: 0.0007284547318704426|\n",
      "                    Val-Mae: 0.01010421384125948\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 132\n",
      "Start training for stock: 2702\n",
      "\n",
      "                    Average train loss: 0.00037273358553647996 | \n",
      "                    Train-Mae: 0.04394858703017235 |\n",
      "\n",
      "                    Average val loss: 0.04775303974747658|\n",
      "                    Val-Mae: 0.028957797214388847\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 133\n",
      "Start training for stock: 2579\n",
      "\n",
      "                    Average train loss: 0.00019223645329475403 | \n",
      "                    Train-Mae: 0.03564229980111122 |\n",
      "\n",
      "                    Average val loss: 0.01693965122103691|\n",
      "                    Val-Mae: 0.02924223616719246\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 134\n",
      "Start training for stock: 9543\n",
      "\n",
      "                    Average train loss: 0.00013810702599585057 | \n",
      "                    Train-Mae: 0.06531655043363571 |\n",
      "\n",
      "                    Average val loss: 0.004883897490799427|\n",
      "                    Val-Mae: 0.022151315584778786\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 135\n",
      "Start training for stock: 3763\n",
      "\n",
      "                    Average train loss: 0.0016980761289596559 | \n",
      "                    Train-Mae: 0.029998421669006348 |\n",
      "\n",
      "                    Average val loss: 0.016148069873452187|\n",
      "                    Val-Mae: 0.02543380856513977\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 136\n",
      "Start training for stock: 6149\n",
      "\n",
      "                    Average train loss: 8.912112563848496e-05 | \n",
      "                    Train-Mae: 0.05047022923827171 |\n",
      "\n",
      "                    Average val loss: 0.007349804043769836|\n",
      "                    Val-Mae: 0.027551235631108284\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 137\n",
      "Start training for stock: 6920\n",
      "\n",
      "                    Average train loss: 5.067714489996433e-05 | \n",
      "                    Train-Mae: 0.046899959444999695 |\n",
      "\n",
      "                    Average val loss: 0.017352541908621788|\n",
      "                    Val-Mae: 0.053305868059396744\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 138\n",
      "Start training for stock: 4767\n",
      "\n",
      "                    Average train loss: 0.0034179311990737917 | \n",
      "                    Train-Mae: 0.057950668036937714 |\n",
      "\n",
      "                    Average val loss: 0.026582634076476097|\n",
      "                    Val-Mae: 0.030226103961467743\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 139\n",
      "Start training for stock: 2752\n",
      "\n",
      "                    Average train loss: 0.007250052690505981 | \n",
      "                    Train-Mae: 0.04479798674583435 |\n",
      "\n",
      "                    Average val loss: 0.00528257479891181|\n",
      "                    Val-Mae: 0.018942004069685936\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 140\n",
      "Start training for stock: 8285\n",
      "\n",
      "                    Average train loss: 0.010741262435913087 | \n",
      "                    Train-Mae: 0.07719184458255768 |\n",
      "\n",
      "                    Average val loss: 0.01564163528382778|\n",
      "                    Val-Mae: 0.025792082771658897\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 141\n",
      "Start training for stock: 4847\n",
      "\n",
      "                    Average train loss: 0.002324438989162445 | \n",
      "                    Train-Mae: 0.04271659255027771 |\n",
      "\n",
      "                    Average val loss: 0.014520464465022087|\n",
      "                    Val-Mae: 0.023471586406230927\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 142\n",
      "Start training for stock: 7741\n",
      "\n",
      "                    Average train loss: 0.000297585129737854 | \n",
      "                    Train-Mae: 0.038076117634773254 |\n",
      "\n",
      "                    Average val loss: 0.050938718020915985|\n",
      "                    Val-Mae: 0.04215763509273529\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 143\n",
      "Start training for stock: 4182\n",
      "\n",
      "                    Average train loss: 0.000402042455971241 | \n",
      "                    Train-Mae: 0.031044645234942436 |\n",
      "\n",
      "                    Average val loss: 0.03382277488708496|\n",
      "                    Val-Mae: 0.031151046976447105\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 144\n",
      "Start training for stock: 1950\n",
      "\n",
      "                    Average train loss: 0.0051495015621185304 | \n",
      "                    Train-Mae: 0.10364498198032379 |\n",
      "\n",
      "                    Average val loss: 0.24063700437545776|\n",
      "                    Val-Mae: 0.06110860034823418\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 145\n",
      "Start training for stock: 4433\n",
      "\n",
      "                    Average train loss: 0.0015174967050552368 | \n",
      "                    Train-Mae: 0.07695745676755905 |\n",
      "\n",
      "                    Average val loss: 0.08689330518245697|\n",
      "                    Val-Mae: 0.049123868346214294\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 146\n",
      "Start training for stock: 3086\n",
      "\n",
      "                    Average train loss: 0.000255503598600626 | \n",
      "                    Train-Mae: 0.028670595958828926 |\n",
      "\n",
      "                    Average val loss: 0.07333569973707199|\n",
      "                    Val-Mae: 0.04036928713321686\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 147\n",
      "Start training for stock: 2130\n",
      "\n",
      "                    Average train loss: 0.00014747558161616326 | \n",
      "                    Train-Mae: 0.06801770627498627 |\n",
      "\n",
      "                    Average val loss: 0.09858842939138412|\n",
      "                    Val-Mae: 0.052882853895425797\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 148\n",
      "Start training for stock: 9039\n",
      "\n",
      "                    Average train loss: 0.003990952670574188 | \n",
      "                    Train-Mae: 0.0597568042576313 |\n",
      "\n",
      "                    Average val loss: 0.03610663115978241|\n",
      "                    Val-Mae: 0.02947097271680832\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 149\n",
      "Start training for stock: 9509\n",
      "\n",
      "                    Average train loss: 0.0015486112236976623 | \n",
      "                    Train-Mae: 0.03529112786054611 |\n",
      "\n",
      "                    Average val loss: 0.005534975789487362|\n",
      "                    Val-Mae: 0.01881607249379158\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 150\n",
      "Start training for stock: 3659\n",
      "\n",
      "                    Average train loss: 0.0007788106054067612 | \n",
      "                    Train-Mae: 0.060236770659685135 |\n",
      "\n",
      "                    Average val loss: 0.03401371091604233|\n",
      "                    Val-Mae: 0.03674550727009773\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 151\n",
      "Start training for stock: 9621\n",
      "\n",
      "                    Average train loss: 0.0002993190847337246 | \n",
      "                    Train-Mae: 0.04681830480694771 |\n",
      "\n",
      "                    Average val loss: 0.009823892265558243|\n",
      "                    Val-Mae: 0.02255713939666748\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 152\n",
      "Start training for stock: 3964\n",
      "\n",
      "                    Average train loss: 0.0014071589708328247 | \n",
      "                    Train-Mae: 0.04657964035868645 |\n",
      "\n",
      "                    Average val loss: 0.035362206399440765|\n",
      "                    Val-Mae: 0.04374907165765762\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 153\n",
      "Start training for stock: 8338\n",
      "\n",
      "                    Average train loss: 0.013902846574783325 | \n",
      "                    Train-Mae: 0.029979612678289413 |\n",
      "\n",
      "                    Average val loss: 0.010076017118990421|\n",
      "                    Val-Mae: 0.023133717477321625\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 154\n",
      "Start training for stock: 1775\n",
      "\n",
      "                    Average train loss: 0.00014002883806824685 | \n",
      "                    Train-Mae: 0.038201186805963516 |\n",
      "\n",
      "                    Average val loss: 0.0010377914877608418|\n",
      "                    Val-Mae: 0.017750874161720276\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 155\n",
      "Start training for stock: 4620\n",
      "\n",
      "                    Average train loss: 0.0008973094820976257 | \n",
      "                    Train-Mae: 0.09710396826267242 |\n",
      "\n",
      "                    Average val loss: 0.20360122621059418|\n",
      "                    Val-Mae: 0.05696174502372742\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 156\n",
      "Start training for stock: 2760\n",
      "\n",
      "                    Average train loss: 0.001341758519411087 | \n",
      "                    Train-Mae: 0.040141183882951736 |\n",
      "\n",
      "                    Average val loss: 0.8401802778244019|\n",
      "                    Val-Mae: 0.11278846859931946\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 157\n",
      "Start training for stock: 5707\n",
      "\n",
      "                    Average train loss: 0.0016580627858638764 | \n",
      "                    Train-Mae: 0.03963940963149071 |\n",
      "\n",
      "                    Average val loss: 0.019766636192798615|\n",
      "                    Val-Mae: 0.034262124449014664\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 158\n",
      "Start training for stock: 4216\n",
      "\n",
      "                    Average train loss: 0.003092911243438721 | \n",
      "                    Train-Mae: 0.02698916755616665 |\n",
      "\n",
      "                    Average val loss: 0.029712270945310593|\n",
      "                    Val-Mae: 0.025641053915023804\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 159\n",
      "Start training for stock: 7211\n",
      "\n",
      "                    Average train loss: 0.004066132307052613 | \n",
      "                    Train-Mae: 0.04917271435260773 |\n",
      "\n",
      "                    Average val loss: 0.0007511223666369915|\n",
      "                    Val-Mae: 0.02127947099506855\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 160\n",
      "Start training for stock: 9537\n",
      "\n",
      "                    Average train loss: 0.0018796968460083009 | \n",
      "                    Train-Mae: 0.11890336871147156 |\n",
      "\n",
      "                    Average val loss: 0.012332204729318619|\n",
      "                    Val-Mae: 0.036368660628795624\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 161\n",
      "Start training for stock: 9107\n",
      "\n",
      "                    Average train loss: 0.0006089447438716888 | \n",
      "                    Train-Mae: 0.04504252225160599 |\n",
      "\n",
      "                    Average val loss: 0.06491879373788834|\n",
      "                    Val-Mae: 0.07166208326816559\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 162\n",
      "Start training for stock: 6539\n",
      "\n",
      "                    Average train loss: 0.00082025907933712 | \n",
      "                    Train-Mae: 0.0336979404091835 |\n",
      "\n",
      "                    Average val loss: 0.001893992768600583|\n",
      "                    Val-Mae: 0.024308402091264725\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 163\n",
      "Start training for stock: 7254\n",
      "\n",
      "                    Average train loss: 0.004655545651912689 | \n",
      "                    Train-Mae: 0.09141502529382706 |\n",
      "\n",
      "                    Average val loss: 0.4691472053527832|\n",
      "                    Val-Mae: 0.09807922691106796\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 164\n",
      "Start training for stock: 9692\n",
      "\n",
      "                    Average train loss: 0.0050523638725280765 | \n",
      "                    Train-Mae: 0.03730045631527901 |\n",
      "\n",
      "                    Average val loss: 0.02041996270418167|\n",
      "                    Val-Mae: 0.026652216911315918\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 165\n",
      "Start training for stock: 5727\n",
      "\n",
      "                    Average train loss: 0.0002627898566424847 | \n",
      "                    Train-Mae: 0.045147109776735306 |\n",
      "\n",
      "                    Average val loss: 0.1221032664179802|\n",
      "                    Val-Mae: 0.05042894929647446\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 166\n",
      "Start training for stock: 8291\n",
      "\n",
      "                    Average train loss: 0.0010656220465898513 | \n",
      "                    Train-Mae: 0.0341198556125164 |\n",
      "\n",
      "                    Average val loss: 0.028436491265892982|\n",
      "                    Val-Mae: 0.02516118250787258\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 167\n",
      "Start training for stock: 9435\n",
      "\n",
      "                    Average train loss: 0.003211909532546997 | \n",
      "                    Train-Mae: 0.0428229458630085 |\n",
      "\n",
      "                    Average val loss: 0.0016949293203651905|\n",
      "                    Val-Mae: 0.017190197482705116\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 168\n",
      "Start training for stock: 4927\n",
      "\n",
      "                    Average train loss: 0.00018812712281942367 | \n",
      "                    Train-Mae: 0.025968186557292938 |\n",
      "\n",
      "                    Average val loss: 0.003421865403652191|\n",
      "                    Val-Mae: 0.01865117810666561\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 169\n",
      "Start training for stock: 6420\n",
      "\n",
      "                    Average train loss: 0.013481571674346923 | \n",
      "                    Train-Mae: 0.04269574210047722 |\n",
      "\n",
      "                    Average val loss: 0.09725868701934814|\n",
      "                    Val-Mae: 0.041408732533454895\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 170\n",
      "Start training for stock: 3990\n",
      "\n",
      "                    Average train loss: 0.00011840132996439934 | \n",
      "                    Train-Mae: 0.050181128084659576 |\n",
      "\n",
      "                    Average val loss: 0.0022906027734279633|\n",
      "                    Val-Mae: 0.022567301988601685\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 171\n",
      "Start training for stock: 7599\n",
      "\n",
      "                    Average train loss: 0.004952481389045716 | \n",
      "                    Train-Mae: 0.05993037670850754 |\n",
      "\n",
      "                    Average val loss: 0.02656204253435135|\n",
      "                    Val-Mae: 0.03616853430867195\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 172\n",
      "Start training for stock: 2157\n",
      "\n",
      "                    Average train loss: 0.0001588728465139866 | \n",
      "                    Train-Mae: 0.04626267030835152 |\n",
      "\n",
      "                    Average val loss: 0.0013648729072883725|\n",
      "                    Val-Mae: 0.02399364300072193\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 173\n",
      "Start training for stock: 2413\n",
      "\n",
      "                    Average train loss: 0.008482563495635986 | \n",
      "                    Train-Mae: 0.044856347143650055 |\n",
      "\n",
      "                    Average val loss: 0.0007518786587752402|\n",
      "                    Val-Mae: 0.019727030768990517\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 174\n",
      "Start training for stock: 3966\n",
      "\n",
      "                    Average train loss: 0.0007213587313890458 | \n",
      "                    Train-Mae: 0.039830707013607025 |\n",
      "\n",
      "                    Average val loss: 0.0018361133988946676|\n",
      "                    Val-Mae: 0.02657334692776203\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 175\n",
      "Start training for stock: 9783\n",
      "\n",
      "                    Average train loss: 0.005297276973724365 | \n",
      "                    Train-Mae: 0.09328065067529678 |\n",
      "\n",
      "                    Average val loss: 0.03024999052286148|\n",
      "                    Val-Mae: 0.032286010682582855\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 176\n",
      "Start training for stock: 4552\n",
      "\n",
      "                    Average train loss: 0.0001354509126394987 | \n",
      "                    Train-Mae: 0.06030398979783058 |\n",
      "\n",
      "                    Average val loss: 0.00175905239302665|\n",
      "                    Val-Mae: 0.019910575821995735\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 177\n",
      "Start training for stock: 3157\n",
      "\n",
      "                    Average train loss: 2.9610402416437866e-05 | \n",
      "                    Train-Mae: 0.023634882643818855 |\n",
      "\n",
      "                    Average val loss: 0.015809547156095505|\n",
      "                    Val-Mae: 0.023316025733947754\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 178\n",
      "Start training for stock: 9044\n",
      "\n",
      "                    Average train loss: 0.0002550181001424789 | \n",
      "                    Train-Mae: 0.038781702518463135 |\n",
      "\n",
      "                    Average val loss: 0.00048177887219935656|\n",
      "                    Val-Mae: 0.014853077940642834\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 179\n",
      "Start training for stock: 2475\n",
      "\n",
      "                    Average train loss: 0.004032221138477326 | \n",
      "                    Train-Mae: 0.03757002577185631 |\n",
      "\n",
      "                    Average val loss: 0.02546108141541481|\n",
      "                    Val-Mae: 0.030260512605309486\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 180\n",
      "Start training for stock: 7621\n",
      "\n",
      "                    Average train loss: 0.0002807479538023472 | \n",
      "                    Train-Mae: 0.029562240466475487 |\n",
      "\n",
      "                    Average val loss: 0.014772845432162285|\n",
      "                    Val-Mae: 0.027874916791915894\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 181\n",
      "Start training for stock: 7965\n",
      "\n",
      "                    Average train loss: 0.0002004285715520382 | \n",
      "                    Train-Mae: 0.0487026683986187 |\n",
      "\n",
      "                    Average val loss: 0.002497636014595628|\n",
      "                    Val-Mae: 0.019070420414209366\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 182\n",
      "Start training for stock: 9828\n",
      "\n",
      "                    Average train loss: 0.000555318184196949 | \n",
      "                    Train-Mae: 0.03905259445309639 |\n",
      "\n",
      "                    Average val loss: 0.003956866916269064|\n",
      "                    Val-Mae: 0.01727324351668358\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 183\n",
      "Start training for stock: 2681\n",
      "\n",
      "                    Average train loss: 0.009510631561279298 | \n",
      "                    Train-Mae: 0.033906951546669006 |\n",
      "\n",
      "                    Average val loss: 0.024878446012735367|\n",
      "                    Val-Mae: 0.026182759553194046\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 184\n",
      "Start training for stock: 8249\n",
      "\n",
      "                    Average train loss: 0.01550220012664795 | \n",
      "                    Train-Mae: 0.06951173394918442 |\n",
      "\n",
      "                    Average val loss: 0.0009934540139511228|\n",
      "                    Val-Mae: 0.020963851362466812\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 185\n",
      "Start training for stock: 7280\n",
      "\n",
      "                    Average train loss: 0.0006129360571503639 | \n",
      "                    Train-Mae: 0.03329291567206383 |\n",
      "\n",
      "                    Average val loss: 0.005463086999952793|\n",
      "                    Val-Mae: 0.027304185554385185\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 186\n",
      "Start training for stock: 7157\n",
      "\n",
      "                    Average train loss: 0.001452910453081131 | \n",
      "                    Train-Mae: 0.04691821336746216 |\n",
      "\n",
      "                    Average val loss: 0.00418491754680872|\n",
      "                    Val-Mae: 0.024587636813521385\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 187\n",
      "Start training for stock: 5481\n",
      "\n",
      "                    Average train loss: 0.0023619213700294493 | \n",
      "                    Train-Mae: 0.036133747547864914 |\n",
      "\n",
      "                    Average val loss: 0.0009093646076507866|\n",
      "                    Val-Mae: 0.024291761219501495\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 188\n",
      "Start training for stock: 2669\n",
      "\n",
      "                    Average train loss: 0.0022199136018753052 | \n",
      "                    Train-Mae: 0.04253016412258148 |\n",
      "\n",
      "                    Average val loss: 0.0073107643984258175|\n",
      "                    Val-Mae: 0.018622584640979767\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 189\n",
      "Start training for stock: 9602\n",
      "\n",
      "                    Average train loss: 0.0002642165496945381 | \n",
      "                    Train-Mae: 0.029357057064771652 |\n",
      "\n",
      "                    Average val loss: 0.046654485166072845|\n",
      "                    Val-Mae: 0.03340311720967293\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 190\n",
      "Start training for stock: 7638\n",
      "\n",
      "                    Average train loss: 2.17163423076272e-05 | \n",
      "                    Train-Mae: 0.055393852293491364 |\n",
      "\n",
      "                    Average val loss: 0.006848234683275223|\n",
      "                    Val-Mae: 0.02707328274846077\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 191\n",
      "Start training for stock: 4548\n",
      "\n",
      "                    Average train loss: 0.00018373891711235047 | \n",
      "                    Train-Mae: 0.03135977312922478 |\n",
      "\n",
      "                    Average val loss: 0.012701380997896194|\n",
      "                    Val-Mae: 0.02240939438343048\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 192\n",
      "Start training for stock: 3649\n",
      "\n",
      "                    Average train loss: 0.000320855975151062 | \n",
      "                    Train-Mae: 0.058195944875478745 |\n",
      "\n",
      "                    Average val loss: 0.13349372148513794|\n",
      "                    Val-Mae: 0.04980088770389557\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 193\n",
      "Start training for stock: 4097\n",
      "\n",
      "                    Average train loss: 0.004584614932537079 | \n",
      "                    Train-Mae: 0.046729132533073425 |\n",
      "\n",
      "                    Average val loss: 0.002775863977149129|\n",
      "                    Val-Mae: 0.017294766381382942\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 194\n",
      "Start training for stock: 5706\n",
      "\n",
      "                    Average train loss: 0.0001750085689127445 | \n",
      "                    Train-Mae: 0.05386237055063248 |\n",
      "\n",
      "                    Average val loss: 0.0007604362326674163|\n",
      "                    Val-Mae: 0.019333766773343086\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 195\n",
      "Start training for stock: 7358\n",
      "\n",
      "                    Average train loss: 0.00042640790343284607 | \n",
      "                    Train-Mae: 0.045790258795022964 |\n",
      "\n",
      "                    Average val loss: 0.0017035675700753927|\n",
      "                    Val-Mae: 0.027361180633306503\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 196\n",
      "Start training for stock: 9946\n",
      "\n",
      "                    Average train loss: 0.0007640637457370758 | \n",
      "                    Train-Mae: 0.036943644285202026 |\n",
      "\n",
      "                    Average val loss: 0.03785305842757225|\n",
      "                    Val-Mae: 0.024386677891016006\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 197\n",
      "Start training for stock: 3361\n",
      "\n",
      "                    Average train loss: 0.004474794566631317 | \n",
      "                    Train-Mae: 0.025958778336644173 |\n",
      "\n",
      "                    Average val loss: 0.004265477415174246|\n",
      "                    Val-Mae: 0.01745988428592682\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 198\n",
      "Start training for stock: 6668\n",
      "\n",
      "                    Average train loss: 0.001585216522216797 | \n",
      "                    Train-Mae: 0.0399349108338356 |\n",
      "\n",
      "                    Average val loss: 0.04032830148935318|\n",
      "                    Val-Mae: 0.04771002382040024\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 199\n",
      "Start training for stock: 8182\n",
      "\n",
      "                    Average train loss: 0.001386493444442749 | \n",
      "                    Train-Mae: 0.08196473121643066 |\n",
      "\n",
      "                    Average val loss: 0.007358390372246504|\n",
      "                    Val-Mae: 0.019287919625639915\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 200\n",
      "Start training for stock: 6272\n",
      "\n",
      "                    Average train loss: 5.5639827623963354e-05 | \n",
      "                    Train-Mae: 0.02991420403122902 |\n",
      "\n",
      "                    Average val loss: 0.0029256842099130154|\n",
      "                    Val-Mae: 0.021954165771603584\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 201\n",
      "Start training for stock: 4483\n",
      "\n",
      "                    Average train loss: 0.00019480714574456214 | \n",
      "                    Train-Mae: 0.04605133831501007 |\n",
      "\n",
      "                    Average val loss: 0.004185548517853022|\n",
      "                    Val-Mae: 0.03398434817790985\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 202\n",
      "Start training for stock: 3632\n",
      "\n",
      "                    Average train loss: 0.0015143726766109467 | \n",
      "                    Train-Mae: 0.03677147999405861 |\n",
      "\n",
      "                    Average val loss: 0.015318849124014378|\n",
      "                    Val-Mae: 0.03231732174754143\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 203\n",
      "Start training for stock: 5911\n",
      "\n",
      "                    Average train loss: 0.00023893387988209723 | \n",
      "                    Train-Mae: 0.03683130815625191 |\n",
      "\n",
      "                    Average val loss: 0.04284124821424484|\n",
      "                    Val-Mae: 0.028914082795381546\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 204\n",
      "Start training for stock: 7272\n",
      "\n",
      "                    Average train loss: 4.161363001912832e-05 | \n",
      "                    Train-Mae: 0.036730386316776276 |\n",
      "\n",
      "                    Average val loss: 0.013047924265265465|\n",
      "                    Val-Mae: 0.025058230385184288\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 205\n",
      "Start training for stock: 9031\n",
      "\n",
      "                    Average train loss: 0.00027302058413624763 | \n",
      "                    Train-Mae: 0.03228449821472168 |\n",
      "\n",
      "                    Average val loss: 0.01272146962583065|\n",
      "                    Val-Mae: 0.02448485791683197\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 206\n",
      "Start training for stock: 8203\n",
      "\n",
      "                    Average train loss: 0.0016834436357021333 | \n",
      "                    Train-Mae: 0.03172522410750389 |\n",
      "\n",
      "                    Average val loss: 0.0015148809179663658|\n",
      "                    Val-Mae: 0.01578541286289692\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 207\n",
      "Start training for stock: 8252\n",
      "\n",
      "                    Average train loss: 0.001194721758365631 | \n",
      "                    Train-Mae: 0.03199110925197601 |\n",
      "\n",
      "                    Average val loss: 0.047962531447410583|\n",
      "                    Val-Mae: 0.03458723798394203\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 208\n",
      "Start training for stock: 3678\n",
      "\n",
      "                    Average train loss: 0.00039934318512678145 | \n",
      "                    Train-Mae: 0.039971791207790375 |\n",
      "\n",
      "                    Average val loss: 0.013586502522230148|\n",
      "                    Val-Mae: 0.03231827914714813\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 209\n",
      "Start training for stock: 7351\n",
      "\n",
      "                    Average train loss: 0.006222297549247742 | \n",
      "                    Train-Mae: 0.08366062492132187 |\n",
      "\n",
      "                    Average val loss: 0.0021951671224087477|\n",
      "                    Val-Mae: 0.029323354363441467\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 210\n",
      "Start training for stock: 2929\n",
      "\n",
      "                    Average train loss: 9.0290242806077e-05 | \n",
      "                    Train-Mae: 0.0708884596824646 |\n",
      "\n",
      "                    Average val loss: 0.00816439837217331|\n",
      "                    Val-Mae: 0.033258359879255295\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 211\n",
      "Start training for stock: 4716\n",
      "\n",
      "                    Average train loss: 0.0014617988467216492 | \n",
      "                    Train-Mae: 0.04629331827163696 |\n",
      "\n",
      "                    Average val loss: 0.11352725327014923|\n",
      "                    Val-Mae: 0.04643816500902176\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 212\n",
      "Start training for stock: 3046\n",
      "\n",
      "                    Average train loss: 0.0052835804224014285 | \n",
      "                    Train-Mae: 0.056651316583156586 |\n",
      "\n",
      "                    Average val loss: 0.1391715407371521|\n",
      "                    Val-Mae: 0.0438743494451046\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 213\n",
      "Start training for stock: 6770\n",
      "\n",
      "                    Average train loss: 0.003885192275047302 | \n",
      "                    Train-Mae: 0.029202818870544434 |\n",
      "\n",
      "                    Average val loss: 0.000434118410339579|\n",
      "                    Val-Mae: 0.014248752035200596\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 214\n",
      "Start training for stock: 2594\n",
      "\n",
      "                    Average train loss: 0.0018907219171524047 | \n",
      "                    Train-Mae: 0.047541942447423935 |\n",
      "\n",
      "                    Average val loss: 0.0004187912563793361|\n",
      "                    Val-Mae: 0.009249148890376091\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 215\n",
      "Start training for stock: 3315\n",
      "\n",
      "                    Average train loss: 0.002966238260269165 | \n",
      "                    Train-Mae: 0.02808043360710144 |\n",
      "\n",
      "                    Average val loss: 0.07284656167030334|\n",
      "                    Val-Mae: 0.0427958220243454\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 216\n",
      "Start training for stock: 7575\n",
      "\n",
      "                    Average train loss: 0.0009915216267108917 | \n",
      "                    Train-Mae: 0.022470276802778244 |\n",
      "\n",
      "                    Average val loss: 0.0023167754989117384|\n",
      "                    Val-Mae: 0.015383272431790829\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 217\n",
      "Start training for stock: 2780\n",
      "\n",
      "                    Average train loss: 0.0027602726221084596 | \n",
      "                    Train-Mae: 0.046118609607219696 |\n",
      "\n",
      "                    Average val loss: 0.008488165214657784|\n",
      "                    Val-Mae: 0.03912960737943649\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 218\n",
      "Start training for stock: 7276\n",
      "\n",
      "                    Average train loss: 0.00011731419712305069 | \n",
      "                    Train-Mae: 0.06413578987121582 |\n",
      "\n",
      "                    Average val loss: 0.13974659144878387|\n",
      "                    Val-Mae: 0.04772533103823662\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 219\n",
      "Start training for stock: 4490\n",
      "\n",
      "                    Average train loss: 0.0010574138164520263 | \n",
      "                    Train-Mae: 0.06147143989801407 |\n",
      "\n",
      "                    Average val loss: 0.04217957332730293|\n",
      "                    Val-Mae: 0.06399110704660416\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 220\n",
      "Start training for stock: 3443\n",
      "\n",
      "                    Average train loss: 0.018012959957122803 | \n",
      "                    Train-Mae: 0.06595535576343536 |\n",
      "\n",
      "                    Average val loss: 0.0026005180552601814|\n",
      "                    Val-Mae: 0.017990482971072197\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 221\n",
      "Start training for stock: 4595\n",
      "\n",
      "                    Average train loss: 0.0017423251271247865 | \n",
      "                    Train-Mae: 0.033798884600400925 |\n",
      "\n",
      "                    Average val loss: 0.003730633296072483|\n",
      "                    Val-Mae: 0.029575727880001068\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 222\n",
      "Start training for stock: 4978\n",
      "\n",
      "                    Average train loss: 0.0021885946393013 | \n",
      "                    Train-Mae: 0.05987795814871788 |\n",
      "\n",
      "                    Average val loss: 0.0024022336583584547|\n",
      "                    Val-Mae: 0.0224286001175642\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 223\n",
      "Start training for stock: 4025\n",
      "\n",
      "                    Average train loss: 0.00043583959341049195 | \n",
      "                    Train-Mae: 0.03869706392288208 |\n",
      "\n",
      "                    Average val loss: 0.004353365395218134|\n",
      "                    Val-Mae: 0.022382836788892746\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 224\n",
      "Start training for stock: 4114\n",
      "\n",
      "                    Average train loss: 0.0006101132184267044 | \n",
      "                    Train-Mae: 0.03260098025202751 |\n",
      "\n",
      "                    Average val loss: 0.011129017919301987|\n",
      "                    Val-Mae: 0.02230156771838665\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 225\n",
      "Start training for stock: 8381\n",
      "\n",
      "                    Average train loss: 0.00011904086917638779 | \n",
      "                    Train-Mae: 0.031917691230773926 |\n",
      "\n",
      "                    Average val loss: 0.02570703998208046|\n",
      "                    Val-Mae: 0.027741163969039917\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 226\n",
      "Start training for stock: 9830\n",
      "\n",
      "                    Average train loss: 0.001064540147781372 | \n",
      "                    Train-Mae: 0.059067387133836746 |\n",
      "\n",
      "                    Average val loss: 0.20599405467510223|\n",
      "                    Val-Mae: 0.05118568614125252\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 227\n",
      "Start training for stock: 9068\n",
      "\n",
      "                    Average train loss: 0.00116230346262455 | \n",
      "                    Train-Mae: 0.05095392093062401 |\n",
      "\n",
      "                    Average val loss: 0.01937558688223362|\n",
      "                    Val-Mae: 0.028175372630357742\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 228\n",
      "Start training for stock: 3696\n",
      "\n",
      "                    Average train loss: 0.003546198904514313 | \n",
      "                    Train-Mae: 0.05842658504843712 |\n",
      "\n",
      "                    Average val loss: 0.08981761336326599|\n",
      "                    Val-Mae: 0.053833313286304474\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 229\n",
      "Start training for stock: 9310\n",
      "\n",
      "                    Average train loss: 0.0009563858807086945 | \n",
      "                    Train-Mae: 0.07998917251825333 |\n",
      "\n",
      "                    Average val loss: 0.531098484992981|\n",
      "                    Val-Mae: 0.07752729207277298\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 230\n",
      "Start training for stock: 4482\n",
      "\n",
      "                    Average train loss: 0.003653434216976166 | \n",
      "                    Train-Mae: 0.08843415975570679 |\n",
      "\n",
      "                    Average val loss: 0.013722549192607403|\n",
      "                    Val-Mae: 0.03928918391466141\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 231\n",
      "Start training for stock: 1799\n",
      "\n",
      "                    Average train loss: 8.464104495942593e-05 | \n",
      "                    Train-Mae: 0.05442807078361511 |\n",
      "\n",
      "                    Average val loss: 0.20460928976535797|\n",
      "                    Val-Mae: 0.06509927660226822\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 232\n",
      "Start training for stock: 9099\n",
      "\n",
      "                    Average train loss: 1.3051679125055672e-05 | \n",
      "                    Train-Mae: 0.04877140745520592 |\n",
      "\n",
      "                    Average val loss: 0.05466155707836151|\n",
      "                    Val-Mae: 0.037114936858415604\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 233\n",
      "Start training for stock: 9960\n",
      "\n",
      "                    Average train loss: 0.0016534736752510072 | \n",
      "                    Train-Mae: 0.03620775416493416 |\n",
      "\n",
      "                    Average val loss: 0.10497494786977768|\n",
      "                    Val-Mae: 0.04008518531918526\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 234\n",
      "Start training for stock: 8707\n",
      "\n",
      "                    Average train loss: 0.0012114472687244416 | \n",
      "                    Train-Mae: 0.029083114117383957 |\n",
      "\n",
      "                    Average val loss: 0.022990385070443153|\n",
      "                    Val-Mae: 0.026478437706828117\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 235\n",
      "Start training for stock: 6630\n",
      "\n",
      "                    Average train loss: 0.0014686577022075653 | \n",
      "                    Train-Mae: 0.028518525883555412 |\n",
      "\n",
      "                    Average val loss: 0.0018352136248722672|\n",
      "                    Val-Mae: 0.024517007172107697\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 236\n",
      "Start training for stock: 6564\n",
      "\n",
      "                    Average train loss: 0.0006011519953608513 | \n",
      "                    Train-Mae: 0.04045512527227402 |\n",
      "\n",
      "                    Average val loss: 0.013409414328634739|\n",
      "                    Val-Mae: 0.042454082518815994\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 237\n",
      "Start training for stock: 8070\n",
      "\n",
      "                    Average train loss: 0.0020269760489463806 | \n",
      "                    Train-Mae: 0.027029499411582947 |\n",
      "\n",
      "                    Average val loss: 0.0007302905432879925|\n",
      "                    Val-Mae: 0.017206571996212006\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 238\n",
      "Start training for stock: 4403\n",
      "\n",
      "                    Average train loss: 0.00016250275075435638 | \n",
      "                    Train-Mae: 0.06821267306804657 |\n",
      "\n",
      "                    Average val loss: 0.17277152836322784|\n",
      "                    Val-Mae: 0.05245933681726456\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 239\n",
      "Start training for stock: 7326\n",
      "\n",
      "                    Average train loss: 0.02900716781616211 | \n",
      "                    Train-Mae: 0.023766441270709038 |\n",
      "\n",
      "                    Average val loss: 0.020968981087207794|\n",
      "                    Val-Mae: 0.02831953577697277\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 240\n",
      "Start training for stock: 3946\n",
      "\n",
      "                    Average train loss: 0.002073344588279724 | \n",
      "                    Train-Mae: 0.02503923326730728 |\n",
      "\n",
      "                    Average val loss: 0.002064472297206521|\n",
      "                    Val-Mae: 0.016268791630864143\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 241\n",
      "Start training for stock: 4251\n",
      "\n",
      "                    Average train loss: 5.9234141372144225e-05 | \n",
      "                    Train-Mae: 0.0465349517762661 |\n",
      "\n",
      "                    Average val loss: 0.014865868724882603|\n",
      "                    Val-Mae: 0.04711229354143143\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 242\n",
      "Start training for stock: 6200\n",
      "\n",
      "                    Average train loss: 5.477556493133307e-05 | \n",
      "                    Train-Mae: 0.03867587447166443 |\n",
      "\n",
      "                    Average val loss: 0.004162580706179142|\n",
      "                    Val-Mae: 0.028954720124602318\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 243\n",
      "Start training for stock: 6050\n",
      "\n",
      "                    Average train loss: 0.0019405566155910492 | \n",
      "                    Train-Mae: 0.03793337196111679 |\n",
      "\n",
      "                    Average val loss: 0.005795655306428671|\n",
      "                    Val-Mae: 0.026868494227528572\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 244\n",
      "Start training for stock: 4323\n",
      "\n",
      "                    Average train loss: 0.00015198721550405025 | \n",
      "                    Train-Mae: 0.06167770177125931 |\n",
      "\n",
      "                    Average val loss: 0.029789477586746216|\n",
      "                    Val-Mae: 0.03984857723116875\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 245\n",
      "Start training for stock: 7172\n",
      "\n",
      "                    Average train loss: 0.00033100269734859467 | \n",
      "                    Train-Mae: 0.04285649582743645 |\n",
      "\n",
      "                    Average val loss: 0.0018950867233797908|\n",
      "                    Val-Mae: 0.022838160395622253\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 246\n",
      "Start training for stock: 3694\n",
      "\n",
      "                    Average train loss: 0.0024319323897361756 | \n",
      "                    Train-Mae: 0.04432138800621033 |\n",
      "\n",
      "                    Average val loss: 0.0006329066236503422|\n",
      "                    Val-Mae: 0.018310246989130974\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 247\n",
      "Start training for stock: 3371\n",
      "\n",
      "                    Average train loss: 0.0002009359560906887 | \n",
      "                    Train-Mae: 0.0315915085375309 |\n",
      "\n",
      "                    Average val loss: 0.0021111276000738144|\n",
      "                    Val-Mae: 0.022714754566550255\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 248\n",
      "Start training for stock: 5602\n",
      "\n",
      "                    Average train loss: 0.00021644946187734604 | \n",
      "                    Train-Mae: 0.044553421437740326 |\n",
      "\n",
      "                    Average val loss: 0.004193857777863741|\n",
      "                    Val-Mae: 0.015173126943409443\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 249\n",
      "Start training for stock: 2353\n",
      "\n",
      "                    Average train loss: 0.0014768654108047485 | \n",
      "                    Train-Mae: 0.022485921159386635 |\n",
      "\n",
      "                    Average val loss: 0.014282365329563618|\n",
      "                    Val-Mae: 0.02413199096918106\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 250\n",
      "Start training for stock: 9983\n",
      "\n",
      "                    Average train loss: 0.000648292601108551 | \n",
      "                    Train-Mae: 0.03133862465620041 |\n",
      "\n",
      "                    Average val loss: 0.006294003687798977|\n",
      "                    Val-Mae: 0.021048592403531075\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 251\n",
      "Start training for stock: 8699\n",
      "\n",
      "                    Average train loss: 0.003507576882839203 | \n",
      "                    Train-Mae: 0.025667432695627213 |\n",
      "\n",
      "                    Average val loss: 0.03267785161733627|\n",
      "                    Val-Mae: 0.03336883336305618\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 252\n",
      "Start training for stock: 8917\n",
      "\n",
      "                    Average train loss: 0.0008099089562892914 | \n",
      "                    Train-Mae: 0.08887436240911484 |\n",
      "\n",
      "                    Average val loss: 0.1991519182920456|\n",
      "                    Val-Mae: 0.05863773077726364\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 253\n",
      "Start training for stock: 8566\n",
      "\n",
      "                    Average train loss: 0.014223268032073974 | \n",
      "                    Train-Mae: 0.055719442665576935 |\n",
      "\n",
      "                    Average val loss: 0.0975564569234848|\n",
      "                    Val-Mae: 0.037729889154434204\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 254\n",
      "Start training for stock: 8864\n",
      "\n",
      "                    Average train loss: 0.0009012041240930558 | \n",
      "                    Train-Mae: 0.08048737794160843 |\n",
      "\n",
      "                    Average val loss: 0.5918601155281067|\n",
      "                    Val-Mae: 0.08388201892375946\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 255\n",
      "Start training for stock: 1885\n",
      "\n",
      "                    Average train loss: 0.015312341451644897 | \n",
      "                    Train-Mae: 0.030389048159122467 |\n",
      "\n",
      "                    Average val loss: 0.07984975725412369|\n",
      "                    Val-Mae: 0.03047529049217701\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 256\n",
      "Start training for stock: 9474\n",
      "\n",
      "                    Average train loss: 0.005006716251373291 | \n",
      "                    Train-Mae: 0.04513377323746681 |\n",
      "\n",
      "                    Average val loss: 0.04047738015651703|\n",
      "                    Val-Mae: 0.02795843780040741\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 257\n",
      "Start training for stock: 8283\n",
      "\n",
      "                    Average train loss: 0.001110440418124199 | \n",
      "                    Train-Mae: 0.04704152047634125 |\n",
      "\n",
      "                    Average val loss: 0.2853768765926361|\n",
      "                    Val-Mae: 0.05322504788637161\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 258\n",
      "Start training for stock: 7003\n",
      "\n",
      "                    Average train loss: 0.003875611424446106 | \n",
      "                    Train-Mae: 0.03523741289973259 |\n",
      "\n",
      "                    Average val loss: 0.00833726953715086|\n",
      "                    Val-Mae: 0.026399264112114906\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 259\n",
      "Start training for stock: 2659\n",
      "\n",
      "                    Average train loss: 0.0013854028284549713 | \n",
      "                    Train-Mae: 0.029152007773518562 |\n",
      "\n",
      "                    Average val loss: 0.016436085104942322|\n",
      "                    Val-Mae: 0.02106747403740883\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 260\n",
      "Start training for stock: 6465\n",
      "\n",
      "                    Average train loss: 0.0006023013964295387 | \n",
      "                    Train-Mae: 0.059908997267484665 |\n",
      "\n",
      "                    Average val loss: 0.1188141405582428|\n",
      "                    Val-Mae: 0.04009222239255905\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 261\n",
      "Start training for stock: 1431\n",
      "\n",
      "                    Average train loss: 0.0016867163777351379 | \n",
      "                    Train-Mae: 0.062341101467609406 |\n",
      "\n",
      "                    Average val loss: 0.0016159911174327135|\n",
      "                    Val-Mae: 0.01577683910727501\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 262\n",
      "Start training for stock: 3984\n",
      "\n",
      "                    Average train loss: 0.0010819110274314881 | \n",
      "                    Train-Mae: 0.032693639397621155 |\n",
      "\n",
      "                    Average val loss: 0.0014663194306194782|\n",
      "                    Val-Mae: 0.02412101812660694\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 263\n",
      "Start training for stock: 6638\n",
      "\n",
      "                    Average train loss: 9.030954912304878e-05 | \n",
      "                    Train-Mae: 0.0326521210372448 |\n",
      "\n",
      "                    Average val loss: 0.007265274878591299|\n",
      "                    Val-Mae: 0.02900460548698902\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 264\n",
      "Start training for stock: 3919\n",
      "\n",
      "                    Average train loss: 0.0006005970761179924 | \n",
      "                    Train-Mae: 0.043133269995450974 |\n",
      "\n",
      "                    Average val loss: 0.0014517232775688171|\n",
      "                    Val-Mae: 0.026098016649484634\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 265\n",
      "Start training for stock: 6815\n",
      "\n",
      "                    Average train loss: 0.0001195888314396143 | \n",
      "                    Train-Mae: 0.031175849959254265 |\n",
      "\n",
      "                    Average val loss: 0.0038249907083809376|\n",
      "                    Val-Mae: 0.023662419989705086\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 266\n",
      "Start training for stock: 6941\n",
      "\n",
      "                    Average train loss: 0.0026051825284957885 | \n",
      "                    Train-Mae: 0.04415625333786011 |\n",
      "\n",
      "                    Average val loss: 0.07789639383554459|\n",
      "                    Val-Mae: 0.045295000076293945\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 267\n",
      "Start training for stock: 9832\n",
      "\n",
      "                    Average train loss: 0.01458475947380066 | \n",
      "                    Train-Mae: 0.029410699382424355 |\n",
      "\n",
      "                    Average val loss: 0.007160865236073732|\n",
      "                    Val-Mae: 0.016083911061286926\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 268\n",
      "Start training for stock: 8242\n",
      "\n",
      "                    Average train loss: 0.007246041297912597 | \n",
      "                    Train-Mae: 0.04055531695485115 |\n",
      "\n",
      "                    Average val loss: 0.04110494256019592|\n",
      "                    Val-Mae: 0.03559383377432823\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 269\n",
      "Start training for stock: 9041\n",
      "\n",
      "                    Average train loss: 0.00035333465784788133 | \n",
      "                    Train-Mae: 0.03264247626066208 |\n",
      "\n",
      "                    Average val loss: 0.01723317615687847|\n",
      "                    Val-Mae: 0.02427048236131668\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 270\n",
      "Start training for stock: 4185\n",
      "\n",
      "                    Average train loss: 0.0012643562257289886 | \n",
      "                    Train-Mae: 0.02880227565765381 |\n",
      "\n",
      "                    Average val loss: 0.021298788487911224|\n",
      "                    Val-Mae: 0.02739470638334751\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 271\n",
      "Start training for stock: 4719\n",
      "\n",
      "                    Average train loss: 5.55094052106142e-05 | \n",
      "                    Train-Mae: 0.046661656349897385 |\n",
      "\n",
      "                    Average val loss: 0.09847414493560791|\n",
      "                    Val-Mae: 0.041699886322021484\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 272\n",
      "Start training for stock: 5185\n",
      "\n",
      "                    Average train loss: 0.005566632747650147 | \n",
      "                    Train-Mae: 0.02388950064778328 |\n",
      "\n",
      "                    Average val loss: 0.007596135139465332|\n",
      "                    Val-Mae: 0.029047781601548195\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 273\n",
      "Start training for stock: 4318\n",
      "\n",
      "                    Average train loss: 0.0039061239361763 | \n",
      "                    Train-Mae: 0.061569761484861374 |\n",
      "\n",
      "                    Average val loss: 0.012743781320750713|\n",
      "                    Val-Mae: 0.02420584298670292\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 274\n",
      "Start training for stock: 4061\n",
      "\n",
      "                    Average train loss: 0.0029382556676864624 | \n",
      "                    Train-Mae: 0.051886048167943954 |\n",
      "\n",
      "                    Average val loss: 0.01576567068696022|\n",
      "                    Val-Mae: 0.027841664850711823\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 275\n",
      "Start training for stock: 6238\n",
      "\n",
      "                    Average train loss: 0.0007313399761915206 | \n",
      "                    Train-Mae: 0.02942553721368313 |\n",
      "\n",
      "                    Average val loss: 0.005638863425701857|\n",
      "                    Val-Mae: 0.027009982615709305\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 276\n",
      "Start training for stock: 4718\n",
      "\n",
      "                    Average train loss: 0.0035962006449699402 | \n",
      "                    Train-Mae: 0.032003723084926605 |\n",
      "\n",
      "                    Average val loss: 0.04708893224596977|\n",
      "                    Val-Mae: 0.028896871954202652\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 277\n",
      "Start training for stock: 2612\n",
      "\n",
      "                    Average train loss: 0.003102717399597168 | \n",
      "                    Train-Mae: 0.02247718721628189 |\n",
      "\n",
      "                    Average val loss: 0.018782613798975945|\n",
      "                    Val-Mae: 0.016926957294344902\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 278\n",
      "Start training for stock: 8411\n",
      "\n",
      "                    Average train loss: 0.00018854675814509393 | \n",
      "                    Train-Mae: 0.039086952805519104 |\n",
      "\n",
      "                    Average val loss: 0.010058406740427017|\n",
      "                    Val-Mae: 0.01894041709601879\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 279\n",
      "Start training for stock: 6330\n",
      "\n",
      "                    Average train loss: 0.0011214494705200195 | \n",
      "                    Train-Mae: 0.030395591631531715 |\n",
      "\n",
      "                    Average val loss: 0.00223514880053699|\n",
      "                    Val-Mae: 0.02677532099187374\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 280\n",
      "Start training for stock: 7914\n",
      "\n",
      "                    Average train loss: 0.0022725412249565125 | \n",
      "                    Train-Mae: 0.030477087944746017 |\n",
      "\n",
      "                    Average val loss: 0.0037290819454938173|\n",
      "                    Val-Mae: 0.017672421410679817\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 281\n",
      "Start training for stock: 6800\n",
      "\n",
      "                    Average train loss: 0.00028699664399027823 | \n",
      "                    Train-Mae: 0.07146328687667847 |\n",
      "\n",
      "                    Average val loss: 0.2648561894893646|\n",
      "                    Val-Mae: 0.06153920665383339\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 282\n",
      "Start training for stock: 7955\n",
      "\n",
      "                    Average train loss: 0.00711645245552063 | \n",
      "                    Train-Mae: 0.04257062450051308 |\n",
      "\n",
      "                    Average val loss: 0.05074580758810043|\n",
      "                    Val-Mae: 0.031636543571949005\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 283\n",
      "Start training for stock: 2268\n",
      "\n",
      "                    Average train loss: 1.8250731518492102e-05 | \n",
      "                    Train-Mae: 0.07637955993413925 |\n",
      "\n",
      "                    Average val loss: 0.03573226556181908|\n",
      "                    Val-Mae: 0.034987688064575195\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 284\n",
      "Start training for stock: 6235\n",
      "\n",
      "                    Average train loss: 0.002402520626783371 | \n",
      "                    Train-Mae: 0.05258145183324814 |\n",
      "\n",
      "                    Average val loss: 0.003999877721071243|\n",
      "                    Val-Mae: 0.022038659080863\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 285\n",
      "Start training for stock: 4554\n",
      "\n",
      "                    Average train loss: 0.0007133758813142777 | \n",
      "                    Train-Mae: 0.030765654519200325 |\n",
      "\n",
      "                    Average val loss: 0.0028730854392051697|\n",
      "                    Val-Mae: 0.015397228300571442\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 286\n",
      "Start training for stock: 4819\n",
      "\n",
      "                    Average train loss: 0.00011054910719394684 | \n",
      "                    Train-Mae: 0.051701948046684265 |\n",
      "\n",
      "                    Average val loss: 0.0008963642758317292|\n",
      "                    Val-Mae: 0.018441081047058105\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 287\n",
      "Start training for stock: 4540\n",
      "\n",
      "                    Average train loss: 0.0007380326092243194 | \n",
      "                    Train-Mae: 0.03066769428551197 |\n",
      "\n",
      "                    Average val loss: 0.00044885891838930547|\n",
      "                    Val-Mae: 0.01310332864522934\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 288\n",
      "Start training for stock: 7419\n",
      "\n",
      "                    Average train loss: 6.350622978061437e-05 | \n",
      "                    Train-Mae: 0.02904263325035572 |\n",
      "\n",
      "                    Average val loss: 0.0012502920581027865|\n",
      "                    Val-Mae: 0.01728477142751217\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 289\n",
      "Start training for stock: 1871\n",
      "\n",
      "                    Average train loss: 0.002225889414548874 | \n",
      "                    Train-Mae: 0.031168192625045776 |\n",
      "\n",
      "                    Average val loss: 0.010327610187232494|\n",
      "                    Val-Mae: 0.020127469673752785\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 290\n",
      "Start training for stock: 2211\n",
      "\n",
      "                    Average train loss: 0.0025925162434577943 | \n",
      "                    Train-Mae: 0.027312658727169037 |\n",
      "\n",
      "                    Average val loss: 0.0016217469237744808|\n",
      "                    Val-Mae: 0.012007440440356731\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 291\n",
      "Start training for stock: 8336\n",
      "\n",
      "                    Average train loss: 0.0005662764236330986 | \n",
      "                    Train-Mae: 0.043649766594171524 |\n",
      "\n",
      "                    Average val loss: 0.0016681436682119966|\n",
      "                    Val-Mae: 0.016069628298282623\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 292\n",
      "Start training for stock: 6962\n",
      "\n",
      "                    Average train loss: 0.00017359280958771704 | \n",
      "                    Train-Mae: 0.048076409846544266 |\n",
      "\n",
      "                    Average val loss: 0.019689161330461502|\n",
      "                    Val-Mae: 0.04291292652487755\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 293\n",
      "Start training for stock: 2484\n",
      "\n",
      "                    Average train loss: 0.00029658451676368714 | \n",
      "                    Train-Mae: 0.046525515615940094 |\n",
      "\n",
      "                    Average val loss: 0.001363679999485612|\n",
      "                    Val-Mae: 0.02755759097635746\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 294\n",
      "Start training for stock: 5951\n",
      "\n",
      "                    Average train loss: 0.00038908973336219786 | \n",
      "                    Train-Mae: 0.057168565690517426 |\n",
      "\n",
      "                    Average val loss: 0.027196533977985382|\n",
      "                    Val-Mae: 0.024778256192803383\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 295\n",
      "Start training for stock: 4186\n",
      "\n",
      "                    Average train loss: 0.0021095699071884155 | \n",
      "                    Train-Mae: 0.04268106073141098 |\n",
      "\n",
      "                    Average val loss: 0.014683578163385391|\n",
      "                    Val-Mae: 0.027209842577576637\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 296\n",
      "Start training for stock: 6141\n",
      "\n",
      "                    Average train loss: 0.0005941666662693023 | \n",
      "                    Train-Mae: 0.03124481439590454 |\n",
      "\n",
      "                    Average val loss: 0.048112399876117706|\n",
      "                    Val-Mae: 0.03431938588619232\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 297\n",
      "Start training for stock: 4659\n",
      "\n",
      "                    Average train loss: 0.0015309350192546844 | \n",
      "                    Train-Mae: 0.037462811917066574 |\n",
      "\n",
      "                    Average val loss: 0.045074399560689926|\n",
      "                    Val-Mae: 0.031204212456941605\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 298\n",
      "Start training for stock: 7893\n",
      "\n",
      "                    Average train loss: 2.6497296057641507e-05 | \n",
      "                    Train-Mae: 0.0455499105155468 |\n",
      "\n",
      "                    Average val loss: 0.006107676774263382|\n",
      "                    Val-Mae: 0.020036917179822922\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 299\n",
      "Start training for stock: 4951\n",
      "\n",
      "                    Average train loss: 0.007741077542304992 | \n",
      "                    Train-Mae: 0.03726789727807045 |\n",
      "\n",
      "                    Average val loss: 0.05639643594622612|\n",
      "                    Val-Mae: 0.02824433706700802\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 300\n",
      "Start training for stock: 7744\n",
      "\n",
      "                    Average train loss: 4.219662398099899e-05 | \n",
      "                    Train-Mae: 0.056122612208127975 |\n",
      "\n",
      "                    Average val loss: 0.02615884691476822|\n",
      "                    Val-Mae: 0.031198516488075256\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 301\n",
      "Start training for stock: 6340\n",
      "\n",
      "                    Average train loss: 0.00013782615773379802 | \n",
      "                    Train-Mae: 0.029219986870884895 |\n",
      "\n",
      "                    Average val loss: 0.0035826540552079678|\n",
      "                    Val-Mae: 0.021019594743847847\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 302\n",
      "Start training for stock: 7047\n",
      "\n",
      "                    Average train loss: 0.0010808216780424118 | \n",
      "                    Train-Mae: 0.03462619334459305 |\n",
      "\n",
      "                    Average val loss: 0.021310457959771156|\n",
      "                    Val-Mae: 0.04838545620441437\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 303\n",
      "Start training for stock: 4534\n",
      "\n",
      "                    Average train loss: 1.186604262329638e-05 | \n",
      "                    Train-Mae: 0.03899265080690384 |\n",
      "\n",
      "                    Average val loss: 0.002830870682373643|\n",
      "                    Val-Mae: 0.0156702920794487\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 304\n",
      "Start training for stock: 6809\n",
      "\n",
      "                    Average train loss: 5.134532693773508e-05 | \n",
      "                    Train-Mae: 0.044189371168613434 |\n",
      "\n",
      "                    Average val loss: 0.06108008325099945|\n",
      "                    Val-Mae: 0.033801399171352386\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 305\n",
      "Start training for stock: 9622\n",
      "\n",
      "                    Average train loss: 0.007373859286308289 | \n",
      "                    Train-Mae: 0.031199166551232338 |\n",
      "\n",
      "                    Average val loss: 0.0006656124605797231|\n",
      "                    Val-Mae: 0.013572905212640762\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 306\n",
      "Start training for stock: 3401\n",
      "\n",
      "                    Average train loss: 1.6028183745220302e-05 | \n",
      "                    Train-Mae: 0.02704714983701706 |\n",
      "\n",
      "                    Average val loss: 0.00800417736172676|\n",
      "                    Val-Mae: 0.018078962340950966\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 307\n",
      "Start training for stock: 2588\n",
      "\n",
      "                    Average train loss: 0.0014360593259334564 | \n",
      "                    Train-Mae: 0.03659573197364807 |\n",
      "\n",
      "                    Average val loss: 0.0010774035472422838|\n",
      "                    Val-Mae: 0.021506622433662415\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 308\n",
      "Start training for stock: 8601\n",
      "\n",
      "                    Average train loss: 0.0013390173017978667 | \n",
      "                    Train-Mae: 0.024116605520248413 |\n",
      "\n",
      "                    Average val loss: 0.020344529300928116|\n",
      "                    Val-Mae: 0.02438187412917614\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 309\n",
      "Start training for stock: 8697\n",
      "\n",
      "                    Average train loss: 0.00022236302495002748 | \n",
      "                    Train-Mae: 0.055002953857183456 |\n",
      "\n",
      "                    Average val loss: 0.27491217851638794|\n",
      "                    Val-Mae: 0.05954911187291145\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 310\n",
      "Start training for stock: 1808\n",
      "\n",
      "                    Average train loss: 7.661962881684303e-05 | \n",
      "                    Train-Mae: 0.025875678285956383 |\n",
      "\n",
      "                    Average val loss: 0.21767400205135345|\n",
      "                    Val-Mae: 0.04832842946052551\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 311\n",
      "Start training for stock: 6459\n",
      "\n",
      "                    Average train loss: 0.00012111164629459381 | \n",
      "                    Train-Mae: 0.04705715924501419 |\n",
      "\n",
      "                    Average val loss: 0.10316675156354904|\n",
      "                    Val-Mae: 0.03773868829011917\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 312\n",
      "Start training for stock: 1898\n",
      "\n",
      "                    Average train loss: 6.042508408427239e-05 | \n",
      "                    Train-Mae: 0.026918241754174232 |\n",
      "\n",
      "                    Average val loss: 0.12941086292266846|\n",
      "                    Val-Mae: 0.037689387798309326\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 313\n",
      "Start training for stock: 6315\n",
      "\n",
      "                    Average train loss: 0.004083532989025116 | \n",
      "                    Train-Mae: 0.05363304167985916 |\n",
      "\n",
      "                    Average val loss: 0.34605246782302856|\n",
      "                    Val-Mae: 0.07612011581659317\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 314\n",
      "Start training for stock: 8331\n",
      "\n",
      "                    Average train loss: 0.00464724212884903 | \n",
      "                    Train-Mae: 0.03474901244044304 |\n",
      "\n",
      "                    Average val loss: 0.0031955463346093893|\n",
      "                    Val-Mae: 0.020651601254940033\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 315\n",
      "Start training for stock: 6140\n",
      "\n",
      "                    Average train loss: 0.0008615949004888534 | \n",
      "                    Train-Mae: 0.03522418811917305 |\n",
      "\n",
      "                    Average val loss: 0.011358530260622501|\n",
      "                    Val-Mae: 0.026918679475784302\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 316\n",
      "Start training for stock: 2497\n",
      "\n",
      "                    Average train loss: 0.0008502695709466934 | \n",
      "                    Train-Mae: 0.040260713547468185 |\n",
      "\n",
      "                    Average val loss: 0.013278443366289139|\n",
      "                    Val-Mae: 0.024566859006881714\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 317\n",
      "Start training for stock: 3431\n",
      "\n",
      "                    Average train loss: 0.0013589221239089966 | \n",
      "                    Train-Mae: 0.033881284296512604 |\n",
      "\n",
      "                    Average val loss: 0.0017146558966487646|\n",
      "                    Val-Mae: 0.017330706119537354\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 318\n",
      "Start training for stock: 7820\n",
      "\n",
      "                    Average train loss: 0.0003113598749041557 | \n",
      "                    Train-Mae: 0.06010010838508606 |\n",
      "\n",
      "                    Average val loss: 0.02664133906364441|\n",
      "                    Val-Mae: 0.031666889786720276\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 319\n",
      "Start training for stock: 8570\n",
      "\n",
      "                    Average train loss: 0.00010377050377428531 | \n",
      "                    Train-Mae: 0.04446224868297577 |\n",
      "\n",
      "                    Average val loss: 0.003851961810141802|\n",
      "                    Val-Mae: 0.021330157294869423\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 320\n",
      "Start training for stock: 4479\n",
      "\n",
      "                    Average train loss: 0.0009767654538154601 | \n",
      "                    Train-Mae: 0.0561247281730175 |\n",
      "\n",
      "                    Average val loss: 0.0011118812253698707|\n",
      "                    Val-Mae: 0.02336658164858818\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 321\n",
      "Start training for stock: 7856\n",
      "\n",
      "                    Average train loss: 0.0019661059975624087 | \n",
      "                    Train-Mae: 0.02374844439327717 |\n",
      "\n",
      "                    Average val loss: 0.010391264222562313|\n",
      "                    Val-Mae: 0.017154527828097343\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 322\n",
      "Start training for stock: 1377\n",
      "\n",
      "                    Average train loss: 0.0028304561972618105 | \n",
      "                    Train-Mae: 0.02786097675561905 |\n",
      "\n",
      "                    Average val loss: 0.0074882907792925835|\n",
      "                    Val-Mae: 0.01707756705582142\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 323\n",
      "Start training for stock: 1879\n",
      "\n",
      "                    Average train loss: 8.231183513998986e-05 | \n",
      "                    Train-Mae: 0.042026665061712265 |\n",
      "\n",
      "                    Average val loss: 0.012787736020982265|\n",
      "                    Val-Mae: 0.02232208102941513\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 324\n",
      "Start training for stock: 9020\n",
      "\n",
      "                    Average train loss: 0.0005760047957301139 | \n",
      "                    Train-Mae: 0.06748424470424652 |\n",
      "\n",
      "                    Average val loss: 0.18087886273860931|\n",
      "                    Val-Mae: 0.05130337178707123\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 325\n",
      "Start training for stock: 8005\n",
      "\n",
      "                    Average train loss: 0.00939764380455017 | \n",
      "                    Train-Mae: 0.04328522831201553 |\n",
      "\n",
      "                    Average val loss: 0.05941050127148628|\n",
      "                    Val-Mae: 0.038552504032850266\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 326\n",
      "Start training for stock: 5703\n",
      "\n",
      "                    Average train loss: 3.9784638211131096e-05 | \n",
      "                    Train-Mae: 0.05038625746965408 |\n",
      "\n",
      "                    Average val loss: 0.0697735920548439|\n",
      "                    Val-Mae: 0.03714921697974205\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 327\n",
      "Start training for stock: 7725\n",
      "\n",
      "                    Average train loss: 0.0015229147672653199 | \n",
      "                    Train-Mae: 0.040030576288700104 |\n",
      "\n",
      "                    Average val loss: 0.01392682921141386|\n",
      "                    Val-Mae: 0.0302048921585083\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 328\n",
      "Start training for stock: 7337\n",
      "\n",
      "                    Average train loss: 0.0009280193597078323 | \n",
      "                    Train-Mae: 0.038127392530441284 |\n",
      "\n",
      "                    Average val loss: 0.0003992825513705611|\n",
      "                    Val-Mae: 0.01689187064766884\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 329\n",
      "Start training for stock: 1965\n",
      "\n",
      "                    Average train loss: 0.001950806826353073 | \n",
      "                    Train-Mae: 0.05261627957224846 |\n",
      "\n",
      "                    Average val loss: 0.026009175926446915|\n",
      "                    Val-Mae: 0.018039703369140625\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 330\n",
      "Start training for stock: 6856\n",
      "\n",
      "                    Average train loss: 0.003159669041633606 | \n",
      "                    Train-Mae: 0.0700874850153923 |\n",
      "\n",
      "                    Average val loss: 0.001578802359290421|\n",
      "                    Val-Mae: 0.02080174908041954\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 331\n",
      "Start training for stock: 8848\n",
      "\n",
      "                    Average train loss: 3.430218668654561e-05 | \n",
      "                    Train-Mae: 0.03687076270580292 |\n",
      "\n",
      "                    Average val loss: 0.0011119829723611474|\n",
      "                    Val-Mae: 0.022425564005970955\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 332\n",
      "Start training for stock: 8358\n",
      "\n",
      "                    Average train loss: 0.00013436274603009223 | \n",
      "                    Train-Mae: 0.020861897617578506 |\n",
      "\n",
      "                    Average val loss: 0.0007305989856831729|\n",
      "                    Val-Mae: 0.017700526863336563\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 333\n",
      "Start training for stock: 6363\n",
      "\n",
      "                    Average train loss: 0.001471720188856125 | \n",
      "                    Train-Mae: 0.05274089425802231 |\n",
      "\n",
      "                    Average val loss: 0.014980574138462543|\n",
      "                    Val-Mae: 0.021221891045570374\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 334\n",
      "Start training for stock: 5105\n",
      "\n",
      "                    Average train loss: 0.010553605556488037 | \n",
      "                    Train-Mae: 0.058059267699718475 |\n",
      "\n",
      "                    Average val loss: 0.019514162093400955|\n",
      "                    Val-Mae: 0.02602037973701954\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 335\n",
      "Start training for stock: 2871\n",
      "\n",
      "                    Average train loss: 0.0006687453389167785 | \n",
      "                    Train-Mae: 0.037236329168081284 |\n",
      "\n",
      "                    Average val loss: 0.04449034109711647|\n",
      "                    Val-Mae: 0.02855280600488186\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 336\n",
      "Start training for stock: 4921\n",
      "\n",
      "                    Average train loss: 0.0009058081358671188 | \n",
      "                    Train-Mae: 0.03019562177360058 |\n",
      "\n",
      "                    Average val loss: 0.0005601984448730946|\n",
      "                    Val-Mae: 0.01513211615383625\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 337\n",
      "Start training for stock: 2193\n",
      "\n",
      "                    Average train loss: 0.0022397787868976594 | \n",
      "                    Train-Mae: 0.029638580977916718 |\n",
      "\n",
      "                    Average val loss: 0.004638936370611191|\n",
      "                    Val-Mae: 0.021710332483053207\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 338\n",
      "Start training for stock: 7839\n",
      "\n",
      "                    Average train loss: 0.005208796858787537 | \n",
      "                    Train-Mae: 0.03835226222872734 |\n",
      "\n",
      "                    Average val loss: 0.0016559953801333904|\n",
      "                    Val-Mae: 0.019026271998882294\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 339\n",
      "Start training for stock: 2220\n",
      "\n",
      "                    Average train loss: 0.002418234944343567 | \n",
      "                    Train-Mae: 0.03792519494891167 |\n",
      "\n",
      "                    Average val loss: 0.00017716969887260348|\n",
      "                    Val-Mae: 0.009706183336675167\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 340\n",
      "Start training for stock: 9632\n",
      "\n",
      "                    Average train loss: 0.0002614860609173775 | \n",
      "                    Train-Mae: 0.024065697565674782 |\n",
      "\n",
      "                    Average val loss: 0.00021000548440497369|\n",
      "                    Val-Mae: 0.008152126334607601\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 341\n",
      "Start training for stock: 7483\n",
      "\n",
      "                    Average train loss: 0.0009291093796491623 | \n",
      "                    Train-Mae: 0.04464695602655411 |\n",
      "\n",
      "                    Average val loss: 0.0029622220899909735|\n",
      "                    Val-Mae: 0.016387250274419785\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 342\n",
      "Start training for stock: 4763\n",
      "\n",
      "                    Average train loss: 0.0008029614388942719 | \n",
      "                    Train-Mae: 0.06342842429876328 |\n",
      "\n",
      "                    Average val loss: 0.043916355818510056|\n",
      "                    Val-Mae: 0.039194244891405106\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 343\n",
      "Start training for stock: 6569\n",
      "\n",
      "                    Average train loss: 0.0023421911895275117 | \n",
      "                    Train-Mae: 0.025849612429738045 |\n",
      "\n",
      "                    Average val loss: 0.0010715874377638102|\n",
      "                    Val-Mae: 0.017730720341205597\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 344\n",
      "Start training for stock: 4923\n",
      "\n",
      "                    Average train loss: 0.0060360640287399295 | \n",
      "                    Train-Mae: 0.06617053598165512 |\n",
      "\n",
      "                    Average val loss: 0.00028094666777178645|\n",
      "                    Val-Mae: 0.012179051525890827\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 345\n",
      "Start training for stock: 9719\n",
      "\n",
      "                    Average train loss: 0.002181995362043381 | \n",
      "                    Train-Mae: 0.029417650774121284 |\n",
      "\n",
      "                    Average val loss: 0.02521233819425106|\n",
      "                    Val-Mae: 0.030817026272416115\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 346\n",
      "Start training for stock: 8750\n",
      "\n",
      "                    Average train loss: 0.0007181773334741593 | \n",
      "                    Train-Mae: 0.04423545300960541 |\n",
      "\n",
      "                    Average val loss: 0.012262373231351376|\n",
      "                    Val-Mae: 0.024006741121411324\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 347\n",
      "Start training for stock: 1662\n",
      "\n",
      "                    Average train loss: 0.0010339288413524627 | \n",
      "                    Train-Mae: 0.03263825923204422 |\n",
      "\n",
      "                    Average val loss: 0.0009882755111902952|\n",
      "                    Val-Mae: 0.01846611313521862\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 348\n",
      "Start training for stock: 7944\n",
      "\n",
      "                    Average train loss: 8.948496542870998e-05 | \n",
      "                    Train-Mae: 0.03273780271410942 |\n",
      "\n",
      "                    Average val loss: 0.0005881234537810087|\n",
      "                    Val-Mae: 0.020870771259069443\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 349\n",
      "Start training for stock: 5444\n",
      "\n",
      "                    Average train loss: 0.0010340315848588943 | \n",
      "                    Train-Mae: 0.03645646572113037 |\n",
      "\n",
      "                    Average val loss: 0.0015202549984678626|\n",
      "                    Val-Mae: 0.02163761854171753\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 350\n",
      "Start training for stock: 1870\n",
      "\n",
      "                    Average train loss: 0.003536345660686493 | \n",
      "                    Train-Mae: 0.05232933163642883 |\n",
      "\n",
      "                    Average val loss: 0.0006980953039601445|\n",
      "                    Val-Mae: 0.015852004289627075\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 351\n",
      "Start training for stock: 9601\n",
      "\n",
      "                    Average train loss: 0.0013721604645252228 | \n",
      "                    Train-Mae: 0.038039885461330414 |\n",
      "\n",
      "                    Average val loss: 0.005566500127315521|\n",
      "                    Val-Mae: 0.023402594029903412\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 352\n",
      "Start training for stock: 7718\n",
      "\n",
      "                    Average train loss: 9.609885513782501e-05 | \n",
      "                    Train-Mae: 0.03103392943739891 |\n",
      "\n",
      "                    Average val loss: 0.02917022816836834|\n",
      "                    Val-Mae: 0.027889275923371315\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 353\n",
      "Start training for stock: 4912\n",
      "\n",
      "                    Average train loss: 0.000693608894944191 | \n",
      "                    Train-Mae: 0.03158517926931381 |\n",
      "\n",
      "                    Average val loss: 0.02854972891509533|\n",
      "                    Val-Mae: 0.024209538474678993\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 354\n",
      "Start training for stock: 5991\n",
      "\n",
      "                    Average train loss: 0.00048351701349020004 | \n",
      "                    Train-Mae: 0.0339604876935482 |\n",
      "\n",
      "                    Average val loss: 0.0008522222633473575|\n",
      "                    Val-Mae: 0.017027046531438828\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 355\n",
      "Start training for stock: 6777\n",
      "\n",
      "                    Average train loss: 0.00013291064649820328 | \n",
      "                    Train-Mae: 0.03830348700284958 |\n",
      "\n",
      "                    Average val loss: 0.0015311299357563257|\n",
      "                    Val-Mae: 0.018735384568572044\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 356\n",
      "Start training for stock: 7060\n",
      "\n",
      "                    Average train loss: 0.00011449697427451611 | \n",
      "                    Train-Mae: 0.024389339610934258 |\n",
      "\n",
      "                    Average val loss: 0.001542675425298512|\n",
      "                    Val-Mae: 0.02778233028948307\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 357\n",
      "Start training for stock: 9728\n",
      "\n",
      "                    Average train loss: 0.001061943992972374 | \n",
      "                    Train-Mae: 0.037079378962516785 |\n",
      "\n",
      "                    Average val loss: 0.001300317351706326|\n",
      "                    Val-Mae: 0.014663954265415668\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 358\n",
      "Start training for stock: 1332\n",
      "\n",
      "                    Average train loss: 1.6223053680732846e-05 | \n",
      "                    Train-Mae: 0.02633494697511196 |\n",
      "\n",
      "                    Average val loss: 0.0013529600109905005|\n",
      "                    Val-Mae: 0.01578621380031109\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 359\n",
      "Start training for stock: 4771\n",
      "\n",
      "                    Average train loss: 4.5185191556811336e-05 | \n",
      "                    Train-Mae: 0.050586994737386703 |\n",
      "\n",
      "                    Average val loss: 0.04401577636599541|\n",
      "                    Val-Mae: 0.04479534551501274\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 360\n",
      "Start training for stock: 7775\n",
      "\n",
      "                    Average train loss: 0.020976624488830566 | \n",
      "                    Train-Mae: 0.058836884796619415 |\n",
      "\n",
      "                    Average val loss: 0.07266757637262344|\n",
      "                    Val-Mae: 0.032812055200338364\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 361\n",
      "Start training for stock: 2117\n",
      "\n",
      "                    Average train loss: 2.5197432842105626e-05 | \n",
      "                    Train-Mae: 0.022751731798052788 |\n",
      "\n",
      "                    Average val loss: 0.05609049275517464|\n",
      "                    Val-Mae: 0.024250883609056473\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 362\n",
      "Start training for stock: 6869\n",
      "\n",
      "                    Average train loss: 0.0029398629069328306 | \n",
      "                    Train-Mae: 0.04092158377170563 |\n",
      "\n",
      "                    Average val loss: 0.010232651606202126|\n",
      "                    Val-Mae: 0.027502015233039856\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 363\n",
      "Start training for stock: 6364\n",
      "\n",
      "                    Average train loss: 0.0012379416823387146 | \n",
      "                    Train-Mae: 0.04578313231468201 |\n",
      "\n",
      "                    Average val loss: 0.020091969519853592|\n",
      "                    Val-Mae: 0.026034563779830933\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 364\n",
      "Start training for stock: 3636\n",
      "\n",
      "                    Average train loss: 0.0018240590393543243 | \n",
      "                    Train-Mae: 0.0238130372017622 |\n",
      "\n",
      "                    Average val loss: 0.002507242374122143|\n",
      "                    Val-Mae: 0.015922335907816887\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 365\n",
      "Start training for stock: 7844\n",
      "\n",
      "                    Average train loss: 0.004030303061008453 | \n",
      "                    Train-Mae: 0.02988806553184986 |\n",
      "\n",
      "                    Average val loss: 0.06559178233146667|\n",
      "                    Val-Mae: 0.033737558871507645\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 366\n",
      "Start training for stock: 1945\n",
      "\n",
      "                    Average train loss: 0.007769654393196106 | \n",
      "                    Train-Mae: 0.04287853464484215 |\n",
      "\n",
      "                    Average val loss: 0.0041038342751562595|\n",
      "                    Val-Mae: 0.01895284652709961\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 367\n",
      "Start training for stock: 3333\n",
      "\n",
      "                    Average train loss: 0.000446605309844017 | \n",
      "                    Train-Mae: 0.026518546044826508 |\n",
      "\n",
      "                    Average val loss: 0.0002515439409762621|\n",
      "                    Val-Mae: 0.010909303091466427\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 368\n",
      "Start training for stock: 6845\n",
      "\n",
      "                    Average train loss: 1.799030927941203e-05 | \n",
      "                    Train-Mae: 0.03399975597858429 |\n",
      "\n",
      "                    Average val loss: 0.008651165291666985|\n",
      "                    Val-Mae: 0.024207795038819313\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 369\n",
      "Start training for stock: 7733\n",
      "\n",
      "                    Average train loss: 0.00041932761669158933 | \n",
      "                    Train-Mae: 0.05352119728922844 |\n",
      "\n",
      "                    Average val loss: 0.004632563330233097|\n",
      "                    Val-Mae: 0.021456647664308548\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 370\n",
      "Start training for stock: 3104\n",
      "\n",
      "                    Average train loss: 9.876216761767865e-05 | \n",
      "                    Train-Mae: 0.04344034940004349 |\n",
      "\n",
      "                    Average val loss: 0.08455878496170044|\n",
      "                    Val-Mae: 0.03998103737831116\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 371\n",
      "Start training for stock: 4973\n",
      "\n",
      "                    Average train loss: 0.006447165608406067 | \n",
      "                    Train-Mae: 0.0694933608174324 |\n",
      "\n",
      "                    Average val loss: 0.2152298092842102|\n",
      "                    Val-Mae: 0.05247486010193825\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 372\n",
      "Start training for stock: 3097\n",
      "\n",
      "                    Average train loss: 0.0011714348942041396 | \n",
      "                    Train-Mae: 0.03662317246198654 |\n",
      "\n",
      "                    Average val loss: 0.04320192337036133|\n",
      "                    Val-Mae: 0.03582000359892845\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 373\n",
      "Start training for stock: 4628\n",
      "\n",
      "                    Average train loss: 0.0004953696951270104 | \n",
      "                    Train-Mae: 0.09821270406246185 |\n",
      "\n",
      "                    Average val loss: 0.0046413061209023|\n",
      "                    Val-Mae: 0.03894598409533501\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 374\n",
      "Start training for stock: 7322\n",
      "\n",
      "                    Average train loss: 7.09238275885582e-05 | \n",
      "                    Train-Mae: 0.01947949081659317 |\n",
      "\n",
      "                    Average val loss: 0.009689795784652233|\n",
      "                    Val-Mae: 0.016536125913262367\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 375\n",
      "Start training for stock: 8129\n",
      "\n",
      "                    Average train loss: 0.0003425000607967377 | \n",
      "                    Train-Mae: 0.036293160170316696 |\n",
      "\n",
      "                    Average val loss: 0.020787512883543968|\n",
      "                    Val-Mae: 0.022926973178982735\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 376\n",
      "Start training for stock: 3708\n",
      "\n",
      "                    Average train loss: 2.7282019145786763e-05 | \n",
      "                    Train-Mae: 0.037890877574682236 |\n",
      "\n",
      "                    Average val loss: 0.004200208466500044|\n",
      "                    Val-Mae: 0.02039049006998539\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 377\n",
      "Start training for stock: 3561\n",
      "\n",
      "                    Average train loss: 0.00032295446842908857 | \n",
      "                    Train-Mae: 0.03475737199187279 |\n",
      "\n",
      "                    Average val loss: 0.001754273776896298|\n",
      "                    Val-Mae: 0.01621062308549881\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 378\n",
      "Start training for stock: 6481\n",
      "\n",
      "                    Average train loss: 0.0010253486782312393 | \n",
      "                    Train-Mae: 0.036331113427877426 |\n",
      "\n",
      "                    Average val loss: 0.00865983311086893|\n",
      "                    Val-Mae: 0.025366757065057755\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 379\n",
      "Start training for stock: 2153\n",
      "\n",
      "                    Average train loss: 0.0008436234295368195 | \n",
      "                    Train-Mae: 0.034063227474689484 |\n",
      "\n",
      "                    Average val loss: 0.0007557606440968812|\n",
      "                    Val-Mae: 0.01621818356215954\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 380\n",
      "Start training for stock: 5463\n",
      "\n",
      "                    Average train loss: 0.00036379121243953707 | \n",
      "                    Train-Mae: 0.03469747304916382 |\n",
      "\n",
      "                    Average val loss: 0.059848710894584656|\n",
      "                    Val-Mae: 0.03253627195954323\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 381\n",
      "Start training for stock: 3663\n",
      "\n",
      "                    Average train loss: 0.005128195285797119 | \n",
      "                    Train-Mae: 0.04549902305006981 |\n",
      "\n",
      "                    Average val loss: 0.0023658701684325933|\n",
      "                    Val-Mae: 0.03532338887453079\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 382\n",
      "Start training for stock: 1822\n",
      "\n",
      "                    Average train loss: 0.0002524701878428459 | \n",
      "                    Train-Mae: 0.03137015551328659 |\n",
      "\n",
      "                    Average val loss: 0.00023284225608222187|\n",
      "                    Val-Mae: 0.01060519926249981\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 383\n",
      "Start training for stock: 6804\n",
      "\n",
      "                    Average train loss: 0.00012433323077857495 | \n",
      "                    Train-Mae: 0.02745119482278824 |\n",
      "\n",
      "                    Average val loss: 0.0016120981890708208|\n",
      "                    Val-Mae: 0.01721738651394844\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 384\n",
      "Start training for stock: 5344\n",
      "\n",
      "                    Average train loss: 0.0011728672683238982 | \n",
      "                    Train-Mae: 0.02979866787791252 |\n",
      "\n",
      "                    Average val loss: 0.060103584080934525|\n",
      "                    Val-Mae: 0.03715783730149269\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 385\n",
      "Start training for stock: 7451\n",
      "\n",
      "                    Average train loss: 4.000728949904442e-05 | \n",
      "                    Train-Mae: 0.023149488493800163 |\n",
      "\n",
      "                    Average val loss: 0.052181176841259|\n",
      "                    Val-Mae: 0.029684042558073997\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 386\n",
      "Start training for stock: 6981\n",
      "\n",
      "                    Average train loss: 0.002364996522665024 | \n",
      "                    Train-Mae: 0.03457831218838692 |\n",
      "\n",
      "                    Average val loss: 0.0007502819644287229|\n",
      "                    Val-Mae: 0.01502019353210926\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 387\n",
      "Start training for stock: 3922\n",
      "\n",
      "                    Average train loss: 0.0004463007301092148 | \n",
      "                    Train-Mae: 0.06567145884037018 |\n",
      "\n",
      "                    Average val loss: 0.015046307817101479|\n",
      "                    Val-Mae: 0.033008165657520294\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 388\n",
      "Start training for stock: 7414\n",
      "\n",
      "                    Average train loss: 0.0034648287296295166 | \n",
      "                    Train-Mae: 0.0357758067548275 |\n",
      "\n",
      "                    Average val loss: 0.000751856598071754|\n",
      "                    Val-Mae: 0.014850187115371227\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 389\n",
      "Start training for stock: 8897\n",
      "\n",
      "                    Average train loss: 0.007898070216178894 | \n",
      "                    Train-Mae: 0.029416659846901894 |\n",
      "\n",
      "                    Average val loss: 0.0390908345580101|\n",
      "                    Val-Mae: 0.029613785445690155\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 390\n",
      "Start training for stock: 2975\n",
      "\n",
      "                    Average train loss: 0.000975838452577591 | \n",
      "                    Train-Mae: 0.042071033269166946 |\n",
      "\n",
      "                    Average val loss: 0.010899381712079048|\n",
      "                    Val-Mae: 0.0279096569865942\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 391\n",
      "Start training for stock: 1860\n",
      "\n",
      "                    Average train loss: 0.0010350161790847778 | \n",
      "                    Train-Mae: 0.02118566632270813 |\n",
      "\n",
      "                    Average val loss: 0.10450862348079681|\n",
      "                    Val-Mae: 0.03806263580918312\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 392\n",
      "Start training for stock: 9436\n",
      "\n",
      "                    Average train loss: 9.598765522241593e-05 | \n",
      "                    Train-Mae: 0.043082498013973236 |\n",
      "\n",
      "                    Average val loss: 0.00888418685644865|\n",
      "                    Val-Mae: 0.0180808175355196\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 393\n",
      "Start training for stock: 7267\n",
      "\n",
      "                    Average train loss: 0.0003253166377544403 | \n",
      "                    Train-Mae: 0.02837185002863407 |\n",
      "\n",
      "                    Average val loss: 0.056988637894392014|\n",
      "                    Val-Mae: 0.03085453063249588\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 394\n",
      "Start training for stock: 7261\n",
      "\n",
      "                    Average train loss: 5.211529787629843e-05 | \n",
      "                    Train-Mae: 0.043271176517009735 |\n",
      "\n",
      "                    Average val loss: 0.0045244889333844185|\n",
      "                    Val-Mae: 0.023066014051437378\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 395\n",
      "Start training for stock: 4443\n",
      "\n",
      "                    Average train loss: 8.775655180215836e-05 | \n",
      "                    Train-Mae: 0.03880686312913895 |\n",
      "\n",
      "                    Average val loss: 0.019458001479506493|\n",
      "                    Val-Mae: 0.045008450746536255\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 396\n",
      "Start training for stock: 3221\n",
      "\n",
      "                    Average train loss: 0.00024287709966301917 | \n",
      "                    Train-Mae: 0.051556117832660675 |\n",
      "\n",
      "                    Average val loss: 0.04474610835313797|\n",
      "                    Val-Mae: 0.03520490601658821\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 397\n",
      "Start training for stock: 9104\n",
      "\n",
      "                    Average train loss: 0.0001802770048379898 | \n",
      "                    Train-Mae: 0.031221304088830948 |\n",
      "\n",
      "                    Average val loss: 0.07692606747150421|\n",
      "                    Val-Mae: 0.060545582324266434\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 398\n",
      "Start training for stock: 8860\n",
      "\n",
      "                    Average train loss: 0.0007403320819139481 | \n",
      "                    Train-Mae: 0.041625671088695526 |\n",
      "\n",
      "                    Average val loss: 0.003080923343077302|\n",
      "                    Val-Mae: 0.01824111118912697\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 399\n",
      "Start training for stock: 4113\n",
      "\n",
      "                    Average train loss: 0.0001945180632174015 | \n",
      "                    Train-Mae: 0.048894159495830536 |\n",
      "\n",
      "                    Average val loss: 0.0020845725666731596|\n",
      "                    Val-Mae: 0.02611548639833927\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 400\n",
      "Start training for stock: 4205\n",
      "\n",
      "                    Average train loss: 0.002293524444103241 | \n",
      "                    Train-Mae: 0.059069618582725525 |\n",
      "\n",
      "                    Average val loss: 0.01587699167430401|\n",
      "                    Val-Mae: 0.027700252830982208\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 401\n",
      "Start training for stock: 2294\n",
      "\n",
      "                    Average train loss: 0.0007707928121089935 | \n",
      "                    Train-Mae: 0.027319278568029404 |\n",
      "\n",
      "                    Average val loss: 0.0649658739566803|\n",
      "                    Val-Mae: 0.03082216903567314\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 402\n",
      "Start training for stock: 9279\n",
      "\n",
      "                    Average train loss: 0.000774628221988678 | \n",
      "                    Train-Mae: 0.028619954362511635 |\n",
      "\n",
      "                    Average val loss: 0.006369651295244694|\n",
      "                    Val-Mae: 0.028111428022384644\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 403\n",
      "Start training for stock: 3087\n",
      "\n",
      "                    Average train loss: 0.0004297543689608574 | \n",
      "                    Train-Mae: 0.028111327439546585 |\n",
      "\n",
      "                    Average val loss: 0.025142941623926163|\n",
      "                    Val-Mae: 0.022705581039190292\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 404\n",
      "Start training for stock: 4611\n",
      "\n",
      "                    Average train loss: 0.00037261515855789183 | \n",
      "                    Train-Mae: 0.026420865207910538 |\n",
      "\n",
      "                    Average val loss: 0.0046020555309951305|\n",
      "                    Val-Mae: 0.01458926871418953\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 405\n",
      "Start training for stock: 4027\n",
      "\n",
      "                    Average train loss: 0.0006047603487968445 | \n",
      "                    Train-Mae: 0.03023015335202217 |\n",
      "\n",
      "                    Average val loss: 0.0011863468680530787|\n",
      "                    Val-Mae: 0.01778610236942768\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 406\n",
      "Start training for stock: 3854\n",
      "\n",
      "                    Average train loss: 0.0003462067246437073 | \n",
      "                    Train-Mae: 0.035708487033843994 |\n",
      "\n",
      "                    Average val loss: 0.007483473978936672|\n",
      "                    Val-Mae: 0.025453027337789536\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 407\n",
      "Start training for stock: 2751\n",
      "\n",
      "                    Average train loss: 1.5384748112410308e-05 | \n",
      "                    Train-Mae: 0.02704131230711937 |\n",
      "\n",
      "                    Average val loss: 0.00025364846806041896|\n",
      "                    Val-Mae: 0.009621130302548409\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 408\n",
      "Start training for stock: 7911\n",
      "\n",
      "                    Average train loss: 0.0001752178929746151 | \n",
      "                    Train-Mae: 0.03541846200823784 |\n",
      "\n",
      "                    Average val loss: 0.031910669058561325|\n",
      "                    Val-Mae: 0.026847628876566887\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 409\n",
      "Start training for stock: 7705\n",
      "\n",
      "                    Average train loss: 0.0032502388954162597 | \n",
      "                    Train-Mae: 0.05506380274891853 |\n",
      "\n",
      "                    Average val loss: 0.038786906749010086|\n",
      "                    Val-Mae: 0.030672380700707436\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 410\n",
      "Start training for stock: 2429\n",
      "\n",
      "                    Average train loss: 0.004165745675563813 | \n",
      "                    Train-Mae: 0.039380356669425964 |\n",
      "\n",
      "                    Average val loss: 0.01621931977570057|\n",
      "                    Val-Mae: 0.026722852140665054\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 411\n",
      "Start training for stock: 9364\n",
      "\n",
      "                    Average train loss: 0.0012098675966262817 | \n",
      "                    Train-Mae: 0.022582340985536575 |\n",
      "\n",
      "                    Average val loss: 0.002256229519844055|\n",
      "                    Val-Mae: 0.014700225554406643\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 412\n",
      "Start training for stock: 4344\n",
      "\n",
      "                    Average train loss: 0.0005788055062294007 | \n",
      "                    Train-Mae: 0.028934448957443237 |\n",
      "\n",
      "                    Average val loss: 0.008413208648562431|\n",
      "                    Val-Mae: 0.025065528228878975\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 413\n",
      "Start training for stock: 7868\n",
      "\n",
      "                    Average train loss: 0.005707601308822632 | \n",
      "                    Train-Mae: 0.04394395649433136 |\n",
      "\n",
      "                    Average val loss: 0.015776127576828003|\n",
      "                    Val-Mae: 0.038472313433885574\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 414\n",
      "Start training for stock: 4189\n",
      "\n",
      "                    Average train loss: 0.0013028723001480102 | \n",
      "                    Train-Mae: 0.02450173906981945 |\n",
      "\n",
      "                    Average val loss: 0.0011324324877932668|\n",
      "                    Val-Mae: 0.018771862611174583\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 415\n",
      "Start training for stock: 3183\n",
      "\n",
      "                    Average train loss: 0.001426946222782135 | \n",
      "                    Train-Mae: 0.03463000804185867 |\n",
      "\n",
      "                    Average val loss: 0.0037976792082190514|\n",
      "                    Val-Mae: 0.013482224196195602\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 416\n",
      "Start training for stock: 6857\n",
      "\n",
      "                    Average train loss: 0.0002901480533182621 | \n",
      "                    Train-Mae: 0.03728551045060158 |\n",
      "\n",
      "                    Average val loss: 0.0016494357259944081|\n",
      "                    Val-Mae: 0.02196061611175537\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 417\n",
      "Start training for stock: 7628\n",
      "\n",
      "                    Average train loss: 0.012324936389923095 | \n",
      "                    Train-Mae: 0.053129468113183975 |\n",
      "\n",
      "                    Average val loss: 0.1154552698135376|\n",
      "                    Val-Mae: 0.038593925535678864\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 418\n",
      "Start training for stock: 7354\n",
      "\n",
      "                    Average train loss: 0.001845010668039322 | \n",
      "                    Train-Mae: 0.055022649466991425 |\n",
      "\n",
      "                    Average val loss: 0.01063117291778326|\n",
      "                    Val-Mae: 0.03373705968260765\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 419\n",
      "Start training for stock: 5989\n",
      "\n",
      "                    Average train loss: 0.00028865199536085126 | \n",
      "                    Train-Mae: 0.030630653724074364 |\n",
      "\n",
      "                    Average val loss: 0.0009366562590003014|\n",
      "                    Val-Mae: 0.01796518824994564\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 420\n",
      "Start training for stock: 8217\n",
      "\n",
      "                    Average train loss: 1.4783899532631039e-05 | \n",
      "                    Train-Mae: 0.02816762402653694 |\n",
      "\n",
      "                    Average val loss: 0.0012719890801236033|\n",
      "                    Val-Mae: 0.016287999227643013\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 421\n",
      "Start training for stock: 2753\n",
      "\n",
      "                    Average train loss: 0.0003090799786150455 | \n",
      "                    Train-Mae: 0.028429178521037102 |\n",
      "\n",
      "                    Average val loss: 0.0005042438278906047|\n",
      "                    Val-Mae: 0.009892410598695278\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 422\n",
      "Start training for stock: 6368\n",
      "\n",
      "                    Average train loss: 5.644217133522034e-05 | \n",
      "                    Train-Mae: 0.030802208930253983 |\n",
      "\n",
      "                    Average val loss: 0.001991163706406951|\n",
      "                    Val-Mae: 0.017487743869423866\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 423\n",
      "Start training for stock: 2980\n",
      "\n",
      "                    Average train loss: 0.0001209617406129837 | \n",
      "                    Train-Mae: 0.043090034276247025 |\n",
      "\n",
      "                    Average val loss: 0.003913684748113155|\n",
      "                    Val-Mae: 0.03359067812561989\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 424\n",
      "Start training for stock: 8155\n",
      "\n",
      "                    Average train loss: 5.068399477750063e-05 | \n",
      "                    Train-Mae: 0.040167082101106644 |\n",
      "\n",
      "                    Average val loss: 0.07863439619541168|\n",
      "                    Val-Mae: 0.039355698972940445\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 425\n",
      "Start training for stock: 4165\n",
      "\n",
      "                    Average train loss: 0.0008617807179689407 | \n",
      "                    Train-Mae: 0.055633794516325 |\n",
      "\n",
      "                    Average val loss: 0.005610162392258644|\n",
      "                    Val-Mae: 0.04205724596977234\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 426\n",
      "Start training for stock: 5186\n",
      "\n",
      "                    Average train loss: 0.005028735399246215 | \n",
      "                    Train-Mae: 0.02622946910560131 |\n",
      "\n",
      "                    Average val loss: 0.03425950929522514|\n",
      "                    Val-Mae: 0.026776770129799843\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 427\n",
      "Start training for stock: 4568\n",
      "\n",
      "                    Average train loss: 0.0017234739661216737 | \n",
      "                    Train-Mae: 0.03628642484545708 |\n",
      "\n",
      "                    Average val loss: 0.010031136684119701|\n",
      "                    Val-Mae: 0.02310948260128498\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 428\n",
      "Start training for stock: 8001\n",
      "\n",
      "                    Average train loss: 0.005226927995681763 | \n",
      "                    Train-Mae: 0.023902006447315216 |\n",
      "\n",
      "                    Average val loss: 0.029179560020565987|\n",
      "                    Val-Mae: 0.02658388949930668\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 429\n",
      "Start training for stock: 4116\n",
      "\n",
      "                    Average train loss: 0.0001281475741416216 | \n",
      "                    Train-Mae: 0.02709813416004181 |\n",
      "\n",
      "                    Average val loss: 0.00071482895873487|\n",
      "                    Val-Mae: 0.01634661667048931\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 430\n",
      "Start training for stock: 8098\n",
      "\n",
      "                    Average train loss: 0.001297331154346466 | \n",
      "                    Train-Mae: 0.04901522397994995 |\n",
      "\n",
      "                    Average val loss: 0.0423533134162426|\n",
      "                    Val-Mae: 0.02870151586830616\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 431\n",
      "Start training for stock: 2810\n",
      "\n",
      "                    Average train loss: 0.0009183546900749206 | \n",
      "                    Train-Mae: 0.040361590683460236 |\n",
      "\n",
      "                    Average val loss: 0.06362113356590271|\n",
      "                    Val-Mae: 0.032679133117198944\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 432\n",
      "Start training for stock: 2573\n",
      "\n",
      "                    Average train loss: 0.00021579697728157043 | \n",
      "                    Train-Mae: 0.04516685754060745 |\n",
      "\n",
      "                    Average val loss: 0.015064637176692486|\n",
      "                    Val-Mae: 0.015339037403464317\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 433\n",
      "Start training for stock: 7806\n",
      "\n",
      "                    Average train loss: 9.11039300262928e-05 | \n",
      "                    Train-Mae: 0.04763975739479065 |\n",
      "\n",
      "                    Average val loss: 0.001979287015274167|\n",
      "                    Val-Mae: 0.025005986914038658\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 434\n",
      "Start training for stock: 6752\n",
      "\n",
      "                    Average train loss: 0.00013275178149342538 | \n",
      "                    Train-Mae: 0.02311600372195244 |\n",
      "\n",
      "                    Average val loss: 0.005744311027228832|\n",
      "                    Val-Mae: 0.020472021773457527\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 435\n",
      "Start training for stock: 4043\n",
      "\n",
      "                    Average train loss: 0.00024877367541193963 | \n",
      "                    Train-Mae: 0.026996543630957603 |\n",
      "\n",
      "                    Average val loss: 0.0029254588298499584|\n",
      "                    Val-Mae: 0.01657130941748619\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 436\n",
      "Start training for stock: 7456\n",
      "\n",
      "                    Average train loss: 0.00039275944232940673 | \n",
      "                    Train-Mae: 0.02480720914900303 |\n",
      "\n",
      "                    Average val loss: 0.033455487340688705|\n",
      "                    Val-Mae: 0.03611219674348831\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 437\n",
      "Start training for stock: 4348\n",
      "\n",
      "                    Average train loss: 0.004830160439014435 | \n",
      "                    Train-Mae: 0.03504202514886856 |\n",
      "\n",
      "                    Average val loss: 0.004095821641385555|\n",
      "                    Val-Mae: 0.02211684361100197\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 438\n",
      "Start training for stock: 4519\n",
      "\n",
      "                    Average train loss: 5.248797591775656e-05 | \n",
      "                    Train-Mae: 0.0388757549226284 |\n",
      "\n",
      "                    Average val loss: 0.0036754775792360306|\n",
      "                    Val-Mae: 0.018052425235509872\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 439\n",
      "Start training for stock: 4005\n",
      "\n",
      "                    Average train loss: 1.3950850116088986e-05 | \n",
      "                    Train-Mae: 0.026985134929418564 |\n",
      "\n",
      "                    Average val loss: 0.000496217398904264|\n",
      "                    Val-Mae: 0.015272130258381367\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 440\n",
      "Start training for stock: 6788\n",
      "\n",
      "                    Average train loss: 0.0002101990208029747 | \n",
      "                    Train-Mae: 0.03409178927540779 |\n",
      "\n",
      "                    Average val loss: 0.0002790530270431191|\n",
      "                    Val-Mae: 0.01232937816530466\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 441\n",
      "Start training for stock: 9386\n",
      "\n",
      "                    Average train loss: 0.0006899683177471161 | \n",
      "                    Train-Mae: 0.04149309918284416 |\n",
      "\n",
      "                    Average val loss: 0.14018923044204712|\n",
      "                    Val-Mae: 0.056883469223976135\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 442\n",
      "Start training for stock: 7420\n",
      "\n",
      "                    Average train loss: 0.00941821575164795 | \n",
      "                    Train-Mae: 0.03680414333939552 |\n",
      "\n",
      "                    Average val loss: 0.0007159162196330726|\n",
      "                    Val-Mae: 0.016541481018066406\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 443\n",
      "Start training for stock: 4528\n",
      "\n",
      "                    Average train loss: 0.0022122614085674287 | \n",
      "                    Train-Mae: 0.039489924907684326 |\n",
      "\n",
      "                    Average val loss: 0.012216679751873016|\n",
      "                    Val-Mae: 0.020513391122221947\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 444\n",
      "Start training for stock: 1376\n",
      "\n",
      "                    Average train loss: 0.000627346932888031 | \n",
      "                    Train-Mae: 0.04744822531938553 |\n",
      "\n",
      "                    Average val loss: 0.11829911172389984|\n",
      "                    Val-Mae: 0.03820721060037613\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 445\n",
      "Start training for stock: 2491\n",
      "\n",
      "                    Average train loss: 0.0011203379184007644 | \n",
      "                    Train-Mae: 0.06156831979751587 |\n",
      "\n",
      "                    Average val loss: 0.002428829437121749|\n",
      "                    Val-Mae: 0.024894675239920616\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 446\n",
      "Start training for stock: 6062\n",
      "\n",
      "                    Average train loss: 0.0004837336018681526 | \n",
      "                    Train-Mae: 0.03886249288916588 |\n",
      "\n",
      "                    Average val loss: 0.01404145173728466|\n",
      "                    Val-Mae: 0.02848333865404129\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 447\n",
      "Start training for stock: 3475\n",
      "\n",
      "                    Average train loss: 2.448252635076642e-05 | \n",
      "                    Train-Mae: 0.03374047204852104 |\n",
      "\n",
      "                    Average val loss: 0.01283134426921606|\n",
      "                    Val-Mae: 0.027329152449965477\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 448\n",
      "Start training for stock: 3626\n",
      "\n",
      "                    Average train loss: 0.0006590349972248077 | \n",
      "                    Train-Mae: 0.038355372846126556 |\n",
      "\n",
      "                    Average val loss: 0.0005562340375036001|\n",
      "                    Val-Mae: 0.01673246920108795\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 449\n",
      "Start training for stock: 4776\n",
      "\n",
      "                    Average train loss: 3.1608077697455884e-05 | \n",
      "                    Train-Mae: 0.03987624868750572 |\n",
      "\n",
      "                    Average val loss: 0.0073035419918596745|\n",
      "                    Val-Mae: 0.027197668328881264\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 450\n",
      "Start training for stock: 2593\n",
      "\n",
      "                    Average train loss: 0.000194263756275177 | \n",
      "                    Train-Mae: 0.02369891107082367 |\n",
      "\n",
      "                    Average val loss: 0.039036042988300323|\n",
      "                    Val-Mae: 0.03017025627195835\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 451\n",
      "Start training for stock: 6099\n",
      "\n",
      "                    Average train loss: 0.0008285877853631973 | \n",
      "                    Train-Mae: 0.045648541301488876 |\n",
      "\n",
      "                    Average val loss: 0.006174047943204641|\n",
      "                    Val-Mae: 0.02238844335079193\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 452\n",
      "Start training for stock: 3688\n",
      "\n",
      "                    Average train loss: 0.0016288956999778747 | \n",
      "                    Train-Mae: 0.030379340052604675 |\n",
      "\n",
      "                    Average val loss: 0.05766437575221062|\n",
      "                    Val-Mae: 0.04100251942873001\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 453\n",
      "Start training for stock: 7814\n",
      "\n",
      "                    Average train loss: 0.01118392586708069 | \n",
      "                    Train-Mae: 0.036747924983501434 |\n",
      "\n",
      "                    Average val loss: 0.002873882418498397|\n",
      "                    Val-Mae: 0.01702245883643627\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 454\n",
      "Start training for stock: 9384\n",
      "\n",
      "                    Average train loss: 0.0005148470774292946 | \n",
      "                    Train-Mae: 0.038051169365644455 |\n",
      "\n",
      "                    Average val loss: 0.02570440247654915|\n",
      "                    Val-Mae: 0.0367981493473053\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 455\n",
      "Start training for stock: 6676\n",
      "\n",
      "                    Average train loss: 0.00255324125289917 | \n",
      "                    Train-Mae: 0.04084314778447151 |\n",
      "\n",
      "                    Average val loss: 0.0006853705272078514|\n",
      "                    Val-Mae: 0.017864692956209183\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 456\n",
      "Start training for stock: 8150\n",
      "\n",
      "                    Average train loss: 0.002044898420572281 | \n",
      "                    Train-Mae: 0.03177828714251518 |\n",
      "\n",
      "                    Average val loss: 0.020894406363368034|\n",
      "                    Val-Mae: 0.02616693079471588\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 457\n",
      "Start training for stock: 6098\n",
      "\n",
      "                    Average train loss: 0.0005048095434904098 | \n",
      "                    Train-Mae: 0.03335307165980339 |\n",
      "\n",
      "                    Average val loss: 0.02806408703327179|\n",
      "                    Val-Mae: 0.03079407475888729\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 458\n",
      "Start training for stock: 9115\n",
      "\n",
      "                    Average train loss: 0.00036159947514533995 | \n",
      "                    Train-Mae: 0.0364774726331234 |\n",
      "\n",
      "                    Average val loss: 0.04543108865618706|\n",
      "                    Val-Mae: 0.0477546863257885\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 459\n",
      "Start training for stock: 6629\n",
      "\n",
      "                    Average train loss: 0.0003529883921146393 | \n",
      "                    Train-Mae: 0.04754281044006348 |\n",
      "\n",
      "                    Average val loss: 0.06687479466199875|\n",
      "                    Val-Mae: 0.05446131154894829\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 460\n",
      "Start training for stock: 4343\n",
      "\n",
      "                    Average train loss: 0.0008264568448066712 | \n",
      "                    Train-Mae: 0.03441821411252022 |\n",
      "\n",
      "                    Average val loss: 0.0016217203810811043|\n",
      "                    Val-Mae: 0.020586227998137474\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 461\n",
      "Start training for stock: 7747\n",
      "\n",
      "                    Average train loss: 0.00022273937240242957 | \n",
      "                    Train-Mae: 0.0319112204015255 |\n",
      "\n",
      "                    Average val loss: 0.004055103287100792|\n",
      "                    Val-Mae: 0.019637299701571465\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 462\n",
      "Start training for stock: 3837\n",
      "\n",
      "                    Average train loss: 0.004855282902717591 | \n",
      "                    Train-Mae: 0.043807219713926315 |\n",
      "\n",
      "                    Average val loss: 0.004980287980288267|\n",
      "                    Val-Mae: 0.020988164469599724\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 463\n",
      "Start training for stock: 2805\n",
      "\n",
      "                    Average train loss: 7.368328981101513e-05 | \n",
      "                    Train-Mae: 0.01497927587479353 |\n",
      "\n",
      "                    Average val loss: 0.0015087933279573917|\n",
      "                    Val-Mae: 0.00861095916479826\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 464\n",
      "Start training for stock: 4619\n",
      "\n",
      "                    Average train loss: 0.0011566658318042755 | \n",
      "                    Train-Mae: 0.02824508585035801 |\n",
      "\n",
      "                    Average val loss: 0.004967661574482918|\n",
      "                    Val-Mae: 0.02027023397386074\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 465\n",
      "Start training for stock: 1780\n",
      "\n",
      "                    Average train loss: 0.0006643877178430557 | \n",
      "                    Train-Mae: 0.05033441260457039 |\n",
      "\n",
      "                    Average val loss: 0.028294473886489868|\n",
      "                    Val-Mae: 0.023707890883088112\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 466\n",
      "Start training for stock: 8157\n",
      "\n",
      "                    Average train loss: 2.578271087259054e-05 | \n",
      "                    Train-Mae: 0.05126159265637398 |\n",
      "\n",
      "                    Average val loss: 0.007173717953264713|\n",
      "                    Val-Mae: 0.023284345865249634\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 467\n",
      "Start training for stock: 9902\n",
      "\n",
      "                    Average train loss: 0.0008404584228992462 | \n",
      "                    Train-Mae: 0.027536267414689064 |\n",
      "\n",
      "                    Average val loss: 0.00125689257401973|\n",
      "                    Val-Mae: 0.016665473580360413\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 468\n",
      "Start training for stock: 9987\n",
      "\n",
      "                    Average train loss: 0.00022905586287379264 | \n",
      "                    Train-Mae: 0.033549025654792786 |\n",
      "\n",
      "                    Average val loss: 0.005077289417386055|\n",
      "                    Val-Mae: 0.017417417839169502\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 469\n",
      "Start training for stock: 3834\n",
      "\n",
      "                    Average train loss: 7.261126302182674e-05 | \n",
      "                    Train-Mae: 0.03216090798377991 |\n",
      "\n",
      "                    Average val loss: 0.015596382319927216|\n",
      "                    Val-Mae: 0.02105003222823143\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 470\n",
      "Start training for stock: 7780\n",
      "\n",
      "                    Average train loss: 0.00011303783394396305 | \n",
      "                    Train-Mae: 0.05131043866276741 |\n",
      "\n",
      "                    Average val loss: 0.026076922193169594|\n",
      "                    Val-Mae: 0.03254392370581627\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 471\n",
      "Start training for stock: 6183\n",
      "\n",
      "                    Average train loss: 0.0005100142210721969 | \n",
      "                    Train-Mae: 0.04925503581762314 |\n",
      "\n",
      "                    Average val loss: 0.003404904855415225|\n",
      "                    Val-Mae: 0.01812846213579178\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 472\n",
      "Start training for stock: 7600\n",
      "\n",
      "                    Average train loss: 0.0001830308884382248 | \n",
      "                    Train-Mae: 0.03221306577324867 |\n",
      "\n",
      "                    Average val loss: 0.00301316287368536|\n",
      "                    Val-Mae: 0.0187075138092041\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 473\n",
      "Start training for stock: 5015\n",
      "\n",
      "                    Average train loss: 0.0011930712312459946 | \n",
      "                    Train-Mae: 0.036913078278303146 |\n",
      "\n",
      "                    Average val loss: 0.07636574655771255|\n",
      "                    Val-Mae: 0.03412140905857086\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 474\n",
      "Start training for stock: 7823\n",
      "\n",
      "                    Average train loss: 0.003001851439476013 | \n",
      "                    Train-Mae: 0.031828876584768295 |\n",
      "\n",
      "                    Average val loss: 0.003616205183789134|\n",
      "                    Val-Mae: 0.015776479616761208\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 475\n",
      "Start training for stock: 3178\n",
      "\n",
      "                    Average train loss: 0.0026679477095603943 | \n",
      "                    Train-Mae: 0.028638409450650215 |\n",
      "\n",
      "                    Average val loss: 0.018344232812523842|\n",
      "                    Val-Mae: 0.02551657147705555\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 476\n",
      "Start training for stock: 9368\n",
      "\n",
      "                    Average train loss: 1.557069714181125e-05 | \n",
      "                    Train-Mae: 0.035617634654045105 |\n",
      "\n",
      "                    Average val loss: 0.0026387416291981936|\n",
      "                    Val-Mae: 0.017956295982003212\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 477\n",
      "Start training for stock: 9010\n",
      "\n",
      "                    Average train loss: 0.00012625552713871002 | \n",
      "                    Train-Mae: 0.028662588447332382 |\n",
      "\n",
      "                    Average val loss: 0.007185204885900021|\n",
      "                    Val-Mae: 0.02494422160089016\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 478\n",
      "Start training for stock: 7012\n",
      "\n",
      "                    Average train loss: 0.00024105416610836983 | \n",
      "                    Train-Mae: 0.02994556352496147 |\n",
      "\n",
      "                    Average val loss: 0.001126734772697091|\n",
      "                    Val-Mae: 0.02012234926223755\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 479\n",
      "Start training for stock: 5726\n",
      "\n",
      "                    Average train loss: 0.0006470416486263276 | \n",
      "                    Train-Mae: 0.02499987743794918 |\n",
      "\n",
      "                    Average val loss: 0.004120430443435907|\n",
      "                    Val-Mae: 0.022440895438194275\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 480\n",
      "Start training for stock: 9984\n",
      "\n",
      "                    Average train loss: 0.001604529321193695 | \n",
      "                    Train-Mae: 0.05078811198472977 |\n",
      "\n",
      "                    Average val loss: 0.010389517061412334|\n",
      "                    Val-Mae: 0.02606799453496933\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 481\n",
      "Start training for stock: 6502\n",
      "\n",
      "                    Average train loss: 0.0002454082667827606 | \n",
      "                    Train-Mae: 0.024519385769963264 |\n",
      "\n",
      "                    Average val loss: 0.025970133021473885|\n",
      "                    Val-Mae: 0.029591381549835205\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 482\n",
      "Start training for stock: 6264\n",
      "\n",
      "                    Average train loss: 0.0009015487879514694 | \n",
      "                    Train-Mae: 0.03428947180509567 |\n",
      "\n",
      "                    Average val loss: 0.004728819243609905|\n",
      "                    Val-Mae: 0.03387116640806198\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 483\n",
      "Start training for stock: 8524\n",
      "\n",
      "                    Average train loss: 0.00026096906512975695 | \n",
      "                    Train-Mae: 0.02682557888329029 |\n",
      "\n",
      "                    Average val loss: 0.01616998203098774|\n",
      "                    Val-Mae: 0.026385262608528137\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 484\n",
      "Start training for stock: 3863\n",
      "\n",
      "                    Average train loss: 0.0007922723144292832 | \n",
      "                    Train-Mae: 0.028843147680163383 |\n",
      "\n",
      "                    Average val loss: 0.006803073920309544|\n",
      "                    Val-Mae: 0.018709072843194008\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 485\n",
      "Start training for stock: 1959\n",
      "\n",
      "                    Average train loss: 0.0016233856976032258 | \n",
      "                    Train-Mae: 0.02591298706829548 |\n",
      "\n",
      "                    Average val loss: 0.0024656509049236774|\n",
      "                    Val-Mae: 0.014465076848864555\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 486\n",
      "Start training for stock: 6088\n",
      "\n",
      "                    Average train loss: 0.0007248494774103164 | \n",
      "                    Train-Mae: 0.05090949684381485 |\n",
      "\n",
      "                    Average val loss: 0.01627984829246998|\n",
      "                    Val-Mae: 0.033093325793743134\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 487\n",
      "Start training for stock: 4809\n",
      "\n",
      "                    Average train loss: 0.003952488601207733 | \n",
      "                    Train-Mae: 0.057006292045116425 |\n",
      "\n",
      "                    Average val loss: 0.009795533493161201|\n",
      "                    Val-Mae: 0.02044234797358513\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 488\n",
      "Start training for stock: 7774\n",
      "\n",
      "                    Average train loss: 0.0012140540033578873 | \n",
      "                    Train-Mae: 0.02576730027794838 |\n",
      "\n",
      "                    Average val loss: 0.0010996938217431307|\n",
      "                    Val-Mae: 0.013758175075054169\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 489\n",
      "Start training for stock: 7777\n",
      "\n",
      "                    Average train loss: 0.00029000837355852127 | \n",
      "                    Train-Mae: 0.03242838755249977 |\n",
      "\n",
      "                    Average val loss: 0.006761461496353149|\n",
      "                    Val-Mae: 0.03274174779653549\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 490\n",
      "Start training for stock: 2371\n",
      "\n",
      "                    Average train loss: 0.0015768551826477052 | \n",
      "                    Train-Mae: 0.0342397540807724 |\n",
      "\n",
      "                    Average val loss: 0.05763048678636551|\n",
      "                    Val-Mae: 0.03623443841934204\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 491\n",
      "Start training for stock: 3048\n",
      "\n",
      "                    Average train loss: 0.00013403980992734432 | \n",
      "                    Train-Mae: 0.022047258913517 |\n",
      "\n",
      "                    Average val loss: 0.04622865468263626|\n",
      "                    Val-Mae: 0.02751711942255497\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 492\n",
      "Start training for stock: 6157\n",
      "\n",
      "                    Average train loss: 0.011520227193832397 | \n",
      "                    Train-Mae: 0.05393936485052109 |\n",
      "\n",
      "                    Average val loss: 0.0009444838506169617|\n",
      "                    Val-Mae: 0.017514707520604134\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 493\n",
      "Start training for stock: 4362\n",
      "\n",
      "                    Average train loss: 0.001962112635374069 | \n",
      "                    Train-Mae: 0.026239624246954918 |\n",
      "\n",
      "                    Average val loss: 0.07167135924100876|\n",
      "                    Val-Mae: 0.03811091184616089\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 494\n",
      "Start training for stock: 6727\n",
      "\n",
      "                    Average train loss: 3.2412391155958176e-05 | \n",
      "                    Train-Mae: 0.04241280257701874 |\n",
      "\n",
      "                    Average val loss: 0.003318330505862832|\n",
      "                    Val-Mae: 0.02112843096256256\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 495\n",
      "Start training for stock: 5970\n",
      "\n",
      "                    Average train loss: 0.001455845683813095 | \n",
      "                    Train-Mae: 0.040425922721624374 |\n",
      "\n",
      "                    Average val loss: 0.0008235742570832372|\n",
      "                    Val-Mae: 0.016183653846383095\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 496\n",
      "Start training for stock: 7994\n",
      "\n",
      "                    Average train loss: 0.002282599210739136 | \n",
      "                    Train-Mae: 0.04078960791230202 |\n",
      "\n",
      "                    Average val loss: 0.002019670559093356|\n",
      "                    Val-Mae: 0.018679393455386162\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 497\n",
      "Start training for stock: 7607\n",
      "\n",
      "                    Average train loss: 0.0024383923411369322 | \n",
      "                    Train-Mae: 0.026343118399381638 |\n",
      "\n",
      "                    Average val loss: 0.06602659076452255|\n",
      "                    Val-Mae: 0.03071533888578415\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 498\n",
      "Start training for stock: 6871\n",
      "\n",
      "                    Average train loss: 0.0012693347036838532 | \n",
      "                    Train-Mae: 0.04801281914114952 |\n",
      "\n",
      "                    Average val loss: 0.01510495413094759|\n",
      "                    Val-Mae: 0.033352065831422806\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 499\n",
      "Start training for stock: 8056\n",
      "\n",
      "                    Average train loss: 0.0006991195678710938 | \n",
      "                    Train-Mae: 0.027271632105112076 |\n",
      "\n",
      "                    Average val loss: 0.0006493806722573936|\n",
      "                    Val-Mae: 0.015416856855154037\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 500\n",
      "Start training for stock: 6345\n",
      "\n",
      "                    Average train loss: 2.792302751913667e-05 | \n",
      "                    Train-Mae: 0.08313411474227905 |\n",
      "\n",
      "                    Average val loss: 0.4757441282272339|\n",
      "                    Val-Mae: 0.07431648671627045\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 501\n",
      "Start training for stock: 5975\n",
      "\n",
      "                    Average train loss: 0.020914506912231446 | \n",
      "                    Train-Mae: 0.03260163962841034 |\n",
      "\n",
      "                    Average val loss: 0.008634531870484352|\n",
      "                    Val-Mae: 0.024145595729351044\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 502\n",
      "Start training for stock: 8362\n",
      "\n",
      "                    Average train loss: 0.0018072529137134552 | \n",
      "                    Train-Mae: 0.026112696155905724 |\n",
      "\n",
      "                    Average val loss: 0.00040710053872317076|\n",
      "                    Val-Mae: 0.015272804535925388\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 503\n",
      "Start training for stock: 4023\n",
      "\n",
      "                    Average train loss: 0.0006155085191130638 | \n",
      "                    Train-Mae: 0.03247771039605141 |\n",
      "\n",
      "                    Average val loss: 0.0012833733344450593|\n",
      "                    Val-Mae: 0.02017471380531788\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 504\n",
      "Start training for stock: 5659\n",
      "\n",
      "                    Average train loss: 0.0001666426844894886 | \n",
      "                    Train-Mae: 0.024454263970255852 |\n",
      "\n",
      "                    Average val loss: 0.0021667254623025656|\n",
      "                    Val-Mae: 0.021088115870952606\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 505\n",
      "Start training for stock: 6787\n",
      "\n",
      "                    Average train loss: 0.001266145706176758 | \n",
      "                    Train-Mae: 0.03810623660683632 |\n",
      "\n",
      "                    Average val loss: 0.045767392963171005|\n",
      "                    Val-Mae: 0.04001525044441223\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 506\n",
      "Start training for stock: 6571\n",
      "\n",
      "                    Average train loss: 0.0009832551330327987 | \n",
      "                    Train-Mae: 0.029223080724477768 |\n",
      "\n",
      "                    Average val loss: 0.0013213077327236533|\n",
      "                    Val-Mae: 0.01996743120253086\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 507\n",
      "Start training for stock: 6036\n",
      "\n",
      "                    Average train loss: 0.0004162290319800377 | \n",
      "                    Train-Mae: 0.045409224927425385 |\n",
      "\n",
      "                    Average val loss: 0.0063153598457574844|\n",
      "                    Val-Mae: 0.03495383262634277\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 508\n",
      "Start training for stock: 4249\n",
      "\n",
      "                    Average train loss: 0.0013168498873710633 | \n",
      "                    Train-Mae: 0.03785457834601402 |\n",
      "\n",
      "                    Average val loss: 0.019933346658945084|\n",
      "                    Val-Mae: 0.026699522510170937\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 509\n",
      "Start training for stock: 3002\n",
      "\n",
      "                    Average train loss: 6.121103651821614e-05 | \n",
      "                    Train-Mae: 0.02426537126302719 |\n",
      "\n",
      "                    Average val loss: 0.004267423413693905|\n",
      "                    Val-Mae: 0.016969120129942894\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 510\n",
      "Start training for stock: 4538\n",
      "\n",
      "                    Average train loss: 0.0009492387622594833 | \n",
      "                    Train-Mae: 0.034683290868997574 |\n",
      "\n",
      "                    Average val loss: 0.0035988648887723684|\n",
      "                    Val-Mae: 0.019419070333242416\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 511\n",
      "Start training for stock: 6365\n",
      "\n",
      "                    Average train loss: 0.0012082239240407944 | \n",
      "                    Train-Mae: 0.03375810384750366 |\n",
      "\n",
      "                    Average val loss: 0.0008232913096435368|\n",
      "                    Val-Mae: 0.01789660006761551\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 512\n",
      "Start training for stock: 2331\n",
      "\n",
      "                    Average train loss: 5.6267529726028445e-05 | \n",
      "                    Train-Mae: 0.017696572467684746 |\n",
      "\n",
      "                    Average val loss: 0.0006748386658728123|\n",
      "                    Val-Mae: 0.01356591284275055\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 513\n",
      "Start training for stock: 3484\n",
      "\n",
      "                    Average train loss: 0.00027178607881069185 | \n",
      "                    Train-Mae: 0.028711149469017982 |\n",
      "\n",
      "                    Average val loss: 0.0006230275612324476|\n",
      "                    Val-Mae: 0.016841938719153404\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 514\n",
      "Start training for stock: 9070\n",
      "\n",
      "                    Average train loss: 0.00035232994705438616 | \n",
      "                    Train-Mae: 0.029718028381466866 |\n",
      "\n",
      "                    Average val loss: 0.0011376097099855542|\n",
      "                    Val-Mae: 0.01887468434870243\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 515\n",
      "Start training for stock: 3969\n",
      "\n",
      "                    Average train loss: 0.0001971670798957348 | \n",
      "                    Train-Mae: 0.03846164047718048 |\n",
      "\n",
      "                    Average val loss: 0.0047167581506073475|\n",
      "                    Val-Mae: 0.022869007661938667\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 516\n",
      "Start training for stock: 5464\n",
      "\n",
      "                    Average train loss: 0.00042400915175676345 | \n",
      "                    Train-Mae: 0.025942491367459297 |\n",
      "\n",
      "                    Average val loss: 0.0005294598522596061|\n",
      "                    Val-Mae: 0.014606520533561707\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 517\n",
      "Start training for stock: 2809\n",
      "\n",
      "                    Average train loss: 0.0011501825600862504 | \n",
      "                    Train-Mae: 0.03625491261482239 |\n",
      "\n",
      "                    Average val loss: 0.002271176315844059|\n",
      "                    Val-Mae: 0.012645314447581768\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 518\n",
      "Start training for stock: 6023\n",
      "\n",
      "                    Average train loss: 0.0006423996388912201 | \n",
      "                    Train-Mae: 0.03719260171055794 |\n",
      "\n",
      "                    Average val loss: 0.003273530164733529|\n",
      "                    Val-Mae: 0.02153281308710575\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 519\n",
      "Start training for stock: 7102\n",
      "\n",
      "                    Average train loss: 6.823406554758549e-05 | \n",
      "                    Train-Mae: 0.02310519851744175 |\n",
      "\n",
      "                    Average val loss: 0.0032941626850515604|\n",
      "                    Val-Mae: 0.01371738687157631\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 520\n",
      "Start training for stock: 9903\n",
      "\n",
      "                    Average train loss: 3.166265087202191e-05 | \n",
      "                    Train-Mae: 0.03459540382027626 |\n",
      "\n",
      "                    Average val loss: 0.011020494624972343|\n",
      "                    Val-Mae: 0.02024432085454464\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 521\n",
      "Start training for stock: 9684\n",
      "\n",
      "                    Average train loss: 0.00013732007704675197 | \n",
      "                    Train-Mae: 0.04680185765028 |\n",
      "\n",
      "                    Average val loss: 0.002467510988935828|\n",
      "                    Val-Mae: 0.019490007311105728\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 522\n",
      "Start training for stock: 7177\n",
      "\n",
      "                    Average train loss: 0.0001823332719504833 | \n",
      "                    Train-Mae: 0.031378842890262604 |\n",
      "\n",
      "                    Average val loss: 0.0008481663535349071|\n",
      "                    Val-Mae: 0.016699042171239853\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 523\n",
      "Start training for stock: 6382\n",
      "\n",
      "                    Average train loss: 0.00012183476239442825 | \n",
      "                    Train-Mae: 0.035899676382541656 |\n",
      "\n",
      "                    Average val loss: 0.005029005464166403|\n",
      "                    Val-Mae: 0.0206534955650568\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 524\n",
      "Start training for stock: 9507\n",
      "\n",
      "                    Average train loss: 1.0996294440701604e-05 | \n",
      "                    Train-Mae: 0.020149771124124527 |\n",
      "\n",
      "                    Average val loss: 0.005588998552411795|\n",
      "                    Val-Mae: 0.016926709562540054\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 525\n",
      "Start training for stock: 9081\n",
      "\n",
      "                    Average train loss: 0.00022092629224061965 | \n",
      "                    Train-Mae: 0.025727521628141403 |\n",
      "\n",
      "                    Average val loss: 0.0008698967867530882|\n",
      "                    Val-Mae: 0.012640470638871193\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 526\n",
      "Start training for stock: 7723\n",
      "\n",
      "                    Average train loss: 0.001162663996219635 | \n",
      "                    Train-Mae: 0.023126279935240746 |\n",
      "\n",
      "                    Average val loss: 0.004537615459412336|\n",
      "                    Val-Mae: 0.014737558551132679\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 527\n",
      "Start training for stock: 5388\n",
      "\n",
      "                    Average train loss: 1.1210108641535044e-05 | \n",
      "                    Train-Mae: 0.04284781217575073 |\n",
      "\n",
      "                    Average val loss: 0.032127879559993744|\n",
      "                    Val-Mae: 0.030024560168385506\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 528\n",
      "Start training for stock: 6594\n",
      "\n",
      "                    Average train loss: 0.0010680719465017319 | \n",
      "                    Train-Mae: 0.04524184763431549 |\n",
      "\n",
      "                    Average val loss: 0.04869939386844635|\n",
      "                    Val-Mae: 0.030597643926739693\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 529\n",
      "Start training for stock: 9404\n",
      "\n",
      "                    Average train loss: 0.010744839906692505 | \n",
      "                    Train-Mae: 0.05211654305458069 |\n",
      "\n",
      "                    Average val loss: 0.0003130610566586256|\n",
      "                    Val-Mae: 0.011703431606292725\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 530\n",
      "Start training for stock: 3328\n",
      "\n",
      "                    Average train loss: 9.030251763761043e-05 | \n",
      "                    Train-Mae: 0.039425406605005264 |\n",
      "\n",
      "                    Average val loss: 0.022739244624972343|\n",
      "                    Val-Mae: 0.03784778341650963\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 531\n",
      "Start training for stock: 4293\n",
      "\n",
      "                    Average train loss: 0.000755191445350647 | \n",
      "                    Train-Mae: 0.037077754735946655 |\n",
      "\n",
      "                    Average val loss: 0.0019227871671319008|\n",
      "                    Val-Mae: 0.022759780287742615\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 532\n",
      "Start training for stock: 8032\n",
      "\n",
      "                    Average train loss: 0.00017005261033773423 | \n",
      "                    Train-Mae: 0.02750415913760662 |\n",
      "\n",
      "                    Average val loss: 0.001978740096092224|\n",
      "                    Val-Mae: 0.01393080409616232\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 533\n",
      "Start training for stock: 2270\n",
      "\n",
      "                    Average train loss: 3.20805748924613e-05 | \n",
      "                    Train-Mae: 0.025509856641292572 |\n",
      "\n",
      "                    Average val loss: 0.02335130237042904|\n",
      "                    Val-Mae: 0.022312335669994354\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 534\n",
      "Start training for stock: 2433\n",
      "\n",
      "                    Average train loss: 0.0025932121276855467 | \n",
      "                    Train-Mae: 0.03134196996688843 |\n",
      "\n",
      "                    Average val loss: 0.03584121912717819|\n",
      "                    Val-Mae: 0.030124329030513763\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 535\n",
      "Start training for stock: 6566\n",
      "\n",
      "                    Average train loss: 0.000306854322552681 | \n",
      "                    Train-Mae: 0.048818476498126984 |\n",
      "\n",
      "                    Average val loss: 0.005691160447895527|\n",
      "                    Val-Mae: 0.017388703301548958\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 536\n",
      "Start training for stock: 3788\n",
      "\n",
      "                    Average train loss: 0.00011528139002621174 | \n",
      "                    Train-Mae: 0.03672483563423157 |\n",
      "\n",
      "                    Average val loss: 0.0017333535943180323|\n",
      "                    Val-Mae: 0.028113652020692825\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 537\n",
      "Start training for stock: 8388\n",
      "\n",
      "                    Average train loss: 0.00013057339936494827 | \n",
      "                    Train-Mae: 0.03422527015209198 |\n",
      "\n",
      "                    Average val loss: 0.003217698074877262|\n",
      "                    Val-Mae: 0.017574183642864227\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 538\n",
      "Start training for stock: 9932\n",
      "\n",
      "                    Average train loss: 0.00030947698280215264 | \n",
      "                    Train-Mae: 0.054815735667943954 |\n",
      "\n",
      "                    Average val loss: 0.0923716276884079|\n",
      "                    Val-Mae: 0.04052815958857536\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 539\n",
      "Start training for stock: 4592\n",
      "\n",
      "                    Average train loss: 0.0002698556147515774 | \n",
      "                    Train-Mae: 0.03598221018910408 |\n",
      "\n",
      "                    Average val loss: 0.002194801112636924|\n",
      "                    Val-Mae: 0.02340562641620636\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 540\n",
      "Start training for stock: 3038\n",
      "\n",
      "                    Average train loss: 0.0006382207572460174 | \n",
      "                    Train-Mae: 0.03130876272916794 |\n",
      "\n",
      "                    Average val loss: 0.002432337263599038|\n",
      "                    Val-Mae: 0.019198104739189148\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 541\n",
      "Start training for stock: 7616\n",
      "\n",
      "                    Average train loss: 4.3491246178746226e-05 | \n",
      "                    Train-Mae: 0.03672236576676369 |\n",
      "\n",
      "                    Average val loss: 0.034108757972717285|\n",
      "                    Val-Mae: 0.029262550175189972\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 542\n",
      "Start training for stock: 6411\n",
      "\n",
      "                    Average train loss: 0.005296640396118164 | \n",
      "                    Train-Mae: 0.05731244385242462 |\n",
      "\n",
      "                    Average val loss: 0.008457476273179054|\n",
      "                    Val-Mae: 0.01963234134018421\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 543\n",
      "Start training for stock: 7339\n",
      "\n",
      "                    Average train loss: 0.0028949594497680664 | \n",
      "                    Train-Mae: 0.05234370008111 |\n",
      "\n",
      "                    Average val loss: 0.006003431975841522|\n",
      "                    Val-Mae: 0.02840712107717991\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 544\n",
      "Start training for stock: 3349\n",
      "\n",
      "                    Average train loss: 0.00010202053003013135 | \n",
      "                    Train-Mae: 0.030545322224497795 |\n",
      "\n",
      "                    Average val loss: 0.010875390842556953|\n",
      "                    Val-Mae: 0.022306377068161964\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 545\n",
      "Start training for stock: 4765\n",
      "\n",
      "                    Average train loss: 0.000581432767212391 | \n",
      "                    Train-Mae: 0.046265821903944016 |\n",
      "\n",
      "                    Average val loss: 0.005067748017609119|\n",
      "                    Val-Mae: 0.01857147365808487\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 546\n",
      "Start training for stock: 6328\n",
      "\n",
      "                    Average train loss: 0.00036373440176248553 | \n",
      "                    Train-Mae: 0.02238692343235016 |\n",
      "\n",
      "                    Average val loss: 0.01722978986799717|\n",
      "                    Val-Mae: 0.029794368892908096\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 547\n",
      "Start training for stock: 3496\n",
      "\n",
      "                    Average train loss: 0.002985840141773224 | \n",
      "                    Train-Mae: 0.06152042746543884 |\n",
      "\n",
      "                    Average val loss: 0.0016066927928477526|\n",
      "                    Val-Mae: 0.028701022267341614\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 548\n",
      "Start training for stock: 4099\n",
      "\n",
      "                    Average train loss: 4.828935023397207e-05 | \n",
      "                    Train-Mae: 0.03520314395427704 |\n",
      "\n",
      "                    Average val loss: 0.03156183660030365|\n",
      "                    Val-Mae: 0.02768866717815399\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 549\n",
      "Start training for stock: 4350\n",
      "\n",
      "                    Average train loss: 0.0033219200372695923 | \n",
      "                    Train-Mae: 0.08551256358623505 |\n",
      "\n",
      "                    Average val loss: 0.3113408088684082|\n",
      "                    Val-Mae: 0.06611013412475586\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 550\n",
      "Start training for stock: 7033\n",
      "\n",
      "                    Average train loss: 0.004417459964752197 | \n",
      "                    Train-Mae: 0.03359227627515793 |\n",
      "\n",
      "                    Average val loss: 0.017742671072483063|\n",
      "                    Val-Mae: 0.04000818356871605\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 551\n",
      "Start training for stock: 8370\n",
      "\n",
      "                    Average train loss: 0.00016489928588271142 | \n",
      "                    Train-Mae: 0.05481083691120148 |\n",
      "\n",
      "                    Average val loss: 0.048774223774671555|\n",
      "                    Val-Mae: 0.03478647768497467\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 552\n",
      "Start training for stock: 4091\n",
      "\n",
      "                    Average train loss: 0.008420581221580506 | \n",
      "                    Train-Mae: 0.029053620994091034 |\n",
      "\n",
      "                    Average val loss: 0.01155163161456585|\n",
      "                    Val-Mae: 0.02175116539001465\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 553\n",
      "Start training for stock: 9369\n",
      "\n",
      "                    Average train loss: 0.0009410833567380906 | \n",
      "                    Train-Mae: 0.03547069802880287 |\n",
      "\n",
      "                    Average val loss: 0.09174417704343796|\n",
      "                    Val-Mae: 0.0376581996679306\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 554\n",
      "Start training for stock: 6965\n",
      "\n",
      "                    Average train loss: 0.0017561808228492737 | \n",
      "                    Train-Mae: 0.03432322293519974 |\n",
      "\n",
      "                    Average val loss: 0.015597382560372353|\n",
      "                    Val-Mae: 0.022444354370236397\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 555\n",
      "Start training for stock: 2469\n",
      "\n",
      "                    Average train loss: 0.00035760536789894106 | \n",
      "                    Train-Mae: 0.02670084498822689 |\n",
      "\n",
      "                    Average val loss: 0.0007657234091311693|\n",
      "                    Val-Mae: 0.01959092915058136\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 556\n",
      "Start training for stock: 4665\n",
      "\n",
      "                    Average train loss: 0.001665990948677063 | \n",
      "                    Train-Mae: 0.024952948093414307 |\n",
      "\n",
      "                    Average val loss: 0.04832779988646507|\n",
      "                    Val-Mae: 0.024597331881523132\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 557\n",
      "Start training for stock: 6182\n",
      "\n",
      "                    Average train loss: 0.0012586043775081634 | \n",
      "                    Train-Mae: 0.052120037376880646 |\n",
      "\n",
      "                    Average val loss: 0.003835969837382436|\n",
      "                    Val-Mae: 0.028105076402425766\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 558\n",
      "Start training for stock: 6807\n",
      "\n",
      "                    Average train loss: 0.00013872855342924594 | \n",
      "                    Train-Mae: 0.031058821827173233 |\n",
      "\n",
      "                    Average val loss: 0.004954278934746981|\n",
      "                    Val-Mae: 0.021245192736387253\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 559\n",
      "Start training for stock: 2212\n",
      "\n",
      "                    Average train loss: 0.0008333978056907653 | \n",
      "                    Train-Mae: 0.030364440754055977 |\n",
      "\n",
      "                    Average val loss: 0.019583668559789658|\n",
      "                    Val-Mae: 0.021822713315486908\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 560\n",
      "Start training for stock: 5184\n",
      "\n",
      "                    Average train loss: 3.6739434581249955e-05 | \n",
      "                    Train-Mae: 0.025864576920866966 |\n",
      "\n",
      "                    Average val loss: 0.004959865007549524|\n",
      "                    Val-Mae: 0.013144925236701965\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 561\n",
      "Start training for stock: 2461\n",
      "\n",
      "                    Average train loss: 0.0006588586419820785 | \n",
      "                    Train-Mae: 0.023225855082273483 |\n",
      "\n",
      "                    Average val loss: 0.00041245113243348897|\n",
      "                    Val-Mae: 0.011660168878734112\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 562\n",
      "Start training for stock: 8613\n",
      "\n",
      "                    Average train loss: 0.0015699751675128937 | \n",
      "                    Train-Mae: 0.031311918050050735 |\n",
      "\n",
      "                    Average val loss: 0.026873651891946793|\n",
      "                    Val-Mae: 0.026402726769447327\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 563\n",
      "Start training for stock: 3076\n",
      "\n",
      "                    Average train loss: 0.0031966876983642576 | \n",
      "                    Train-Mae: 0.031053535640239716 |\n",
      "\n",
      "                    Average val loss: 0.001856657792814076|\n",
      "                    Val-Mae: 0.01805221103131771\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 564\n",
      "Start training for stock: 7238\n",
      "\n",
      "                    Average train loss: 0.001010783165693283 | \n",
      "                    Train-Mae: 0.03286784514784813 |\n",
      "\n",
      "                    Average val loss: 0.0074946084059774876|\n",
      "                    Val-Mae: 0.024509629234671593\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 565\n",
      "Start training for stock: 2329\n",
      "\n",
      "                    Average train loss: 1.752893440425396e-05 | \n",
      "                    Train-Mae: 0.022253267467021942 |\n",
      "\n",
      "                    Average val loss: 0.0032978334929794073|\n",
      "                    Val-Mae: 0.015020116232335567\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 566\n",
      "Start training for stock: 9810\n",
      "\n",
      "                    Average train loss: 0.0004037077724933624 | \n",
      "                    Train-Mae: 0.03587291017174721 |\n",
      "\n",
      "                    Average val loss: 0.015614391304552555|\n",
      "                    Val-Mae: 0.02416350692510605\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 567\n",
      "Start training for stock: 6479\n",
      "\n",
      "                    Average train loss: 0.00013302222825586796 | \n",
      "                    Train-Mae: 0.029445640742778778 |\n",
      "\n",
      "                    Average val loss: 0.027552185580134392|\n",
      "                    Val-Mae: 0.027061600238084793\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 568\n",
      "Start training for stock: 1716\n",
      "\n",
      "                    Average train loss: 1.532378024421632e-05 | \n",
      "                    Train-Mae: 0.02597559615969658 |\n",
      "\n",
      "                    Average val loss: 0.0031052599661052227|\n",
      "                    Val-Mae: 0.016719549894332886\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 569\n",
      "Start training for stock: 1815\n",
      "\n",
      "                    Average train loss: 0.00019609855487942696 | \n",
      "                    Train-Mae: 0.047843340784311295 |\n",
      "\n",
      "                    Average val loss: 0.01581219770014286|\n",
      "                    Val-Mae: 0.019913485273718834\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 570\n",
      "Start training for stock: 9843\n",
      "\n",
      "                    Average train loss: 0.005968368649482727 | \n",
      "                    Train-Mae: 0.059648048132658005 |\n",
      "\n",
      "                    Average val loss: 0.07657467573881149|\n",
      "                    Val-Mae: 0.03402965888381004\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 571\n",
      "Start training for stock: 3769\n",
      "\n",
      "                    Average train loss: 0.0004117417335510254 | \n",
      "                    Train-Mae: 0.04283518344163895 |\n",
      "\n",
      "                    Average val loss: 0.0021104479674249887|\n",
      "                    Val-Mae: 0.02076995000243187\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 572\n",
      "Start training for stock: 8194\n",
      "\n",
      "                    Average train loss: 9.23184771090746e-05 | \n",
      "                    Train-Mae: 0.02799283340573311 |\n",
      "\n",
      "                    Average val loss: 0.011971957050263882|\n",
      "                    Val-Mae: 0.025193488225340843\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 573\n",
      "Start training for stock: 7537\n",
      "\n",
      "                    Average train loss: 0.0008956537395715714 | \n",
      "                    Train-Mae: 0.04132339358329773 |\n",
      "\n",
      "                    Average val loss: 0.0037421314045786858|\n",
      "                    Val-Mae: 0.024355316534638405\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 574\n",
      "Start training for stock: 7246\n",
      "\n",
      "                    Average train loss: 1.3319143326953054e-05 | \n",
      "                    Train-Mae: 0.028988715261220932 |\n",
      "\n",
      "                    Average val loss: 0.005195808131247759|\n",
      "                    Val-Mae: 0.020747069269418716\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 575\n",
      "Start training for stock: 3657\n",
      "\n",
      "                    Average train loss: 0.0006544116884469986 | \n",
      "                    Train-Mae: 0.026344401761889458 |\n",
      "\n",
      "                    Average val loss: 0.009175949729979038|\n",
      "                    Val-Mae: 0.021199457347393036\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 576\n",
      "Start training for stock: 6151\n",
      "\n",
      "                    Average train loss: 0.002396711856126785 | \n",
      "                    Train-Mae: 0.05103945732116699 |\n",
      "\n",
      "                    Average val loss: 0.016355395317077637|\n",
      "                    Val-Mae: 0.023728305473923683\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 577\n",
      "Start training for stock: 3088\n",
      "\n",
      "                    Average train loss: 0.00010617915540933609 | \n",
      "                    Train-Mae: 0.02705911174416542 |\n",
      "\n",
      "                    Average val loss: 0.0067903040908277035|\n",
      "                    Val-Mae: 0.02178676426410675\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 578\n",
      "Start training for stock: 2393\n",
      "\n",
      "                    Average train loss: 0.0016389232873916626 | \n",
      "                    Train-Mae: 0.02902224287390709 |\n",
      "\n",
      "                    Average val loss: 0.00036457949317991734|\n",
      "                    Val-Mae: 0.009905701503157616\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 579\n",
      "Start training for stock: 7974\n",
      "\n",
      "                    Average train loss: 0.0007942706346511841 | \n",
      "                    Train-Mae: 0.02541651763021946 |\n",
      "\n",
      "                    Average val loss: 0.012657903134822845|\n",
      "                    Val-Mae: 0.022464657202363014\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 580\n",
      "Start training for stock: 7552\n",
      "\n",
      "                    Average train loss: 0.003644774556159973 | \n",
      "                    Train-Mae: 0.0398779958486557 |\n",
      "\n",
      "                    Average val loss: 0.0006077804719097912|\n",
      "                    Val-Mae: 0.011277370154857635\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 581\n",
      "Start training for stock: 4516\n",
      "\n",
      "                    Average train loss: 0.00025040289387106895 | \n",
      "                    Train-Mae: 0.04006030037999153 |\n",
      "\n",
      "                    Average val loss: 0.11831703037023544|\n",
      "                    Val-Mae: 0.04099264740943909\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 582\n",
      "Start training for stock: 7593\n",
      "\n",
      "                    Average train loss: 0.008116950392723083 | \n",
      "                    Train-Mae: 0.025150304660201073 |\n",
      "\n",
      "                    Average val loss: 0.03716679662466049|\n",
      "                    Val-Mae: 0.029113005846738815\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 583\n",
      "Start training for stock: 4046\n",
      "\n",
      "                    Average train loss: 0.0004187862575054169 | \n",
      "                    Train-Mae: 0.025769047439098358 |\n",
      "\n",
      "                    Average val loss: 0.012998863123357296|\n",
      "                    Val-Mae: 0.021425003185868263\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 584\n",
      "Start training for stock: 9433\n",
      "\n",
      "                    Average train loss: 0.001075999215245247 | \n",
      "                    Train-Mae: 0.022626325488090515 |\n",
      "\n",
      "                    Average val loss: 0.010432831943035126|\n",
      "                    Val-Mae: 0.01826523244380951\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 585\n",
      "Start training for stock: 7751\n",
      "\n",
      "                    Average train loss: 0.0003797697275876999 | \n",
      "                    Train-Mae: 0.025527765974402428 |\n",
      "\n",
      "                    Average val loss: 0.007627520710229874|\n",
      "                    Val-Mae: 0.018413322046399117\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 586\n",
      "Start training for stock: 4919\n",
      "\n",
      "                    Average train loss: 0.0010704948008060456 | \n",
      "                    Train-Mae: 0.030685845762491226 |\n",
      "\n",
      "                    Average val loss: 0.0023977041710168123|\n",
      "                    Val-Mae: 0.01720432937145233\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 587\n",
      "Start training for stock: 5021\n",
      "\n",
      "                    Average train loss: 0.0009045658260583878 | \n",
      "                    Train-Mae: 0.038762252777814865 |\n",
      "\n",
      "                    Average val loss: 0.0030649593099951744|\n",
      "                    Val-Mae: 0.02210422046482563\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 588\n",
      "Start training for stock: 9658\n",
      "\n",
      "                    Average train loss: 0.0002637164294719696 | \n",
      "                    Train-Mae: 0.02580926939845085 |\n",
      "\n",
      "                    Average val loss: 0.0010635452345013618|\n",
      "                    Val-Mae: 0.015414688736200333\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 589\n",
      "Start training for stock: 2503\n",
      "\n",
      "                    Average train loss: 0.002212892323732376 | \n",
      "                    Train-Mae: 0.03357257321476936 |\n",
      "\n",
      "                    Average val loss: 0.030190594494342804|\n",
      "                    Val-Mae: 0.023239130154252052\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 590\n",
      "Start training for stock: 4425\n",
      "\n",
      "                    Average train loss: 0.0005779305845499039 | \n",
      "                    Train-Mae: 0.055437009781599045 |\n",
      "\n",
      "                    Average val loss: 0.0013322369195520878|\n",
      "                    Val-Mae: 0.02860509417951107\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 591\n",
      "Start training for stock: 4992\n",
      "\n",
      "                    Average train loss: 8.326458046212792e-06 | \n",
      "                    Train-Mae: 0.02754190005362034 |\n",
      "\n",
      "                    Average val loss: 0.014812898822128773|\n",
      "                    Val-Mae: 0.027795854955911636\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 592\n",
      "Start training for stock: 8018\n",
      "\n",
      "                    Average train loss: 7.5743230991065505e-06 | \n",
      "                    Train-Mae: 0.024332646280527115 |\n",
      "\n",
      "                    Average val loss: 0.00871692318469286|\n",
      "                    Val-Mae: 0.019573988392949104\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 593\n",
      "Start training for stock: 4963\n",
      "\n",
      "                    Average train loss: 0.000646943524479866 | \n",
      "                    Train-Mae: 0.026726286858320236 |\n",
      "\n",
      "                    Average val loss: 0.0007238007965497673|\n",
      "                    Val-Mae: 0.015508151613175869\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 594\n",
      "Start training for stock: 9506\n",
      "\n",
      "                    Average train loss: 9.206837974488735e-05 | \n",
      "                    Train-Mae: 0.025558048859238625 |\n",
      "\n",
      "                    Average val loss: 0.0001539257646072656|\n",
      "                    Val-Mae: 0.009309975430369377\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 595\n",
      "Start training for stock: 5191\n",
      "\n",
      "                    Average train loss: 4.3610390275716784e-05 | \n",
      "                    Train-Mae: 0.033352989703416824 |\n",
      "\n",
      "                    Average val loss: 0.003901252057403326|\n",
      "                    Val-Mae: 0.02125922404229641\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 596\n",
      "Start training for stock: 2053\n",
      "\n",
      "                    Average train loss: 0.00035958729684352873 | \n",
      "                    Train-Mae: 0.03445925563573837 |\n",
      "\n",
      "                    Average val loss: 0.00354128354229033|\n",
      "                    Val-Mae: 0.017200466245412827\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 597\n",
      "Start training for stock: 4507\n",
      "\n",
      "                    Average train loss: 0.00025470521301031114 | \n",
      "                    Train-Mae: 0.023613417521119118 |\n",
      "\n",
      "                    Average val loss: 0.006219261791557074|\n",
      "                    Val-Mae: 0.01974782533943653\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 598\n",
      "Start training for stock: 6849\n",
      "\n",
      "                    Average train loss: 0.0002785521931946278 | \n",
      "                    Train-Mae: 0.026185639202594757 |\n",
      "\n",
      "                    Average val loss: 0.006517508532851934|\n",
      "                    Val-Mae: 0.019265998154878616\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 599\n",
      "Start training for stock: 1333\n",
      "\n",
      "                    Average train loss: 0.0016189064085483551 | \n",
      "                    Train-Mae: 0.023437459021806717 |\n",
      "\n",
      "                    Average val loss: 0.010750600136816502|\n",
      "                    Val-Mae: 0.01849682256579399\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 600\n",
      "Start training for stock: 8713\n",
      "\n",
      "                    Average train loss: 0.00038176968693733217 | \n",
      "                    Train-Mae: 0.01972591131925583 |\n",
      "\n",
      "                    Average val loss: 0.02427089214324951|\n",
      "                    Val-Mae: 0.07645050436258316\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 601\n",
      "Start training for stock: 8596\n",
      "\n",
      "                    Average train loss: 0.00042710606008768083 | \n",
      "                    Train-Mae: 0.02313671074807644 |\n",
      "\n",
      "                    Average val loss: 0.0025993473827838898|\n",
      "                    Val-Mae: 0.013540990650653839\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 602\n",
      "Start training for stock: 7088\n",
      "\n",
      "                    Average train loss: 4.2708050459623335e-05 | \n",
      "                    Train-Mae: 0.028842736035585403 |\n",
      "\n",
      "                    Average val loss: 0.0006120647885836661|\n",
      "                    Val-Mae: 0.012916275300085545\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 603\n",
      "Start training for stock: 3843\n",
      "\n",
      "                    Average train loss: 0.00013531481847167014 | \n",
      "                    Train-Mae: 0.040773097425699234 |\n",
      "\n",
      "                    Average val loss: 0.043857622891664505|\n",
      "                    Val-Mae: 0.03480619192123413\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 604\n",
      "Start training for stock: 4801\n",
      "\n",
      "                    Average train loss: 0.0001251844223588705 | \n",
      "                    Train-Mae: 0.022985924035310745 |\n",
      "\n",
      "                    Average val loss: 0.01905747689306736|\n",
      "                    Val-Mae: 0.02281654253602028\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 605\n",
      "Start training for stock: 3288\n",
      "\n",
      "                    Average train loss: 0.0023057033121585847 | \n",
      "                    Train-Mae: 0.05113759636878967 |\n",
      "\n",
      "                    Average val loss: 0.017242254689335823|\n",
      "                    Val-Mae: 0.027503609657287598\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 606\n",
      "Start training for stock: 4187\n",
      "\n",
      "                    Average train loss: 0.00022454334422945975 | \n",
      "                    Train-Mae: 0.0334288664162159 |\n",
      "\n",
      "                    Average val loss: 0.0032936742063611746|\n",
      "                    Val-Mae: 0.02671784907579422\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 607\n",
      "Start training for stock: 2531\n",
      "\n",
      "                    Average train loss: 9.026562795042991e-05 | \n",
      "                    Train-Mae: 0.03582974150776863 |\n",
      "\n",
      "                    Average val loss: 0.03238392621278763|\n",
      "                    Val-Mae: 0.02990921586751938\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 608\n",
      "Start training for stock: 3983\n",
      "\n",
      "                    Average train loss: 0.00018795976415276528 | \n",
      "                    Train-Mae: 0.03534792736172676 |\n",
      "\n",
      "                    Average val loss: 0.008254910819232464|\n",
      "                    Val-Mae: 0.025930127128958702\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 609\n",
      "Start training for stock: 6289\n",
      "\n",
      "                    Average train loss: 0.000814017578959465 | \n",
      "                    Train-Mae: 0.03921687230467796 |\n",
      "\n",
      "                    Average val loss: 0.00930224359035492|\n",
      "                    Val-Mae: 0.01910291239619255\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 610\n",
      "Start training for stock: 9982\n",
      "\n",
      "                    Average train loss: 0.00019250178709626198 | \n",
      "                    Train-Mae: 0.026774775236845016 |\n",
      "\n",
      "                    Average val loss: 0.0012752267066389322|\n",
      "                    Val-Mae: 0.015799231827259064\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 611\n",
      "Start training for stock: 8031\n",
      "\n",
      "                    Average train loss: 3.302800236269832e-05 | \n",
      "                    Train-Mae: 0.02884557656943798 |\n",
      "\n",
      "                    Average val loss: 0.0012199331540614367|\n",
      "                    Val-Mae: 0.017033731564879417\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 612\n",
      "Start training for stock: 7244\n",
      "\n",
      "                    Average train loss: 2.3612910881638525e-05 | \n",
      "                    Train-Mae: 0.027546098455786705 |\n",
      "\n",
      "                    Average val loss: 0.002988427644595504|\n",
      "                    Val-Mae: 0.019746823236346245\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 613\n",
      "Start training for stock: 4365\n",
      "\n",
      "                    Average train loss: 0.000572768971323967 | \n",
      "                    Train-Mae: 0.06526248902082443 |\n",
      "\n",
      "                    Average val loss: 0.0007249811897054315|\n",
      "                    Val-Mae: 0.0209836233407259\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 614\n",
      "Start training for stock: 7148\n",
      "\n",
      "                    Average train loss: 0.0007063347101211548 | \n",
      "                    Train-Mae: 0.030575742945075035 |\n",
      "\n",
      "                    Average val loss: 0.002490988001227379|\n",
      "                    Val-Mae: 0.019404804334044456\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 615\n",
      "Start training for stock: 8097\n",
      "\n",
      "                    Average train loss: 0.00032787345349788666 | \n",
      "                    Train-Mae: 0.02492925338447094 |\n",
      "\n",
      "                    Average val loss: 0.0012662039371207356|\n",
      "                    Val-Mae: 0.022395199164748192\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 616\n",
      "Start training for stock: 8871\n",
      "\n",
      "                    Average train loss: 0.0006062395125627517 | \n",
      "                    Train-Mae: 0.03885975107550621 |\n",
      "\n",
      "                    Average val loss: 0.0003515829739626497|\n",
      "                    Val-Mae: 0.012849973514676094\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 617\n",
      "Start training for stock: 1973\n",
      "\n",
      "                    Average train loss: 0.0002461220882833004 | \n",
      "                    Train-Mae: 0.03397778794169426 |\n",
      "\n",
      "                    Average val loss: 0.006576807238161564|\n",
      "                    Val-Mae: 0.018652185797691345\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 618\n",
      "Start training for stock: 4553\n",
      "\n",
      "                    Average train loss: 0.00034316986799240115 | \n",
      "                    Train-Mae: 0.03242192789912224 |\n",
      "\n",
      "                    Average val loss: 0.01617247611284256|\n",
      "                    Val-Mae: 0.023678328841924667\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 619\n",
      "Start training for stock: 2372\n",
      "\n",
      "                    Average train loss: 0.003287787139415741 | \n",
      "                    Train-Mae: 0.039483003318309784 |\n",
      "\n",
      "                    Average val loss: 0.013120905496180058|\n",
      "                    Val-Mae: 0.027225088328123093\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 620\n",
      "Start training for stock: 4449\n",
      "\n",
      "                    Average train loss: 0.0013680817186832428 | \n",
      "                    Train-Mae: 0.05710874870419502 |\n",
      "\n",
      "                    Average val loss: 0.04373346269130707|\n",
      "                    Val-Mae: 0.05372399464249611\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 621\n",
      "Start training for stock: 4975\n",
      "\n",
      "                    Average train loss: 0.003761903643608093 | \n",
      "                    Train-Mae: 0.02292216569185257 |\n",
      "\n",
      "                    Average val loss: 0.0011246121721342206|\n",
      "                    Val-Mae: 0.017483726143836975\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 622\n",
      "Start training for stock: 6430\n",
      "\n",
      "                    Average train loss: 0.0002676036208868027 | \n",
      "                    Train-Mae: 0.02748151496052742 |\n",
      "\n",
      "                    Average val loss: 0.0029001659713685513|\n",
      "                    Val-Mae: 0.01725727692246437\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 623\n",
      "Start training for stock: 5929\n",
      "\n",
      "                    Average train loss: 9.459212888032198e-06 | \n",
      "                    Train-Mae: 0.02946910262107849 |\n",
      "\n",
      "                    Average val loss: 0.000983268953859806|\n",
      "                    Val-Mae: 0.01599346101284027\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 624\n",
      "Start training for stock: 3950\n",
      "\n",
      "                    Average train loss: 0.000530267022550106 | \n",
      "                    Train-Mae: 0.03698457404971123 |\n",
      "\n",
      "                    Average val loss: 0.0015978296287357807|\n",
      "                    Val-Mae: 0.01713738590478897\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 625\n",
      "Start training for stock: 1925\n",
      "\n",
      "                    Average train loss: 0.00019720453768968583 | \n",
      "                    Train-Mae: 0.042996104806661606 |\n",
      "\n",
      "                    Average val loss: 0.022000618278980255|\n",
      "                    Val-Mae: 0.023234322667121887\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 626\n",
      "Start training for stock: 6082\n",
      "\n",
      "                    Average train loss: 0.00016879040747880936 | \n",
      "                    Train-Mae: 0.03888237848877907 |\n",
      "\n",
      "                    Average val loss: 0.000808581942692399|\n",
      "                    Val-Mae: 0.016663456335663795\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 627\n",
      "Start training for stock: 4204\n",
      "\n",
      "                    Average train loss: 0.00013001139275729657 | \n",
      "                    Train-Mae: 0.022512663155794144 |\n",
      "\n",
      "                    Average val loss: 0.003293577814474702|\n",
      "                    Val-Mae: 0.016958972439169884\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 628\n",
      "Start training for stock: 4725\n",
      "\n",
      "                    Average train loss: 0.0005088227614760399 | \n",
      "                    Train-Mae: 0.06212490051984787 |\n",
      "\n",
      "                    Average val loss: 0.20158085227012634|\n",
      "                    Val-Mae: 0.05043487623333931\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 629\n",
      "Start training for stock: 8020\n",
      "\n",
      "                    Average train loss: 0.0014220303297042846 | \n",
      "                    Train-Mae: 0.03583371639251709 |\n",
      "\n",
      "                    Average val loss: 0.012620007619261742|\n",
      "                    Val-Mae: 0.020621417090296745\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 630\n",
      "Start training for stock: 3844\n",
      "\n",
      "                    Average train loss: 0.004035362303256989 | \n",
      "                    Train-Mae: 0.03525184467434883 |\n",
      "\n",
      "                    Average val loss: 0.005751455202698708|\n",
      "                    Val-Mae: 0.023891784250736237\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 631\n",
      "Start training for stock: 9438\n",
      "\n",
      "                    Average train loss: 0.00015085384249687194 | \n",
      "                    Train-Mae: 0.03802749142050743 |\n",
      "\n",
      "                    Average val loss: 0.04162047430872917|\n",
      "                    Val-Mae: 0.03515792638063431\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 632\n",
      "Start training for stock: 6383\n",
      "\n",
      "                    Average train loss: 0.0007432294636964798 | \n",
      "                    Train-Mae: 0.02562372200191021 |\n",
      "\n",
      "                    Average val loss: 0.02478949911892414|\n",
      "                    Val-Mae: 0.027289846912026405\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 633\n",
      "Start training for stock: 3687\n",
      "\n",
      "                    Average train loss: 0.00040066707879304886 | \n",
      "                    Train-Mae: 0.029131602495908737 |\n",
      "\n",
      "                    Average val loss: 0.0008583220187574625|\n",
      "                    Val-Mae: 0.01963621936738491\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 634\n",
      "Start training for stock: 1911\n",
      "\n",
      "                    Average train loss: 0.0013987119495868683 | \n",
      "                    Train-Mae: 0.042218808084726334 |\n",
      "\n",
      "                    Average val loss: 0.007316193077713251|\n",
      "                    Val-Mae: 0.02189350686967373\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 635\n",
      "Start training for stock: 8075\n",
      "\n",
      "                    Average train loss: 8.330632117576898e-06 | \n",
      "                    Train-Mae: 0.04544779285788536 |\n",
      "\n",
      "                    Average val loss: 0.025526881217956543|\n",
      "                    Val-Mae: 0.031581126153469086\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 636\n",
      "Start training for stock: 9990\n",
      "\n",
      "                    Average train loss: 0.00020105136558413506 | \n",
      "                    Train-Mae: 0.04881612956523895 |\n",
      "\n",
      "                    Average val loss: 0.001131129334680736|\n",
      "                    Val-Mae: 0.016436489298939705\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 637\n",
      "Start training for stock: 2676\n",
      "\n",
      "                    Average train loss: 3.013968002051115e-05 | \n",
      "                    Train-Mae: 0.022436082363128662 |\n",
      "\n",
      "                    Average val loss: 0.0048728762194514275|\n",
      "                    Val-Mae: 0.014144944958388805\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 638\n",
      "Start training for stock: 9432\n",
      "\n",
      "                    Average train loss: 2.9425551183521747e-05 | \n",
      "                    Train-Mae: 0.023660235106945038 |\n",
      "\n",
      "                    Average val loss: 0.005626040045171976|\n",
      "                    Val-Mae: 0.015218026004731655\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 639\n",
      "Start training for stock: 6723\n",
      "\n",
      "                    Average train loss: 2.6291108224540948e-05 | \n",
      "                    Train-Mae: 0.03467632830142975 |\n",
      "\n",
      "                    Average val loss: 0.004855932202190161|\n",
      "                    Val-Mae: 0.02351827546954155\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 640\n",
      "Start training for stock: 3608\n",
      "\n",
      "                    Average train loss: 0.00011135593056678772 | \n",
      "                    Train-Mae: 0.026460716500878334 |\n",
      "\n",
      "                    Average val loss: 0.007073141634464264|\n",
      "                    Val-Mae: 0.027398759499192238\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 641\n",
      "Start training for stock: 4617\n",
      "\n",
      "                    Average train loss: 5.1441197283566e-05 | \n",
      "                    Train-Mae: 0.0459703654050827 |\n",
      "\n",
      "                    Average val loss: 0.07652400434017181|\n",
      "                    Val-Mae: 0.038007598370313644\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 642\n",
      "Start training for stock: 6565\n",
      "\n",
      "                    Average train loss: 0.0022967395186424253 | \n",
      "                    Train-Mae: 0.031006725504994392 |\n",
      "\n",
      "                    Average val loss: 0.0011128608603030443|\n",
      "                    Val-Mae: 0.02661309950053692\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 643\n",
      "Start training for stock: 9005\n",
      "\n",
      "                    Average train loss: 0.0009948602318763733 | \n",
      "                    Train-Mae: 0.027877479791641235 |\n",
      "\n",
      "                    Average val loss: 0.0011180673027411103|\n",
      "                    Val-Mae: 0.01652052439749241\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 644\n",
      "Start training for stock: 6351\n",
      "\n",
      "                    Average train loss: 0.006178616881370545 | \n",
      "                    Train-Mae: 0.0538606159389019 |\n",
      "\n",
      "                    Average val loss: 0.005193097982555628|\n",
      "                    Val-Mae: 0.019743818789720535\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 645\n",
      "Start training for stock: 8804\n",
      "\n",
      "                    Average train loss: 8.169403299689293e-05 | \n",
      "                    Train-Mae: 0.030098965391516685 |\n",
      "\n",
      "                    Average val loss: 0.05370297655463219|\n",
      "                    Val-Mae: 0.03186428174376488\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 646\n",
      "Start training for stock: 3193\n",
      "\n",
      "                    Average train loss: 0.0010689012706279755 | \n",
      "                    Train-Mae: 0.03146626427769661 |\n",
      "\n",
      "                    Average val loss: 0.003724550362676382|\n",
      "                    Val-Mae: 0.022806474938988686\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 647\n",
      "Start training for stock: 4151\n",
      "\n",
      "                    Average train loss: 5.191060481593013e-06 | \n",
      "                    Train-Mae: 0.03830823674798012 |\n",
      "\n",
      "                    Average val loss: 0.029587190598249435|\n",
      "                    Val-Mae: 0.027708875015378\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 648\n",
      "Start training for stock: 9381\n",
      "\n",
      "                    Average train loss: 0.0007528901845216752 | \n",
      "                    Train-Mae: 0.03544854000210762 |\n",
      "\n",
      "                    Average val loss: 0.009190126322209835|\n",
      "                    Val-Mae: 0.02293054573237896\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 649\n",
      "Start training for stock: 7220\n",
      "\n",
      "                    Average train loss: 5.7418309152126314e-05 | \n",
      "                    Train-Mae: 0.04235566779971123 |\n",
      "\n",
      "                    Average val loss: 0.0020161387510597706|\n",
      "                    Val-Mae: 0.022504189983010292\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 650\n",
      "Start training for stock: 9037\n",
      "\n",
      "                    Average train loss: 0.0005961993709206581 | \n",
      "                    Train-Mae: 0.03785084933042526 |\n",
      "\n",
      "                    Average val loss: 0.025910470634698868|\n",
      "                    Val-Mae: 0.024901079013943672\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 651\n",
      "Start training for stock: 5020\n",
      "\n",
      "                    Average train loss: 0.0001809523068368435 | \n",
      "                    Train-Mae: 0.03251658380031586 |\n",
      "\n",
      "                    Average val loss: 0.003482560394331813|\n",
      "                    Val-Mae: 0.016318872570991516\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 652\n",
      "Start training for stock: 2613\n",
      "\n",
      "                    Average train loss: 1.4211280504241586e-05 | \n",
      "                    Train-Mae: 0.028229529038071632 |\n",
      "\n",
      "                    Average val loss: 0.0043496740981936455|\n",
      "                    Val-Mae: 0.016978275030851364\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 653\n",
      "Start training for stock: 9003\n",
      "\n",
      "                    Average train loss: 8.516007103025913e-05 | \n",
      "                    Train-Mae: 0.027282509952783585 |\n",
      "\n",
      "                    Average val loss: 0.0003122443740721792|\n",
      "                    Val-Mae: 0.013692585751414299\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 654\n",
      "Start training for stock: 2590\n",
      "\n",
      "                    Average train loss: 0.0003580120950937271 | \n",
      "                    Train-Mae: 0.03410791978240013 |\n",
      "\n",
      "                    Average val loss: 0.0017103509744629264|\n",
      "                    Val-Mae: 0.013762722723186016\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 655\n",
      "Start training for stock: 1515\n",
      "\n",
      "                    Average train loss: 7.750783115625381e-05 | \n",
      "                    Train-Mae: 0.03066670149564743 |\n",
      "\n",
      "                    Average val loss: 0.011209270916879177|\n",
      "                    Val-Mae: 0.027130533009767532\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 656\n",
      "Start training for stock: 9616\n",
      "\n",
      "                    Average train loss: 2.7558845467865466e-05 | \n",
      "                    Train-Mae: 0.044697295874357224 |\n",
      "\n",
      "                    Average val loss: 0.00539168156683445|\n",
      "                    Val-Mae: 0.023002810776233673\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 657\n",
      "Start training for stock: 3252\n",
      "\n",
      "                    Average train loss: 0.00022331632673740386 | \n",
      "                    Train-Mae: 0.020525168627500534 |\n",
      "\n",
      "                    Average val loss: 0.0015696508344262838|\n",
      "                    Val-Mae: 0.012156926095485687\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 658\n",
      "Start training for stock: 7702\n",
      "\n",
      "                    Average train loss: 0.0006549251824617386 | \n",
      "                    Train-Mae: 0.0457058809697628 |\n",
      "\n",
      "                    Average val loss: 0.02898624911904335|\n",
      "                    Val-Mae: 0.028622545301914215\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 659\n",
      "Start training for stock: 7510\n",
      "\n",
      "                    Average train loss: 0.0019385986030101775 | \n",
      "                    Train-Mae: 0.01878519356250763 |\n",
      "\n",
      "                    Average val loss: 0.0037491717375814915|\n",
      "                    Val-Mae: 0.013510344550013542\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 660\n",
      "Start training for stock: 2930\n",
      "\n",
      "                    Average train loss: 0.0005337675288319588 | \n",
      "                    Train-Mae: 0.025785908102989197 |\n",
      "\n",
      "                    Average val loss: 0.0006078342557884753|\n",
      "                    Val-Mae: 0.016194062307476997\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 661\n",
      "Start training for stock: 3232\n",
      "\n",
      "                    Average train loss: 0.0013741153478622438 | \n",
      "                    Train-Mae: 0.03236247971653938 |\n",
      "\n",
      "                    Average val loss: 0.00461294362321496|\n",
      "                    Val-Mae: 0.017544973641633987\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 662\n",
      "Start training for stock: 5331\n",
      "\n",
      "                    Average train loss: 0.000936967134475708 | \n",
      "                    Train-Mae: 0.0227707140147686 |\n",
      "\n",
      "                    Average val loss: 0.01349544245749712|\n",
      "                    Val-Mae: 0.02423091232776642\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 663\n",
      "Start training for stock: 8892\n",
      "\n",
      "                    Average train loss: 0.0002641700394451618 | \n",
      "                    Train-Mae: 0.03053579479455948 |\n",
      "\n",
      "                    Average val loss: 0.0331454873085022|\n",
      "                    Val-Mae: 0.022797241806983948\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 664\n",
      "Start training for stock: 7554\n",
      "\n",
      "                    Average train loss: 0.002012846767902374 | \n",
      "                    Train-Mae: 0.024178197607398033 |\n",
      "\n",
      "                    Average val loss: 0.0004651215858757496|\n",
      "                    Val-Mae: 0.011714448221027851\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 665\n",
      "Start training for stock: 6758\n",
      "\n",
      "                    Average train loss: 9.976931847631932e-05 | \n",
      "                    Train-Mae: 0.026038771495223045 |\n",
      "\n",
      "                    Average val loss: 0.0036290613934397697|\n",
      "                    Val-Mae: 0.019585009664297104\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 666\n",
      "Start training for stock: 4631\n",
      "\n",
      "                    Average train loss: 0.0005204491317272186 | \n",
      "                    Train-Mae: 0.03439956530928612 |\n",
      "\n",
      "                    Average val loss: 0.00036699228803627193|\n",
      "                    Val-Mae: 0.013521963730454445\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 667\n",
      "Start training for stock: 8344\n",
      "\n",
      "                    Average train loss: 6.629905663430691e-05 | \n",
      "                    Train-Mae: 0.024406641721725464 |\n",
      "\n",
      "                    Average val loss: 0.00039804054540582|\n",
      "                    Val-Mae: 0.014576445333659649\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 668\n",
      "Start training for stock: 6432\n",
      "\n",
      "                    Average train loss: 0.0031809827685356142 | \n",
      "                    Train-Mae: 0.034647151827812195 |\n",
      "\n",
      "                    Average val loss: 0.16115079820156097|\n",
      "                    Val-Mae: 0.04570399224758148\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 669\n",
      "Start training for stock: 9955\n",
      "\n",
      "                    Average train loss: 0.006214926242828369 | \n",
      "                    Train-Mae: 0.07030323147773743 |\n",
      "\n",
      "                    Average val loss: 0.22072312235832214|\n",
      "                    Val-Mae: 0.04602169990539551\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 670\n",
      "Start training for stock: 4053\n",
      "\n",
      "                    Average train loss: 0.00010069730691611767 | \n",
      "                    Train-Mae: 0.039353858679533005 |\n",
      "\n",
      "                    Average val loss: 0.018394701182842255|\n",
      "                    Val-Mae: 0.046956270933151245\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 671\n",
      "Start training for stock: 5851\n",
      "\n",
      "                    Average train loss: 0.0012157667428255082 | \n",
      "                    Train-Mae: 0.026930412277579308 |\n",
      "\n",
      "                    Average val loss: 0.007067208644002676|\n",
      "                    Val-Mae: 0.02361323870718479\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 672\n",
      "Start training for stock: 4681\n",
      "\n",
      "                    Average train loss: 0.0042539858818054195 | \n",
      "                    Train-Mae: 0.027166109532117844 |\n",
      "\n",
      "                    Average val loss: 0.016830747947096825|\n",
      "                    Val-Mae: 0.02827940694987774\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 673\n",
      "Start training for stock: 8439\n",
      "\n",
      "                    Average train loss: 0.0008407553285360337 | \n",
      "                    Train-Mae: 0.03235861286520958 |\n",
      "\n",
      "                    Average val loss: 0.004400166217237711|\n",
      "                    Val-Mae: 0.024351388216018677\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 674\n",
      "Start training for stock: 4088\n",
      "\n",
      "                    Average train loss: 0.0003206458315253258 | \n",
      "                    Train-Mae: 0.030844952911138535 |\n",
      "\n",
      "                    Average val loss: 0.005883658770471811|\n",
      "                    Val-Mae: 0.018171917647123337\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 675\n",
      "Start training for stock: 3228\n",
      "\n",
      "                    Average train loss: 0.0008249840140342712 | \n",
      "                    Train-Mae: 0.03399742767214775 |\n",
      "\n",
      "                    Average val loss: 0.003658298635855317|\n",
      "                    Val-Mae: 0.01836216449737549\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 676\n",
      "Start training for stock: 4078\n",
      "\n",
      "                    Average train loss: 0.0003296154737472534 | \n",
      "                    Train-Mae: 0.024620935320854187 |\n",
      "\n",
      "                    Average val loss: 0.0020577297545969486|\n",
      "                    Val-Mae: 0.017280712723731995\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 677\n",
      "Start training for stock: 1812\n",
      "\n",
      "                    Average train loss: 0.00019329838454723358 | \n",
      "                    Train-Mae: 0.024944297969341278 |\n",
      "\n",
      "                    Average val loss: 0.0044374591670930386|\n",
      "                    Val-Mae: 0.017679274082183838\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 678\n",
      "Start training for stock: 6966\n",
      "\n",
      "                    Average train loss: 0.0010284658521413804 | \n",
      "                    Train-Mae: 0.039551254361867905 |\n",
      "\n",
      "                    Average val loss: 0.0361361987888813|\n",
      "                    Val-Mae: 0.04364384338259697\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 679\n",
      "Start training for stock: 4971\n",
      "\n",
      "                    Average train loss: 0.00017699263989925384 | \n",
      "                    Train-Mae: 0.029843125492334366 |\n",
      "\n",
      "                    Average val loss: 0.001143778208643198|\n",
      "                    Val-Mae: 0.02498832531273365\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 680\n",
      "Start training for stock: 8914\n",
      "\n",
      "                    Average train loss: 0.0005562184378504753 | \n",
      "                    Train-Mae: 0.023343587294220924 |\n",
      "\n",
      "                    Average val loss: 0.0021843495778739452|\n",
      "                    Val-Mae: 0.021350916475057602\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 681\n",
      "Start training for stock: 9517\n",
      "\n",
      "                    Average train loss: 9.46895033121109e-05 | \n",
      "                    Train-Mae: 0.03758171200752258 |\n",
      "\n",
      "                    Average val loss: 0.0020645821932703257|\n",
      "                    Val-Mae: 0.027272434905171394\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 682\n",
      "Start training for stock: 4480\n",
      "\n",
      "                    Average train loss: 0.0004993099346756935 | \n",
      "                    Train-Mae: 0.0502103716135025 |\n",
      "\n",
      "                    Average val loss: 0.0022712291684001684|\n",
      "                    Val-Mae: 0.02867482416331768\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 683\n",
      "Start training for stock: 4042\n",
      "\n",
      "                    Average train loss: 0.0004436764121055603 | \n",
      "                    Train-Mae: 0.03334014490246773 |\n",
      "\n",
      "                    Average val loss: 0.01954656094312668|\n",
      "                    Val-Mae: 0.02562182955443859\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 684\n",
      "Start training for stock: 9278\n",
      "\n",
      "                    Average train loss: 0.004614806771278381 | \n",
      "                    Train-Mae: 0.028567185625433922 |\n",
      "\n",
      "                    Average val loss: 0.008669187314808369|\n",
      "                    Val-Mae: 0.01519065536558628\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 685\n",
      "Start training for stock: 4704\n",
      "\n",
      "                    Average train loss: 0.001072842851281166 | \n",
      "                    Train-Mae: 0.02782011777162552 |\n",
      "\n",
      "                    Average val loss: 0.003981787711381912|\n",
      "                    Val-Mae: 0.015013329684734344\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 686\n",
      "Start training for stock: 9532\n",
      "\n",
      "                    Average train loss: 7.045910693705082e-05 | \n",
      "                    Train-Mae: 0.02176402509212494 |\n",
      "\n",
      "                    Average val loss: 0.0018740174127742648|\n",
      "                    Val-Mae: 0.013721393421292305\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 687\n",
      "Start training for stock: 4452\n",
      "\n",
      "                    Average train loss: 8.333483710885048e-05 | \n",
      "                    Train-Mae: 0.022457052022218704 |\n",
      "\n",
      "                    Average val loss: 0.022411717101931572|\n",
      "                    Val-Mae: 0.021008774638175964\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 688\n",
      "Start training for stock: 9513\n",
      "\n",
      "                    Average train loss: 0.0008573886752128601 | \n",
      "                    Train-Mae: 0.02226368710398674 |\n",
      "\n",
      "                    Average val loss: 0.004189373459666967|\n",
      "                    Val-Mae: 0.015585795044898987\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 689\n",
      "Start training for stock: 4092\n",
      "\n",
      "                    Average train loss: 0.00026766842231154444 | \n",
      "                    Train-Mae: 0.03091958723962307 |\n",
      "\n",
      "                    Average val loss: 0.0034695686772465706|\n",
      "                    Val-Mae: 0.02169562689960003\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 690\n",
      "Start training for stock: 2288\n",
      "\n",
      "                    Average train loss: 6.326854228973389e-05 | \n",
      "                    Train-Mae: 0.02553633414208889 |\n",
      "\n",
      "                    Average val loss: 0.00020631610823329538|\n",
      "                    Val-Mae: 0.00906592607498169\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 691\n",
      "Start training for stock: 4008\n",
      "\n",
      "                    Average train loss: 0.00022521549835801123 | \n",
      "                    Train-Mae: 0.03594079986214638 |\n",
      "\n",
      "                    Average val loss: 0.001450734562240541|\n",
      "                    Val-Mae: 0.012761218473315239\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 692\n",
      "Start training for stock: 4477\n",
      "\n",
      "                    Average train loss: 6.539570633322e-05 | \n",
      "                    Train-Mae: 0.05387664958834648 |\n",
      "\n",
      "                    Average val loss: 0.0021464808378368616|\n",
      "                    Val-Mae: 0.033999424427747726\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 693\n",
      "Start training for stock: 3040\n",
      "\n",
      "                    Average train loss: 0.00010915465652942657 | \n",
      "                    Train-Mae: 0.04703710600733757 |\n",
      "\n",
      "                    Average val loss: 0.040125492960214615|\n",
      "                    Val-Mae: 0.030956005677580833\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 694\n",
      "Start training for stock: 7203\n",
      "\n",
      "                    Average train loss: 0.0025622254610061647 | \n",
      "                    Train-Mae: 0.024311017245054245 |\n",
      "\n",
      "                    Average val loss: 0.002305271802470088|\n",
      "                    Val-Mae: 0.019888682290911674\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 695\n",
      "Start training for stock: 7947\n",
      "\n",
      "                    Average train loss: 0.00042786605656147 | \n",
      "                    Train-Mae: 0.020046329125761986 |\n",
      "\n",
      "                    Average val loss: 0.004543851129710674|\n",
      "                    Val-Mae: 0.01606392115354538\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 696\n",
      "Start training for stock: 4235\n",
      "\n",
      "                    Average train loss: 4.3103299103677275e-05 | \n",
      "                    Train-Mae: 0.030525723472237587 |\n",
      "\n",
      "                    Average val loss: 0.003092734608799219|\n",
      "                    Val-Mae: 0.025564933195710182\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 697\n",
      "Start training for stock: 6789\n",
      "\n",
      "                    Average train loss: 0.0001046640332788229 | \n",
      "                    Train-Mae: 0.027920452877879143 |\n",
      "\n",
      "                    Average val loss: 0.008206487633287907|\n",
      "                    Val-Mae: 0.026406262069940567\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 698\n",
      "Start training for stock: 9064\n",
      "\n",
      "                    Average train loss: 6.4849265618249775e-06 | \n",
      "                    Train-Mae: 0.02187771536409855 |\n",
      "\n",
      "                    Average val loss: 0.014074563048779964|\n",
      "                    Val-Mae: 0.019946949556469917\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 699\n",
      "Start training for stock: 6960\n",
      "\n",
      "                    Average train loss: 0.0002907932735979557 | \n",
      "                    Train-Mae: 0.034235093742609024 |\n",
      "\n",
      "                    Average val loss: 0.07298506796360016|\n",
      "                    Val-Mae: 0.035890329629182816\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 700\n",
      "Start training for stock: 1893\n",
      "\n",
      "                    Average train loss: 0.000708242803812027 | \n",
      "                    Train-Mae: 0.04311177879571915 |\n",
      "\n",
      "                    Average val loss: 0.07263188064098358|\n",
      "                    Val-Mae: 0.03588973730802536\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 701\n",
      "Start training for stock: 7826\n",
      "\n",
      "                    Average train loss: 0.0011794013530015946 | \n",
      "                    Train-Mae: 0.036236245185136795 |\n",
      "\n",
      "                    Average val loss: 0.006284618750214577|\n",
      "                    Val-Mae: 0.030652040615677834\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 702\n",
      "Start training for stock: 7936\n",
      "\n",
      "                    Average train loss: 0.003953237533569336 | \n",
      "                    Train-Mae: 0.030896950513124466 |\n",
      "\n",
      "                    Average val loss: 0.14118123054504395|\n",
      "                    Val-Mae: 0.05231820046901703\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 703\n",
      "Start training for stock: 5631\n",
      "\n",
      "                    Average train loss: 0.000615101084113121 | \n",
      "                    Train-Mae: 0.031148036941885948 |\n",
      "\n",
      "                    Average val loss: 0.00612671859562397|\n",
      "                    Val-Mae: 0.02500808797776699\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 704\n",
      "Start training for stock: 6556\n",
      "\n",
      "                    Average train loss: 0.0001049876306205988 | \n",
      "                    Train-Mae: 0.026089265942573547 |\n",
      "\n",
      "                    Average val loss: 0.002872136188670993|\n",
      "                    Val-Mae: 0.020332302898168564\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 705\n",
      "Start training for stock: 3547\n",
      "\n",
      "                    Average train loss: 4.475023131817579e-05 | \n",
      "                    Train-Mae: 0.025263138115406036 |\n",
      "\n",
      "                    Average val loss: 0.0022661606781184673|\n",
      "                    Val-Mae: 0.023026486858725548\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 706\n",
      "Start training for stock: 6070\n",
      "\n",
      "                    Average train loss: 8.207247592508792e-05 | \n",
      "                    Train-Mae: 0.03639448434114456 |\n",
      "\n",
      "                    Average val loss: 0.004628217313438654|\n",
      "                    Val-Mae: 0.0286098662763834\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 707\n",
      "Start training for stock: 6104\n",
      "\n",
      "                    Average train loss: 6.93117966875434e-05 | \n",
      "                    Train-Mae: 0.024487342685461044 |\n",
      "\n",
      "                    Average val loss: 0.0011317147873342037|\n",
      "                    Val-Mae: 0.017702631652355194\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 708\n",
      "Start training for stock: 2209\n",
      "\n",
      "                    Average train loss: 4.915006458759308e-05 | \n",
      "                    Train-Mae: 0.022853320464491844 |\n",
      "\n",
      "                    Average val loss: 0.002964271930977702|\n",
      "                    Val-Mae: 0.014104839414358139\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 709\n",
      "Start training for stock: 6278\n",
      "\n",
      "                    Average train loss: 0.00041617013514041903 | \n",
      "                    Train-Mae: 0.02924942597746849 |\n",
      "\n",
      "                    Average val loss: 0.0010358347790315747|\n",
      "                    Val-Mae: 0.015263826586306095\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 710\n",
      "Start training for stock: 6440\n",
      "\n",
      "                    Average train loss: 0.0021032963693141935 | \n",
      "                    Train-Mae: 0.02901742234826088 |\n",
      "\n",
      "                    Average val loss: 0.024633662775158882|\n",
      "                    Val-Mae: 0.03015405684709549\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 711\n",
      "Start training for stock: 8530\n",
      "\n",
      "                    Average train loss: 0.0018879538774490357 | \n",
      "                    Train-Mae: 0.02804277464747429 |\n",
      "\n",
      "                    Average val loss: 0.0020591337233781815|\n",
      "                    Val-Mae: 0.017353156581521034\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 712\n",
      "Start training for stock: 6369\n",
      "\n",
      "                    Average train loss: 0.00010656454600393772 | \n",
      "                    Train-Mae: 0.019908394664525986 |\n",
      "\n",
      "                    Average val loss: 0.0007654100772924721|\n",
      "                    Val-Mae: 0.013843413442373276\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 713\n",
      "Start training for stock: 9934\n",
      "\n",
      "                    Average train loss: 0.0014365383982658387 | \n",
      "                    Train-Mae: 0.03383254632353783 |\n",
      "\n",
      "                    Average val loss: 0.019617661833763123|\n",
      "                    Val-Mae: 0.02012108452618122\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 714\n",
      "Start training for stock: 4526\n",
      "\n",
      "                    Average train loss: 0.0003286170214414597 | \n",
      "                    Train-Mae: 0.03193319961428642 |\n",
      "\n",
      "                    Average val loss: 0.0009178461041301489|\n",
      "                    Val-Mae: 0.01623428426682949\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 715\n",
      "Start training for stock: 6703\n",
      "\n",
      "                    Average train loss: 2.0708658266812562e-05 | \n",
      "                    Train-Mae: 0.021415701135993004 |\n",
      "\n",
      "                    Average val loss: 0.000427655759267509|\n",
      "                    Val-Mae: 0.014712768606841564\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 716\n",
      "Start training for stock: 7952\n",
      "\n",
      "                    Average train loss: 1.584708457812667e-05 | \n",
      "                    Train-Mae: 0.023238105699419975 |\n",
      "\n",
      "                    Average val loss: 0.0008624853217042983|\n",
      "                    Val-Mae: 0.017561230808496475\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 717\n",
      "Start training for stock: 4714\n",
      "\n",
      "                    Average train loss: 3.342284820973873e-05 | \n",
      "                    Train-Mae: 0.021057303994894028 |\n",
      "\n",
      "                    Average val loss: 0.0004563183756545186|\n",
      "                    Val-Mae: 0.015682412311434746\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 718\n",
      "Start training for stock: 2768\n",
      "\n",
      "                    Average train loss: 0.0030048799514770506 | \n",
      "                    Train-Mae: 0.04396235570311546 |\n",
      "\n",
      "                    Average val loss: 0.037287384271621704|\n",
      "                    Val-Mae: 0.05842547118663788\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 719\n",
      "Start training for stock: 1429\n",
      "\n",
      "                    Average train loss: 8.218441158533096e-05 | \n",
      "                    Train-Mae: 0.02886563166975975 |\n",
      "\n",
      "                    Average val loss: 0.011171868070960045|\n",
      "                    Val-Mae: 0.0218003261834383\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 720\n",
      "Start training for stock: 9055\n",
      "\n",
      "                    Average train loss: 0.00023872151970863342 | \n",
      "                    Train-Mae: 0.023199547082185745 |\n",
      "\n",
      "                    Average val loss: 0.0024868904147297144|\n",
      "                    Val-Mae: 0.01971958577632904\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 721\n",
      "Start training for stock: 6844\n",
      "\n",
      "                    Average train loss: 2.399386838078499e-05 | \n",
      "                    Train-Mae: 0.026047924533486366 |\n",
      "\n",
      "                    Average val loss: 0.0008428760920651257|\n",
      "                    Val-Mae: 0.022435978055000305\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 722\n",
      "Start training for stock: 2811\n",
      "\n",
      "                    Average train loss: 0.00022566137835383415 | \n",
      "                    Train-Mae: 0.03161649778485298 |\n",
      "\n",
      "                    Average val loss: 0.002600474515929818|\n",
      "                    Val-Mae: 0.013631124049425125\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 723\n",
      "Start training for stock: 2120\n",
      "\n",
      "                    Average train loss: 0.00014463510364294053 | \n",
      "                    Train-Mae: 0.026256030425429344 |\n",
      "\n",
      "                    Average val loss: 0.0008337820181623101|\n",
      "                    Val-Mae: 0.01510437298566103\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 724\n",
      "Start training for stock: 4168\n",
      "\n",
      "                    Average train loss: 6.0152108781039714e-05 | \n",
      "                    Train-Mae: 0.03860778361558914 |\n",
      "\n",
      "                    Average val loss: 0.001652418402954936|\n",
      "                    Val-Mae: 0.030921071767807007\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 725\n",
      "Start training for stock: 2705\n",
      "\n",
      "                    Average train loss: 3.391728096175939e-06 | \n",
      "                    Train-Mae: 0.03627706319093704 |\n",
      "\n",
      "                    Average val loss: 0.06196879222989082|\n",
      "                    Val-Mae: 0.028448475524783134\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 726\n",
      "Start training for stock: 8919\n",
      "\n",
      "                    Average train loss: 0.004075128138065338 | \n",
      "                    Train-Mae: 0.04810188338160515 |\n",
      "\n",
      "                    Average val loss: 0.00170921313110739|\n",
      "                    Val-Mae: 0.02018703706562519\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 727\n",
      "Start training for stock: 3110\n",
      "\n",
      "                    Average train loss: 1.9551906734704972e-05 | \n",
      "                    Train-Mae: 0.03520073741674423 |\n",
      "\n",
      "                    Average val loss: 0.006317023187875748|\n",
      "                    Val-Mae: 0.02233613282442093\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 728\n",
      "Start training for stock: 4543\n",
      "\n",
      "                    Average train loss: 0.0016849948465824127 | \n",
      "                    Train-Mae: 0.040904611349105835 |\n",
      "\n",
      "                    Average val loss: 0.002501691924408078|\n",
      "                    Val-Mae: 0.0171893872320652\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 729\n",
      "Start training for stock: 9979\n",
      "\n",
      "                    Average train loss: 0.0006526686251163482 | \n",
      "                    Train-Mae: 0.02911565452814102 |\n",
      "\n",
      "                    Average val loss: 0.013601424172520638|\n",
      "                    Val-Mae: 0.022388968616724014\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 730\n",
      "Start training for stock: 1873\n",
      "\n",
      "                    Average train loss: 0.0018918204307556152 | \n",
      "                    Train-Mae: 0.02395600453019142 |\n",
      "\n",
      "                    Average val loss: 0.010346840135753155|\n",
      "                    Val-Mae: 0.02278715744614601\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 731\n",
      "Start training for stock: 6627\n",
      "\n",
      "                    Average train loss: 0.000444977693259716 | \n",
      "                    Train-Mae: 0.028348227962851524 |\n",
      "\n",
      "                    Average val loss: 0.0017263523768633604|\n",
      "                    Val-Mae: 0.03133713826537132\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 732\n",
      "Start training for stock: 3482\n",
      "\n",
      "                    Average train loss: 0.0009394906461238861 | \n",
      "                    Train-Mae: 0.03255724906921387 |\n",
      "\n",
      "                    Average val loss: 0.0026442077942192554|\n",
      "                    Val-Mae: 0.019803525879979134\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 733\n",
      "Start training for stock: 3628\n",
      "\n",
      "                    Average train loss: 5.9411199763417245e-05 | \n",
      "                    Train-Mae: 0.04137331247329712 |\n",
      "\n",
      "                    Average val loss: 0.009712968952953815|\n",
      "                    Val-Mae: 0.03734071925282478\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 734\n",
      "Start training for stock: 6058\n",
      "\n",
      "                    Average train loss: 0.0020152118802070616 | \n",
      "                    Train-Mae: 0.05130339041352272 |\n",
      "\n",
      "                    Average val loss: 0.012771666049957275|\n",
      "                    Val-Mae: 0.029599158093333244\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 735\n",
      "Start training for stock: 8136\n",
      "\n",
      "                    Average train loss: 0.00046640649437904356 | \n",
      "                    Train-Mae: 0.028132174164056778 |\n",
      "\n",
      "                    Average val loss: 0.009456037543714046|\n",
      "                    Val-Mae: 0.0259046982973814\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 736\n",
      "Start training for stock: 2281\n",
      "\n",
      "                    Average train loss: 8.663539774715901e-05 | \n",
      "                    Train-Mae: 0.02052229456603527 |\n",
      "\n",
      "                    Average val loss: 0.006304765120148659|\n",
      "                    Val-Mae: 0.018035143613815308\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 737\n",
      "Start training for stock: 7082\n",
      "\n",
      "                    Average train loss: 6.914227269589901e-05 | \n",
      "                    Train-Mae: 0.04274012893438339 |\n",
      "\n",
      "                    Average val loss: 0.0037412322126328945|\n",
      "                    Val-Mae: 0.044919952750205994\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 738\n",
      "Start training for stock: 6232\n",
      "\n",
      "                    Average train loss: 0.00014746381901204587 | \n",
      "                    Train-Mae: 0.035733841359615326 |\n",
      "\n",
      "                    Average val loss: 0.0009109857492148876|\n",
      "                    Val-Mae: 0.02175546996295452\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 739\n",
      "Start training for stock: 1766\n",
      "\n",
      "                    Average train loss: 0.0005942734330892563 | \n",
      "                    Train-Mae: 0.019376691430807114 |\n",
      "\n",
      "                    Average val loss: 0.012869970872998238|\n",
      "                    Val-Mae: 0.020338794216513634\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 740\n",
      "Start training for stock: 1801\n",
      "\n",
      "                    Average train loss: 0.0002668627724051475 | \n",
      "                    Train-Mae: 0.025749415159225464 |\n",
      "\n",
      "                    Average val loss: 0.00027239532209932804|\n",
      "                    Val-Mae: 0.011892429552972317\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 741\n",
      "Start training for stock: 9948\n",
      "\n",
      "                    Average train loss: 9.700480848550796e-05 | \n",
      "                    Train-Mae: 0.022459911182522774 |\n",
      "\n",
      "                    Average val loss: 0.014857782050967216|\n",
      "                    Val-Mae: 0.02035140059888363\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 742\n",
      "Start training for stock: 3549\n",
      "\n",
      "                    Average train loss: 0.003066886365413666 | \n",
      "                    Train-Mae: 0.054444462060928345 |\n",
      "\n",
      "                    Average val loss: 0.07232822477817535|\n",
      "                    Val-Mae: 0.03524070978164673\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 743\n",
      "Start training for stock: 9232\n",
      "\n",
      "                    Average train loss: 9.509955532848835e-05 | \n",
      "                    Train-Mae: 0.03470270708203316 |\n",
      "\n",
      "                    Average val loss: 0.0443132258951664|\n",
      "                    Val-Mae: 0.03279444947838783\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 744\n",
      "Start training for stock: 7981\n",
      "\n",
      "                    Average train loss: 0.007567102313041687 | \n",
      "                    Train-Mae: 0.050611235201358795 |\n",
      "\n",
      "                    Average val loss: 0.0013941634679213166|\n",
      "                    Val-Mae: 0.014855028130114079\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 745\n",
      "Start training for stock: 9202\n",
      "\n",
      "                    Average train loss: 0.0007996045798063278 | \n",
      "                    Train-Mae: 0.025967536494135857 |\n",
      "\n",
      "                    Average val loss: 0.0011513069039210677|\n",
      "                    Val-Mae: 0.018075237050652504\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 746\n",
      "Start training for stock: 8558\n",
      "\n",
      "                    Average train loss: 0.000453532375395298 | \n",
      "                    Train-Mae: 0.021149834617972374 |\n",
      "\n",
      "                    Average val loss: 0.0002476294175721705|\n",
      "                    Val-Mae: 0.011491754092276096\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 747\n",
      "Start training for stock: 3199\n",
      "\n",
      "                    Average train loss: 0.00023200374096632003 | \n",
      "                    Train-Mae: 0.02591528929769993 |\n",
      "\n",
      "                    Average val loss: 0.0002602778549771756|\n",
      "                    Val-Mae: 0.010525364428758621\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 748\n",
      "Start training for stock: 6924\n",
      "\n",
      "                    Average train loss: 0.00109786756336689 | \n",
      "                    Train-Mae: 0.0284549780189991 |\n",
      "\n",
      "                    Average val loss: 0.015680566430091858|\n",
      "                    Val-Mae: 0.024166787043213844\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 749\n",
      "Start training for stock: 7701\n",
      "\n",
      "                    Average train loss: 0.00042620744556188584 | \n",
      "                    Train-Mae: 0.047473274171352386 |\n",
      "\n",
      "                    Average val loss: 0.030205441638827324|\n",
      "                    Val-Mae: 0.0287796538323164\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 750\n",
      "Start training for stock: 7048\n",
      "\n",
      "                    Average train loss: 0.0017330920696258544 | \n",
      "                    Train-Mae: 0.03742820397019386 |\n",
      "\n",
      "                    Average val loss: 0.0027567902579903603|\n",
      "                    Val-Mae: 0.03402165696024895\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 751\n",
      "Start training for stock: 8343\n",
      "\n",
      "                    Average train loss: 0.0005595278739929199 | \n",
      "                    Train-Mae: 0.022692130878567696 |\n",
      "\n",
      "                    Average val loss: 0.00041475475882180035|\n",
      "                    Val-Mae: 0.011083322577178478\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 752\n",
      "Start training for stock: 3994\n",
      "\n",
      "                    Average train loss: 0.0004925212264060974 | \n",
      "                    Train-Mae: 0.04155593365430832 |\n",
      "\n",
      "                    Average val loss: 0.0022222637198865414|\n",
      "                    Val-Mae: 0.030622731894254684\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 753\n",
      "Start training for stock: 8399\n",
      "\n",
      "                    Average train loss: 3.155442187562585e-05 | \n",
      "                    Train-Mae: 0.018615376204252243 |\n",
      "\n",
      "                    Average val loss: 0.000248292664764449|\n",
      "                    Val-Mae: 0.011165443807840347\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 754\n",
      "Start training for stock: 4689\n",
      "\n",
      "                    Average train loss: 0.0002418508566915989 | \n",
      "                    Train-Mae: 0.028400471433997154 |\n",
      "\n",
      "                    Average val loss: 0.008738897740840912|\n",
      "                    Val-Mae: 0.02523951232433319\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 755\n",
      "Start training for stock: 6875\n",
      "\n",
      "                    Average train loss: 0.0002411770261824131 | \n",
      "                    Train-Mae: 0.03420047089457512 |\n",
      "\n",
      "                    Average val loss: 0.008850621990859509|\n",
      "                    Val-Mae: 0.025903770700097084\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 756\n",
      "Start training for stock: 2801\n",
      "\n",
      "                    Average train loss: 0.0003200492262840271 | \n",
      "                    Train-Mae: 0.0400373600423336 |\n",
      "\n",
      "                    Average val loss: 0.005677263252437115|\n",
      "                    Val-Mae: 0.022318558767437935\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 757\n",
      "Start training for stock: 7222\n",
      "\n",
      "                    Average train loss: 0.0003183124214410782 | \n",
      "                    Train-Mae: 0.04033110290765762 |\n",
      "\n",
      "                    Average val loss: 0.027276797220110893|\n",
      "                    Val-Mae: 0.02613581158220768\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 758\n",
      "Start training for stock: 6988\n",
      "\n",
      "                    Average train loss: 0.0017696425318717956 | \n",
      "                    Train-Mae: 0.029184864833950996 |\n",
      "\n",
      "                    Average val loss: 0.0019710410851985216|\n",
      "                    Val-Mae: 0.016785359010100365\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 759\n",
      "Start training for stock: 7508\n",
      "\n",
      "                    Average train loss: 0.0008504426479339599 | \n",
      "                    Train-Mae: 0.029135819524526596 |\n",
      "\n",
      "                    Average val loss: 0.01422757375985384|\n",
      "                    Val-Mae: 0.02824326790869236\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 760\n",
      "Start training for stock: 8425\n",
      "\n",
      "                    Average train loss: 4.75439359433949e-06 | \n",
      "                    Train-Mae: 0.02702510356903076 |\n",
      "\n",
      "                    Average val loss: 0.0007625923026353121|\n",
      "                    Val-Mae: 0.013886312954127789\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 761\n",
      "Start training for stock: 6143\n",
      "\n",
      "                    Average train loss: 0.0028023135662078856 | \n",
      "                    Train-Mae: 0.029032940044999123 |\n",
      "\n",
      "                    Average val loss: 0.1060074120759964|\n",
      "                    Val-Mae: 0.040005773305892944\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 762\n",
      "Start training for stock: 5332\n",
      "\n",
      "                    Average train loss: 0.0006036392599344253 | \n",
      "                    Train-Mae: 0.046827107667922974 |\n",
      "\n",
      "                    Average val loss: 0.010304887779057026|\n",
      "                    Val-Mae: 0.02502080798149109\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 763\n",
      "Start training for stock: 5938\n",
      "\n",
      "                    Average train loss: 0.00023199593648314475 | \n",
      "                    Train-Mae: 0.028610246255993843 |\n",
      "\n",
      "                    Average val loss: 0.025723235681653023|\n",
      "                    Val-Mae: 0.02747275121510029\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 764\n",
      "Start training for stock: 4826\n",
      "\n",
      "                    Average train loss: 0.0006948298215866089 | \n",
      "                    Train-Mae: 0.023025497794151306 |\n",
      "\n",
      "                    Average val loss: 0.0001408387179253623|\n",
      "                    Val-Mae: 0.008932949043810368\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 765\n",
      "Start training for stock: 6144\n",
      "\n",
      "                    Average train loss: 0.00019606269896030426 | \n",
      "                    Train-Mae: 0.032546184957027435 |\n",
      "\n",
      "                    Average val loss: 0.000787772296462208|\n",
      "                    Val-Mae: 0.020456528291106224\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 766\n",
      "Start training for stock: 9045\n",
      "\n",
      "                    Average train loss: 7.557203993201256e-05 | \n",
      "                    Train-Mae: 0.025148173794150352 |\n",
      "\n",
      "                    Average val loss: 0.003615090623497963|\n",
      "                    Val-Mae: 0.02122201956808567\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 767\n",
      "Start training for stock: 4063\n",
      "\n",
      "                    Average train loss: 0.0007106970995664596 | \n",
      "                    Train-Mae: 0.023549919947981834 |\n",
      "\n",
      "                    Average val loss: 0.0002814467006828636|\n",
      "                    Val-Mae: 0.013285570777952671\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 768\n",
      "Start training for stock: 9418\n",
      "\n",
      "                    Average train loss: 0.001283172369003296 | \n",
      "                    Train-Mae: 0.03992588445544243 |\n",
      "\n",
      "                    Average val loss: 0.0013080339413136244|\n",
      "                    Val-Mae: 0.026188068091869354\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 769\n",
      "Start training for stock: 2185\n",
      "\n",
      "                    Average train loss: 6.54666032642126e-05 | \n",
      "                    Train-Mae: 0.02558363415300846 |\n",
      "\n",
      "                    Average val loss: 0.0007226452580653131|\n",
      "                    Val-Mae: 0.0165404062718153\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 770\n",
      "Start training for stock: 9470\n",
      "\n",
      "                    Average train loss: 0.0001362750492990017 | \n",
      "                    Train-Mae: 0.03750906139612198 |\n",
      "\n",
      "                    Average val loss: 0.0001900338684208691|\n",
      "                    Val-Mae: 0.01043656188994646\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 771\n",
      "Start training for stock: 3901\n",
      "\n",
      "                    Average train loss: 0.00045569680631160733 | \n",
      "                    Train-Mae: 0.040884681046009064 |\n",
      "\n",
      "                    Average val loss: 0.010055682621896267|\n",
      "                    Val-Mae: 0.02607647143304348\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 772\n",
      "Start training for stock: 4203\n",
      "\n",
      "                    Average train loss: 0.0004720926657319069 | \n",
      "                    Train-Mae: 0.032403696328401566 |\n",
      "\n",
      "                    Average val loss: 0.017580507323145866|\n",
      "                    Val-Mae: 0.027310308068990707\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 773\n",
      "Start training for stock: 6201\n",
      "\n",
      "                    Average train loss: 0.00035002436488866805 | \n",
      "                    Train-Mae: 0.021090198308229446 |\n",
      "\n",
      "                    Average val loss: 0.000749049533624202|\n",
      "                    Val-Mae: 0.014924369752407074\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 774\n",
      "Start training for stock: 9101\n",
      "\n",
      "                    Average train loss: 0.0006044887006282807 | \n",
      "                    Train-Mae: 0.02307857573032379 |\n",
      "\n",
      "                    Average val loss: 0.018343579024076462|\n",
      "                    Val-Mae: 0.04538354650139809\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 775\n",
      "Start training for stock: 3597\n",
      "\n",
      "                    Average train loss: 0.0001622255891561508 | \n",
      "                    Train-Mae: 0.046361956745386124 |\n",
      "\n",
      "                    Average val loss: 0.0006410636124201119|\n",
      "                    Val-Mae: 0.015320045873522758\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 776\n",
      "Start training for stock: 6250\n",
      "\n",
      "                    Average train loss: 1.6121554654091597e-05 | \n",
      "                    Train-Mae: 0.02996651828289032 |\n",
      "\n",
      "                    Average val loss: 0.0006205246318131685|\n",
      "                    Val-Mae: 0.01391038578003645\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 777\n",
      "Start training for stock: 7840\n",
      "\n",
      "                    Average train loss: 0.0009217708557844162 | \n",
      "                    Train-Mae: 0.04520674794912338 |\n",
      "\n",
      "                    Average val loss: 0.0446368046104908|\n",
      "                    Val-Mae: 0.026889503002166748\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 778\n",
      "Start training for stock: 7278\n",
      "\n",
      "                    Average train loss: 0.00019884791225194932 | \n",
      "                    Train-Mae: 0.040854424238204956 |\n",
      "\n",
      "                    Average val loss: 0.009039153344929218|\n",
      "                    Val-Mae: 0.020162973552942276\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 779\n",
      "Start training for stock: 7988\n",
      "\n",
      "                    Average train loss: 0.0001524998899549246 | \n",
      "                    Train-Mae: 0.02328086830675602 |\n",
      "\n",
      "                    Average val loss: 0.0012242922093719244|\n",
      "                    Val-Mae: 0.018327882513403893\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 780\n",
      "Start training for stock: 8818\n",
      "\n",
      "                    Average train loss: 0.0007373432070016861 | \n",
      "                    Train-Mae: 0.02918911911547184 |\n",
      "\n",
      "                    Average val loss: 0.0033442797139286995|\n",
      "                    Val-Mae: 0.017066558822989464\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 781\n",
      "Start training for stock: 6902\n",
      "\n",
      "                    Average train loss: 0.003427545726299286 | \n",
      "                    Train-Mae: 0.05967526510357857 |\n",
      "\n",
      "                    Average val loss: 0.027939872816205025|\n",
      "                    Val-Mae: 0.027651647105813026\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 782\n",
      "Start training for stock: 1810\n",
      "\n",
      "                    Average train loss: 0.0001650138758122921 | \n",
      "                    Train-Mae: 0.02356831729412079 |\n",
      "\n",
      "                    Average val loss: 0.0004396532312966883|\n",
      "                    Val-Mae: 0.016010133549571037\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 783\n",
      "Start training for stock: 7433\n",
      "\n",
      "                    Average train loss: 9.184486232697964e-05 | \n",
      "                    Train-Mae: 0.027688920497894287 |\n",
      "\n",
      "                    Average val loss: 0.028113149106502533|\n",
      "                    Val-Mae: 0.029342658817768097\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 784\n",
      "Start training for stock: 1930\n",
      "\n",
      "                    Average train loss: 8.257701410911978e-06 | \n",
      "                    Train-Mae: 0.023133939132094383 |\n",
      "\n",
      "                    Average val loss: 0.019637757912278175|\n",
      "                    Val-Mae: 0.027753645554184914\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 785\n",
      "Start training for stock: 7094\n",
      "\n",
      "                    Average train loss: 5.3703337907791135e-05 | \n",
      "                    Train-Mae: 0.0485863983631134 |\n",
      "\n",
      "                    Average val loss: 0.002525174291804433|\n",
      "                    Val-Mae: 0.032274022698402405\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 786\n",
      "Start training for stock: 4661\n",
      "\n",
      "                    Average train loss: 1.540023600682616e-05 | \n",
      "                    Train-Mae: 0.030167030170559883 |\n",
      "\n",
      "                    Average val loss: 0.10408929735422134|\n",
      "                    Val-Mae: 0.03774496540427208\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 787\n",
      "Start training for stock: 6741\n",
      "\n",
      "                    Average train loss: 0.0008692321181297302 | \n",
      "                    Train-Mae: 0.021150292828679085 |\n",
      "\n",
      "                    Average val loss: 0.015357689000666142|\n",
      "                    Val-Mae: 0.019364509731531143\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 788\n",
      "Start training for stock: 7229\n",
      "\n",
      "                    Average train loss: 0.0013137339055538178 | \n",
      "                    Train-Mae: 0.04037678986787796 |\n",
      "\n",
      "                    Average val loss: 0.004352441523224115|\n",
      "                    Val-Mae: 0.019280388951301575\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 789\n",
      "Start training for stock: 2734\n",
      "\n",
      "                    Average train loss: 0.0026558589935302733 | \n",
      "                    Train-Mae: 0.04570160433650017 |\n",
      "\n",
      "                    Average val loss: 0.007144465576857328|\n",
      "                    Val-Mae: 0.01656157709658146\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 790\n",
      "Start training for stock: 6409\n",
      "\n",
      "                    Average train loss: 1.2674853205680848e-05 | \n",
      "                    Train-Mae: 0.02629189006984234 |\n",
      "\n",
      "                    Average val loss: 0.001605593366548419|\n",
      "                    Val-Mae: 0.019782135263085365\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 791\n",
      "Start training for stock: 6071\n",
      "\n",
      "                    Average train loss: 0.00015838660299777985 | \n",
      "                    Train-Mae: 0.035812512040138245 |\n",
      "\n",
      "                    Average val loss: 0.003615114139392972|\n",
      "                    Val-Mae: 0.024736925959587097\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 792\n",
      "Start training for stock: 6508\n",
      "\n",
      "                    Average train loss: 0.00039625227451324464 | \n",
      "                    Train-Mae: 0.022645113989710808 |\n",
      "\n",
      "                    Average val loss: 0.006487604696303606|\n",
      "                    Val-Mae: 0.020890560001134872\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 793\n",
      "Start training for stock: 6146\n",
      "\n",
      "                    Average train loss: 3.224946791306138e-05 | \n",
      "                    Train-Mae: 0.045648638159036636 |\n",
      "\n",
      "                    Average val loss: 0.03102347068488598|\n",
      "                    Val-Mae: 0.029678652063012123\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 794\n",
      "Start training for stock: 2412\n",
      "\n",
      "                    Average train loss: 0.000661134123802185 | \n",
      "                    Train-Mae: 0.025890203192830086 |\n",
      "\n",
      "                    Average val loss: 0.0013743905583396554|\n",
      "                    Val-Mae: 0.022893859073519707\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 795\n",
      "Start training for stock: 6078\n",
      "\n",
      "                    Average train loss: 0.00021201342344284057 | \n",
      "                    Train-Mae: 0.029812468215823174 |\n",
      "\n",
      "                    Average val loss: 0.00039999367436394095|\n",
      "                    Val-Mae: 0.014523521065711975\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 796\n",
      "Start training for stock: 4521\n",
      "\n",
      "                    Average train loss: 0.00017133364453911782 | \n",
      "                    Train-Mae: 0.037704356014728546 |\n",
      "\n",
      "                    Average val loss: 0.027983078733086586|\n",
      "                    Val-Mae: 0.023021992295980453\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 797\n",
      "Start training for stock: 4997\n",
      "\n",
      "                    Average train loss: 0.0022135204076766967 | \n",
      "                    Train-Mae: 0.025552913546562195 |\n",
      "\n",
      "                    Average val loss: 0.047674793750047684|\n",
      "                    Val-Mae: 0.029107311740517616\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 798\n",
      "Start training for stock: 3050\n",
      "\n",
      "                    Average train loss: 0.0011137761920690537 | \n",
      "                    Train-Mae: 0.032775312662124634 |\n",
      "\n",
      "                    Average val loss: 0.0376359224319458|\n",
      "                    Val-Mae: 0.02667952887713909\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 799\n",
      "Start training for stock: 1407\n",
      "\n",
      "                    Average train loss: 5.0483024679124356e-05 | \n",
      "                    Train-Mae: 0.0378442257642746 |\n",
      "\n",
      "                    Average val loss: 0.031053509563207626|\n",
      "                    Val-Mae: 0.04163831099867821\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 800\n",
      "Start training for stock: 5563\n",
      "\n",
      "                    Average train loss: 1.2881620787084102e-05 | \n",
      "                    Train-Mae: 0.030716698616743088 |\n",
      "\n",
      "                    Average val loss: 0.009951530955731869|\n",
      "                    Val-Mae: 0.026940632611513138\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 801\n",
      "Start training for stock: 9065\n",
      "\n",
      "                    Average train loss: 0.0003514360263943672 | \n",
      "                    Train-Mae: 0.02000783383846283 |\n",
      "\n",
      "                    Average val loss: 0.0008219427545554936|\n",
      "                    Val-Mae: 0.01417587511241436\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 802\n",
      "Start training for stock: 9501\n",
      "\n",
      "                    Average train loss: 2.1500070579349996e-05 | \n",
      "                    Train-Mae: 0.02405603975057602 |\n",
      "\n",
      "                    Average val loss: 0.0027025192975997925|\n",
      "                    Val-Mae: 0.019003912806510925\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 803\n",
      "Start training for stock: 6333\n",
      "\n",
      "                    Average train loss: 0.0005803100764751434 | \n",
      "                    Train-Mae: 0.04563937336206436 |\n",
      "\n",
      "                    Average val loss: 0.010046864859759808|\n",
      "                    Val-Mae: 0.01941603049635887\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 804\n",
      "Start training for stock: 6196\n",
      "\n",
      "                    Average train loss: 0.0021540936827659607 | \n",
      "                    Train-Mae: 0.035031240433454514 |\n",
      "\n",
      "                    Average val loss: 0.005361624527722597|\n",
      "                    Val-Mae: 0.027146557345986366\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 805\n",
      "Start training for stock: 9119\n",
      "\n",
      "                    Average train loss: 0.0011859080195426941 | \n",
      "                    Train-Mae: 0.02620178461074829 |\n",
      "\n",
      "                    Average val loss: 0.04688518866896629|\n",
      "                    Val-Mae: 0.03718096390366554\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 806\n",
      "Start training for stock: 7487\n",
      "\n",
      "                    Average train loss: 3.0134310945868493e-05 | \n",
      "                    Train-Mae: 0.017134858295321465 |\n",
      "\n",
      "                    Average val loss: 0.043207816779613495|\n",
      "                    Val-Mae: 0.022601420059800148\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 807\n",
      "Start training for stock: 4755\n",
      "\n",
      "                    Average train loss: 0.0005011330917477608 | \n",
      "                    Train-Mae: 0.02914435788989067 |\n",
      "\n",
      "                    Average val loss: 0.0200605820864439|\n",
      "                    Val-Mae: 0.02898276597261429\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 808\n",
      "Start training for stock: 6458\n",
      "\n",
      "                    Average train loss: 0.0004390608891844749 | \n",
      "                    Train-Mae: 0.02927183173596859 |\n",
      "\n",
      "                    Average val loss: 0.03917970135807991|\n",
      "                    Val-Mae: 0.029961930587887764\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 809\n",
      "Start training for stock: 7979\n",
      "\n",
      "                    Average train loss: 1.2303950497880579e-05 | \n",
      "                    Train-Mae: 0.04761384427547455 |\n",
      "\n",
      "                    Average val loss: 0.05777841806411743|\n",
      "                    Val-Mae: 0.03524984046816826\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 810\n",
      "Start training for stock: 7259\n",
      "\n",
      "                    Average train loss: 0.0008786871284246445 | \n",
      "                    Train-Mae: 0.03688739612698555 |\n",
      "\n",
      "                    Average val loss: 0.018601445481181145|\n",
      "                    Val-Mae: 0.02419438585639\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 811\n",
      "Start training for stock: 7630\n",
      "\n",
      "                    Average train loss: 0.0024450089037418364 | \n",
      "                    Train-Mae: 0.02331862971186638 |\n",
      "\n",
      "                    Average val loss: 0.008737447671592236|\n",
      "                    Val-Mae: 0.014971759170293808\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 812\n",
      "Start training for stock: 8522\n",
      "\n",
      "                    Average train loss: 3.537184791639447e-05 | \n",
      "                    Train-Mae: 0.025262510403990746 |\n",
      "\n",
      "                    Average val loss: 0.0011012583272531629|\n",
      "                    Val-Mae: 0.016504578292369843\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 813\n",
      "Start training for stock: 7649\n",
      "\n",
      "                    Average train loss: 0.002893891930580139 | \n",
      "                    Train-Mae: 0.058314088732004166 |\n",
      "\n",
      "                    Average val loss: 0.02146398462355137|\n",
      "                    Val-Mae: 0.02409936860203743\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 814\n",
      "Start training for stock: 3662\n",
      "\n",
      "                    Average train loss: 7.27959256619215e-05 | \n",
      "                    Train-Mae: 0.027694260701537132 |\n",
      "\n",
      "                    Average val loss: 0.0048693446442484856|\n",
      "                    Val-Mae: 0.02458927221596241\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 815\n",
      "Start training for stock: 9706\n",
      "\n",
      "                    Average train loss: 9.137975866906346e-06 | \n",
      "                    Train-Mae: 0.02953319624066353 |\n",
      "\n",
      "                    Average val loss: 0.0012962118489667773|\n",
      "                    Val-Mae: 0.022175146266818047\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 816\n",
      "Start training for stock: 7864\n",
      "\n",
      "                    Average train loss: 0.00017503287643194198 | \n",
      "                    Train-Mae: 0.02393963932991028 |\n",
      "\n",
      "                    Average val loss: 0.01127634011209011|\n",
      "                    Val-Mae: 0.021981336176395416\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 817\n",
      "Start training for stock: 3762\n",
      "\n",
      "                    Average train loss: 0.0003012791648507118 | \n",
      "                    Train-Mae: 0.03587225452065468 |\n",
      "\n",
      "                    Average val loss: 0.0025424594059586525|\n",
      "                    Val-Mae: 0.022235039621591568\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 818\n",
      "Start training for stock: 8214\n",
      "\n",
      "                    Average train loss: 0.002232312709093094 | \n",
      "                    Train-Mae: 0.0487368144094944 |\n",
      "\n",
      "                    Average val loss: 0.0007174710626713932|\n",
      "                    Val-Mae: 0.019539205357432365\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 819\n",
      "Start training for stock: 2453\n",
      "\n",
      "                    Average train loss: 0.00023585287854075432 | \n",
      "                    Train-Mae: 0.03792405501008034 |\n",
      "\n",
      "                    Average val loss: 0.0018210269045084715|\n",
      "                    Val-Mae: 0.022799614816904068\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 820\n",
      "Start training for stock: 7949\n",
      "\n",
      "                    Average train loss: 0.00048265036195516587 | \n",
      "                    Train-Mae: 0.023039311170578003 |\n",
      "\n",
      "                    Average val loss: 0.0014802395598962903|\n",
      "                    Val-Mae: 0.012544825673103333\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 821\n",
      "Start training for stock: 7279\n",
      "\n",
      "                    Average train loss: 0.00020652657374739647 | \n",
      "                    Train-Mae: 0.02560572512447834 |\n",
      "\n",
      "                    Average val loss: 0.004408099688589573|\n",
      "                    Val-Mae: 0.018589649349451065\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 822\n",
      "Start training for stock: 6136\n",
      "\n",
      "                    Average train loss: 0.0002675982192158699 | \n",
      "                    Train-Mae: 0.02234150469303131 |\n",
      "\n",
      "                    Average val loss: 0.0009715595515444875|\n",
      "                    Val-Mae: 0.01740858145058155\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 823\n",
      "Start training for stock: 4488\n",
      "\n",
      "                    Average train loss: 5.4233749397099016e-05 | \n",
      "                    Train-Mae: 0.04480663686990738 |\n",
      "\n",
      "                    Average val loss: 0.00258189020678401|\n",
      "                    Val-Mae: 0.03559769317507744\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 824\n",
      "Start training for stock: 6841\n",
      "\n",
      "                    Average train loss: 0.0001931881532073021 | \n",
      "                    Train-Mae: 0.022694002836942673 |\n",
      "\n",
      "                    Average val loss: 0.002795126289129257|\n",
      "                    Val-Mae: 0.018134502694010735\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 825\n",
      "Start training for stock: 4883\n",
      "\n",
      "                    Average train loss: 0.0007029343396425247 | \n",
      "                    Train-Mae: 0.04978930950164795 |\n",
      "\n",
      "                    Average val loss: 0.0019547613337635994|\n",
      "                    Val-Mae: 0.027540454640984535\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 826\n",
      "Start training for stock: 9613\n",
      "\n",
      "                    Average train loss: 0.00034339796751737595 | \n",
      "                    Train-Mae: 0.01686055213212967 |\n",
      "\n",
      "                    Average val loss: 0.0023407679982483387|\n",
      "                    Val-Mae: 0.015911027789115906\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 827\n",
      "Start training for stock: 6755\n",
      "\n",
      "                    Average train loss: 0.00021276414394378663 | \n",
      "                    Train-Mae: 0.036310695111751556 |\n",
      "\n",
      "                    Average val loss: 0.058593396097421646|\n",
      "                    Val-Mae: 0.03269327059388161\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 828\n",
      "Start training for stock: 5214\n",
      "\n",
      "                    Average train loss: 0.00022458216175436974 | \n",
      "                    Train-Mae: 0.020397931337356567 |\n",
      "\n",
      "                    Average val loss: 0.007498905993998051|\n",
      "                    Val-Mae: 0.019171707332134247\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 829\n",
      "Start training for stock: 4028\n",
      "\n",
      "                    Average train loss: 0.0019742091000080108 | \n",
      "                    Train-Mae: 0.03050791285932064 |\n",
      "\n",
      "                    Average val loss: 0.0019466947996988893|\n",
      "                    Val-Mae: 0.02228967659175396\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 830\n",
      "Start training for stock: 2726\n",
      "\n",
      "                    Average train loss: 0.00011343101970851422 | \n",
      "                    Train-Mae: 0.03091409243643284 |\n",
      "\n",
      "                    Average val loss: 0.00033728103153407574|\n",
      "                    Val-Mae: 0.013593022711575031\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 831\n",
      "Start training for stock: 6472\n",
      "\n",
      "                    Average train loss: 1.9268044270575045e-05 | \n",
      "                    Train-Mae: 0.032692935317754745 |\n",
      "\n",
      "                    Average val loss: 0.008092625997960567|\n",
      "                    Val-Mae: 0.023557400330901146\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 832\n",
      "Start training for stock: 3436\n",
      "\n",
      "                    Average train loss: 0.00034887664020061493 | \n",
      "                    Train-Mae: 0.028217406943440437 |\n",
      "\n",
      "                    Average val loss: 0.0008270203834399581|\n",
      "                    Val-Mae: 0.01788167841732502\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 833\n",
      "Start training for stock: 6361\n",
      "\n",
      "                    Average train loss: 4.1861841455101965e-05 | \n",
      "                    Train-Mae: 0.027855759486556053 |\n",
      "\n",
      "                    Average val loss: 0.05369015783071518|\n",
      "                    Val-Mae: 0.03553348034620285\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 834\n",
      "Start training for stock: 7915\n",
      "\n",
      "                    Average train loss: 0.0011925379931926727 | \n",
      "                    Train-Mae: 0.030870487913489342 |\n",
      "\n",
      "                    Average val loss: 0.0012994741555303335|\n",
      "                    Val-Mae: 0.019514502957463264\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 835\n",
      "Start training for stock: 9769\n",
      "\n",
      "                    Average train loss: 4.954382311552763e-05 | \n",
      "                    Train-Mae: 0.022968124598264694 |\n",
      "\n",
      "                    Average val loss: 0.007097739726305008|\n",
      "                    Val-Mae: 0.013099615462124348\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 836\n",
      "Start training for stock: 6309\n",
      "\n",
      "                    Average train loss: 9.213616140186786e-05 | \n",
      "                    Train-Mae: 0.027541179209947586 |\n",
      "\n",
      "                    Average val loss: 0.04409509897232056|\n",
      "                    Val-Mae: 0.02805870771408081\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 837\n",
      "Start training for stock: 8153\n",
      "\n",
      "                    Average train loss: 0.001123679056763649 | \n",
      "                    Train-Mae: 0.02719205990433693 |\n",
      "\n",
      "                    Average val loss: 0.004418576136231422|\n",
      "                    Val-Mae: 0.015079399570822716\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 838\n",
      "Start training for stock: 8132\n",
      "\n",
      "                    Average train loss: 0.0002424830012023449 | \n",
      "                    Train-Mae: 0.02411031350493431 |\n",
      "\n",
      "                    Average val loss: 0.014264332130551338|\n",
      "                    Val-Mae: 0.023473544046282768\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 839\n",
      "Start training for stock: 3825\n",
      "\n",
      "                    Average train loss: 9.842038154602051e-05 | \n",
      "                    Train-Mae: 0.033158086240291595 |\n",
      "\n",
      "                    Average val loss: 0.0030965330079197884|\n",
      "                    Val-Mae: 0.03520517796278\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 840\n",
      "Start training for stock: 9083\n",
      "\n",
      "                    Average train loss: 9.305838495492935e-05 | \n",
      "                    Train-Mae: 0.040536101907491684 |\n",
      "\n",
      "                    Average val loss: 0.0019439507741481066|\n",
      "                    Val-Mae: 0.0189303420484066\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 841\n",
      "Start training for stock: 9629\n",
      "\n",
      "                    Average train loss: 6.456391420215369e-05 | \n",
      "                    Train-Mae: 0.02973196469247341 |\n",
      "\n",
      "                    Average val loss: 0.00130579830147326|\n",
      "                    Val-Mae: 0.02441103756427765\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 842\n",
      "Start training for stock: 6619\n",
      "\n",
      "                    Average train loss: 0.00017354076728224755 | \n",
      "                    Train-Mae: 0.04289240762591362 |\n",
      "\n",
      "                    Average val loss: 0.0032468929421156645|\n",
      "                    Val-Mae: 0.03109077550470829\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 843\n",
      "Start training for stock: 6222\n",
      "\n",
      "                    Average train loss: 0.0010716284066438675 | \n",
      "                    Train-Mae: 0.028283504769206047 |\n",
      "\n",
      "                    Average val loss: 0.0033935552928596735|\n",
      "                    Val-Mae: 0.02118276059627533\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 844\n",
      "Start training for stock: 6269\n",
      "\n",
      "                    Average train loss: 0.0008738621324300766 | \n",
      "                    Train-Mae: 0.03919978067278862 |\n",
      "\n",
      "                    Average val loss: 0.0041532269679009914|\n",
      "                    Val-Mae: 0.020632633939385414\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 845\n",
      "Start training for stock: 2904\n",
      "\n",
      "                    Average train loss: 1.081436756066978e-05 | \n",
      "                    Train-Mae: 0.01866418495774269 |\n",
      "\n",
      "                    Average val loss: 0.008841720409691334|\n",
      "                    Val-Mae: 0.01623518392443657\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 846\n",
      "Start training for stock: 3778\n",
      "\n",
      "                    Average train loss: 0.00015644146129488944 | \n",
      "                    Train-Mae: 0.03100198693573475 |\n",
      "\n",
      "                    Average val loss: 0.002031888347119093|\n",
      "                    Val-Mae: 0.0172930508852005\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 847\n",
      "Start training for stock: 7500\n",
      "\n",
      "                    Average train loss: 0.00015921710059046745 | \n",
      "                    Train-Mae: 0.06267320364713669 |\n",
      "\n",
      "                    Average val loss: 0.0018560985336080194|\n",
      "                    Val-Mae: 0.023998845368623734\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 848\n",
      "Start training for stock: 6370\n",
      "\n",
      "                    Average train loss: 7.385873701423406e-05 | \n",
      "                    Train-Mae: 0.02908053621649742 |\n",
      "\n",
      "                    Average val loss: 0.043597765266895294|\n",
      "                    Val-Mae: 0.031075263395905495\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 849\n",
      "Start training for stock: 9201\n",
      "\n",
      "                    Average train loss: 0.0020404647290706633 | \n",
      "                    Train-Mae: 0.03161591663956642 |\n",
      "\n",
      "                    Average val loss: 0.0073142945766448975|\n",
      "                    Val-Mae: 0.022732244804501534\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 850\n",
      "Start training for stock: 8058\n",
      "\n",
      "                    Average train loss: 0.0003908248245716095 | \n",
      "                    Train-Mae: 0.03703298419713974 |\n",
      "\n",
      "                    Average val loss: 0.003853312460705638|\n",
      "                    Val-Mae: 0.017034772783517838\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 851\n",
      "Start training for stock: 6005\n",
      "\n",
      "                    Average train loss: 2.8827639762312175e-05 | \n",
      "                    Train-Mae: 0.025701867416501045 |\n",
      "\n",
      "                    Average val loss: 0.00037108201649971306|\n",
      "                    Val-Mae: 0.015080484561622143\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 852\n",
      "Start training for stock: 9956\n",
      "\n",
      "                    Average train loss: 0.0009470043331384659 | \n",
      "                    Train-Mae: 0.042887985706329346 |\n",
      "\n",
      "                    Average val loss: 0.0029888199642300606|\n",
      "                    Val-Mae: 0.017685338854789734\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 853\n",
      "Start training for stock: 7995\n",
      "\n",
      "                    Average train loss: 0.00010341228917241097 | \n",
      "                    Train-Mae: 0.021278295665979385 |\n",
      "\n",
      "                    Average val loss: 0.005472301971167326|\n",
      "                    Val-Mae: 0.016982709988951683\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 854\n",
      "Start training for stock: 6961\n",
      "\n",
      "                    Average train loss: 1.535391784273088e-05 | \n",
      "                    Train-Mae: 0.05419987812638283 |\n",
      "\n",
      "                    Average val loss: 0.05235900729894638|\n",
      "                    Val-Mae: 0.03356434404850006\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 855\n",
      "Start training for stock: 9014\n",
      "\n",
      "                    Average train loss: 0.0017161473631858825 | \n",
      "                    Train-Mae: 0.018931010738015175 |\n",
      "\n",
      "                    Average val loss: 0.0036755180917680264|\n",
      "                    Val-Mae: 0.01063969824463129\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 856\n",
      "Start training for stock: 6306\n",
      "\n",
      "                    Average train loss: 0.00040776830166578293 | \n",
      "                    Train-Mae: 0.03331022337079048 |\n",
      "\n",
      "                    Average val loss: 0.00022349024948198348|\n",
      "                    Val-Mae: 0.009221775457262993\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 857\n",
      "Start training for stock: 9735\n",
      "\n",
      "                    Average train loss: 0.00022510403767228126 | \n",
      "                    Train-Mae: 0.02719644084572792 |\n",
      "\n",
      "                    Average val loss: 0.02002815343439579|\n",
      "                    Val-Mae: 0.020026350393891335\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 858\n",
      "Start training for stock: 9641\n",
      "\n",
      "                    Average train loss: 7.455963175743818e-05 | \n",
      "                    Train-Mae: 0.037872686982154846 |\n",
      "\n",
      "                    Average val loss: 0.1698978841304779|\n",
      "                    Val-Mae: 0.04512735828757286\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 859\n",
      "Start training for stock: 8593\n",
      "\n",
      "                    Average train loss: 0.002867330014705658 | \n",
      "                    Train-Mae: 0.02353539876639843 |\n",
      "\n",
      "                    Average val loss: 0.007096337154507637|\n",
      "                    Val-Mae: 0.017289815470576286\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 860\n",
      "Start training for stock: 9467\n",
      "\n",
      "                    Average train loss: 0.00026253534480929374 | \n",
      "                    Train-Mae: 0.03521151468157768 |\n",
      "\n",
      "                    Average val loss: 0.001793745788745582|\n",
      "                    Val-Mae: 0.0242917463183403\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 861\n",
      "Start training for stock: 3563\n",
      "\n",
      "                    Average train loss: 5.801927298307419e-05 | \n",
      "                    Train-Mae: 0.03741506487131119 |\n",
      "\n",
      "                    Average val loss: 0.005247029941529036|\n",
      "                    Val-Mae: 0.023264147341251373\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 862\n",
      "Start training for stock: 8219\n",
      "\n",
      "                    Average train loss: 0.003432886004447937 | \n",
      "                    Train-Mae: 0.04577776789665222 |\n",
      "\n",
      "                    Average val loss: 0.005444649141281843|\n",
      "                    Val-Mae: 0.0276982132345438\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 863\n",
      "Start training for stock: 6258\n",
      "\n",
      "                    Average train loss: 0.0007286729663610459 | \n",
      "                    Train-Mae: 0.03222247213125229 |\n",
      "\n",
      "                    Average val loss: 0.00597603153437376|\n",
      "                    Val-Mae: 0.022368550300598145\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 864\n",
      "Start training for stock: 9519\n",
      "\n",
      "                    Average train loss: 4.99402591958642e-05 | \n",
      "                    Train-Mae: 0.0357491597533226 |\n",
      "\n",
      "                    Average val loss: 0.003438805229961872|\n",
      "                    Val-Mae: 0.03284681215882301\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 865\n",
      "Start training for stock: 4499\n",
      "\n",
      "                    Average train loss: 4.036986269056797e-05 | \n",
      "                    Train-Mae: 0.04038577526807785 |\n",
      "\n",
      "                    Average val loss: 0.0015830517513677478|\n",
      "                    Val-Mae: 0.029134662821888924\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 866\n",
      "Start training for stock: 5408\n",
      "\n",
      "                    Average train loss: 1.5001925639808178e-05 | \n",
      "                    Train-Mae: 0.028443604707717896 |\n",
      "\n",
      "                    Average val loss: 0.0026156443636864424|\n",
      "                    Val-Mae: 0.019375190138816833\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 867\n",
      "Start training for stock: 9715\n",
      "\n",
      "                    Average train loss: 7.326290011405945e-05 | \n",
      "                    Train-Mae: 0.03292366489768028 |\n",
      "\n",
      "                    Average val loss: 0.0024161969777196646|\n",
      "                    Val-Mae: 0.01713196560740471\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 868\n",
      "Start training for stock: 2305\n",
      "\n",
      "                    Average train loss: 0.0010789651423692703 | \n",
      "                    Train-Mae: 0.028134727850556374 |\n",
      "\n",
      "                    Average val loss: 0.007751494646072388|\n",
      "                    Val-Mae: 0.020265961065888405\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 869\n",
      "Start training for stock: 7294\n",
      "\n",
      "                    Average train loss: 0.0003097555972635746 | \n",
      "                    Train-Mae: 0.0256191436201334 |\n",
      "\n",
      "                    Average val loss: 0.000520931207574904|\n",
      "                    Val-Mae: 0.017028959468007088\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 870\n",
      "Start training for stock: 5985\n",
      "\n",
      "                    Average train loss: 4.0242108516395094e-05 | \n",
      "                    Train-Mae: 0.02938362956047058 |\n",
      "\n",
      "                    Average val loss: 0.013481966219842434|\n",
      "                    Val-Mae: 0.02084757387638092\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 871\n",
      "Start training for stock: 5992\n",
      "\n",
      "                    Average train loss: 0.0004108555242419243 | \n",
      "                    Train-Mae: 0.018796179443597794 |\n",
      "\n",
      "                    Average val loss: 0.0010537445778027177|\n",
      "                    Val-Mae: 0.023546230047941208\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 872\n",
      "Start training for stock: 7089\n",
      "\n",
      "                    Average train loss: 6.107646506279707e-05 | \n",
      "                    Train-Mae: 0.033991746604442596 |\n",
      "\n",
      "                    Average val loss: 0.0047252667136490345|\n",
      "                    Val-Mae: 0.05481018126010895\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 873\n",
      "Start training for stock: 4464\n",
      "\n",
      "                    Average train loss: 0.00018853483721613883 | \n",
      "                    Train-Mae: 0.01459974329918623 |\n",
      "\n",
      "                    Average val loss: 0.001969309989362955|\n",
      "                    Val-Mae: 0.014214062131941319\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 874\n",
      "Start training for stock: 5930\n",
      "\n",
      "                    Average train loss: 3.7002472672611476e-05 | \n",
      "                    Train-Mae: 0.022074030712246895 |\n",
      "\n",
      "                    Average val loss: 0.00022290363267529756|\n",
      "                    Val-Mae: 0.010715814307332039\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 875\n",
      "Start training for stock: 4541\n",
      "\n",
      "                    Average train loss: 0.0011492688953876496 | \n",
      "                    Train-Mae: 0.0403946191072464 |\n",
      "\n",
      "                    Average val loss: 0.003425612347200513|\n",
      "                    Val-Mae: 0.01750992052257061\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 876\n",
      "Start training for stock: 9533\n",
      "\n",
      "                    Average train loss: 0.00017748834565281868 | \n",
      "                    Train-Mae: 0.024031687527894974 |\n",
      "\n",
      "                    Average val loss: 0.006576403044164181|\n",
      "                    Val-Mae: 0.020765474066138268\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 877\n",
      "Start training for stock: 9726\n",
      "\n",
      "                    Average train loss: 9.986374527215958e-05 | \n",
      "                    Train-Mae: 0.028956294059753418 |\n",
      "\n",
      "                    Average val loss: 0.0046389177441596985|\n",
      "                    Val-Mae: 0.02889721654355526\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 878\n",
      "Start training for stock: 2445\n",
      "\n",
      "                    Average train loss: 0.003838914930820465 | \n",
      "                    Train-Mae: 0.051852986216545105 |\n",
      "\n",
      "                    Average val loss: 0.0016907122917473316|\n",
      "                    Val-Mae: 0.01756913959980011\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 879\n",
      "Start training for stock: 4739\n",
      "\n",
      "                    Average train loss: 0.00018074747174978256 | \n",
      "                    Train-Mae: 0.022789241746068 |\n",
      "\n",
      "                    Average val loss: 0.0006072959513403475|\n",
      "                    Val-Mae: 0.014628015458583832\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 880\n",
      "Start training for stock: 3798\n",
      "\n",
      "                    Average train loss: 9.167869575321674e-05 | \n",
      "                    Train-Mae: 0.03594774380326271 |\n",
      "\n",
      "                    Average val loss: 0.01827404834330082|\n",
      "                    Val-Mae: 0.03475312888622284\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 881\n",
      "Start training for stock: 8999\n",
      "\n",
      "                    Average train loss: 0.0021662718057632448 | \n",
      "                    Train-Mae: 0.029953401535749435 |\n",
      "\n",
      "                    Average val loss: 0.003915748093277216|\n",
      "                    Val-Mae: 0.017812184989452362\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 882\n",
      "Start training for stock: 4636\n",
      "\n",
      "                    Average train loss: 0.0004587750136852264 | \n",
      "                    Train-Mae: 0.02346011810004711 |\n",
      "\n",
      "                    Average val loss: 0.0008040647371672094|\n",
      "                    Val-Mae: 0.017185596749186516\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 883\n",
      "Start training for stock: 4167\n",
      "\n",
      "                    Average train loss: 0.00044528983533382416 | \n",
      "                    Train-Mae: 0.05294732749462128 |\n",
      "\n",
      "                    Average val loss: 0.002472278894856572|\n",
      "                    Val-Mae: 0.03363880515098572\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 884\n",
      "Start training for stock: 7679\n",
      "\n",
      "                    Average train loss: 0.0006086776778101922 | \n",
      "                    Train-Mae: 0.032553791999816895 |\n",
      "\n",
      "                    Average val loss: 0.0011759847402572632|\n",
      "                    Val-Mae: 0.0164143368601799\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 885\n",
      "Start training for stock: 1833\n",
      "\n",
      "                    Average train loss: 9.093716740608215e-05 | \n",
      "                    Train-Mae: 0.019625794142484665 |\n",
      "\n",
      "                    Average val loss: 0.003676873166114092|\n",
      "                    Val-Mae: 0.01596720889210701\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 886\n",
      "Start training for stock: 9375\n",
      "\n",
      "                    Average train loss: 0.0009537545591592789 | \n",
      "                    Train-Mae: 0.040193744003772736 |\n",
      "\n",
      "                    Average val loss: 0.004869130440056324|\n",
      "                    Val-Mae: 0.02157123200595379\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 887\n",
      "Start training for stock: 5807\n",
      "\n",
      "                    Average train loss: 4.4403797946870324e-05 | \n",
      "                    Train-Mae: 0.020861594006419182 |\n",
      "\n",
      "                    Average val loss: 0.004008756019175053|\n",
      "                    Val-Mae: 0.0145421102643013\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 888\n",
      "Start training for stock: 4462\n",
      "\n",
      "                    Average train loss: 0.00021779684349894522 | \n",
      "                    Train-Mae: 0.022411629557609558 |\n",
      "\n",
      "                    Average val loss: 0.00048060130211524665|\n",
      "                    Val-Mae: 0.016442306339740753\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 889\n",
      "Start training for stock: 4658\n",
      "\n",
      "                    Average train loss: 0.0016313730180263519 | \n",
      "                    Train-Mae: 0.0485212616622448 |\n",
      "\n",
      "                    Average val loss: 0.03071446716785431|\n",
      "                    Val-Mae: 0.02390052005648613\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 890\n",
      "Start training for stock: 2108\n",
      "\n",
      "                    Average train loss: 4.3518240563571456e-05 | \n",
      "                    Train-Mae: 0.02607637457549572 |\n",
      "\n",
      "                    Average val loss: 0.003931283485144377|\n",
      "                    Val-Mae: 0.0120387002825737\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 891\n",
      "Start training for stock: 9090\n",
      "\n",
      "                    Average train loss: 0.0002900097519159317 | \n",
      "                    Train-Mae: 0.026957785710692406 |\n",
      "\n",
      "                    Average val loss: 0.0006949829403311014|\n",
      "                    Val-Mae: 0.016083067283034325\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 892\n",
      "Start training for stock: 8137\n",
      "\n",
      "                    Average train loss: 0.00020028416067361833 | \n",
      "                    Train-Mae: 0.022300373762845993 |\n",
      "\n",
      "                    Average val loss: 0.0021729159634560347|\n",
      "                    Val-Mae: 0.01899789646267891\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 893\n",
      "Start training for stock: 9757\n",
      "\n",
      "                    Average train loss: 0.00012079221196472644 | \n",
      "                    Train-Mae: 0.01989278569817543 |\n",
      "\n",
      "                    Average val loss: 0.0007334433030337095|\n",
      "                    Val-Mae: 0.015881357714533806\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 894\n",
      "Start training for stock: 4220\n",
      "\n",
      "                    Average train loss: 0.00038473226130008697 | \n",
      "                    Train-Mae: 0.02510855719447136 |\n",
      "\n",
      "                    Average val loss: 0.0071074883453547955|\n",
      "                    Val-Mae: 0.021553948521614075\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 895\n",
      "Start training for stock: 7516\n",
      "\n",
      "                    Average train loss: 1.0001348564401268e-05 | \n",
      "                    Train-Mae: 0.02303292602300644 |\n",
      "\n",
      "                    Average val loss: 0.024794504046440125|\n",
      "                    Val-Mae: 0.02736710198223591\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 896\n",
      "Start training for stock: 7937\n",
      "\n",
      "                    Average train loss: 4.784061748068779e-06 | \n",
      "                    Train-Mae: 0.029557697474956512 |\n",
      "\n",
      "                    Average val loss: 0.00043391159852035344|\n",
      "                    Val-Mae: 0.0143384775146842\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 897\n",
      "Start training for stock: 1814\n",
      "\n",
      "                    Average train loss: 1.3069025008007885e-05 | \n",
      "                    Train-Mae: 0.017217233777046204 |\n",
      "\n",
      "                    Average val loss: 0.00041862038779072464|\n",
      "                    Val-Mae: 0.012375423684716225\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 898\n",
      "Start training for stock: 9993\n",
      "\n",
      "                    Average train loss: 0.001207180768251419 | \n",
      "                    Train-Mae: 0.05420035123825073 |\n",
      "\n",
      "                    Average val loss: 0.08103199303150177|\n",
      "                    Val-Mae: 0.029342321678996086\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 899\n",
      "Start training for stock: 2730\n",
      "\n",
      "                    Average train loss: 1.1687256628647447e-05 | \n",
      "                    Train-Mae: 0.054844483733177185 |\n",
      "\n",
      "                    Average val loss: 0.06260274350643158|\n",
      "                    Val-Mae: 0.03151558339595795\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 900\n",
      "Start training for stock: 8527\n",
      "\n",
      "                    Average train loss: 0.0007260638475418091 | \n",
      "                    Train-Mae: 0.025155890733003616 |\n",
      "\n",
      "                    Average val loss: 0.005831005983054638|\n",
      "                    Val-Mae: 0.017899855971336365\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 901\n",
      "Start training for stock: 2987\n",
      "\n",
      "                    Average train loss: 0.00016351465135812758 | \n",
      "                    Train-Mae: 0.0371045283973217 |\n",
      "\n",
      "                    Average val loss: 0.002660298254340887|\n",
      "                    Val-Mae: 0.03998957946896553\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 902\n",
      "Start training for stock: 6302\n",
      "\n",
      "                    Average train loss: 7.259579375386238e-05 | \n",
      "                    Train-Mae: 0.03409821540117264 |\n",
      "\n",
      "                    Average val loss: 0.0017745995428413153|\n",
      "                    Val-Mae: 0.017950907349586487\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 903\n",
      "Start training for stock: 4206\n",
      "\n",
      "                    Average train loss: 0.0003066486120223999 | \n",
      "                    Train-Mae: 0.044163402169942856 |\n",
      "\n",
      "                    Average val loss: 0.054753441363573074|\n",
      "                    Val-Mae: 0.030729051679372787\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 904\n",
      "Start training for stock: 4911\n",
      "\n",
      "                    Average train loss: 0.0011737143993377685 | \n",
      "                    Train-Mae: 0.024350350722670555 |\n",
      "\n",
      "                    Average val loss: 0.015915323048830032|\n",
      "                    Val-Mae: 0.02326972968876362\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 905\n",
      "Start training for stock: 8877\n",
      "\n",
      "                    Average train loss: 0.0007046705484390259 | \n",
      "                    Train-Mae: 0.04077989235520363 |\n",
      "\n",
      "                    Average val loss: 0.03424534574151039|\n",
      "                    Val-Mae: 0.025881607085466385\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 906\n",
      "Start training for stock: 2806\n",
      "\n",
      "                    Average train loss: 0.0005359021201729775 | \n",
      "                    Train-Mae: 0.043646298348903656 |\n",
      "\n",
      "                    Average val loss: 0.01023023296147585|\n",
      "                    Val-Mae: 0.02780861034989357\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 907\n",
      "Start training for stock: 9824\n",
      "\n",
      "                    Average train loss: 0.0024258847534656524 | \n",
      "                    Train-Mae: 0.055267881602048874 |\n",
      "\n",
      "                    Average val loss: 0.053553733974695206|\n",
      "                    Val-Mae: 0.036506809294223785\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 908\n",
      "Start training for stock: 7595\n",
      "\n",
      "                    Average train loss: 0.0022996671497821806 | \n",
      "                    Train-Mae: 0.039481405168771744 |\n",
      "\n",
      "                    Average val loss: 0.03337808698415756|\n",
      "                    Val-Mae: 0.028128210455179214\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 909\n",
      "Start training for stock: 3064\n",
      "\n",
      "                    Average train loss: 0.00022002976387739182 | \n",
      "                    Train-Mae: 0.044670481234788895 |\n",
      "\n",
      "                    Average val loss: 0.0022757211700081825|\n",
      "                    Val-Mae: 0.020741663873195648\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 910\n",
      "Start training for stock: 7408\n",
      "\n",
      "                    Average train loss: 0.00068652905523777 | \n",
      "                    Train-Mae: 0.051613714545965195 |\n",
      "\n",
      "                    Average val loss: 0.004740919452160597|\n",
      "                    Val-Mae: 0.03006706014275551\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 911\n",
      "Start training for stock: 2897\n",
      "\n",
      "                    Average train loss: 0.0006003577634692192 | \n",
      "                    Train-Mae: 0.04358891025185585 |\n",
      "\n",
      "                    Average val loss: 0.00398970115929842|\n",
      "                    Val-Mae: 0.014106903225183487\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 912\n",
      "Start training for stock: 7564\n",
      "\n",
      "                    Average train loss: 0.00011974848806858063 | \n",
      "                    Train-Mae: 0.03451831266283989 |\n",
      "\n",
      "                    Average val loss: 0.007678635884076357|\n",
      "                    Val-Mae: 0.02132156491279602\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 913\n",
      "Start training for stock: 4047\n",
      "\n",
      "                    Average train loss: 0.001719004511833191 | \n",
      "                    Train-Mae: 0.04293430224061012 |\n",
      "\n",
      "                    Average val loss: 0.0035729631781578064|\n",
      "                    Val-Mae: 0.018918948248028755\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 914\n",
      "Start training for stock: 5803\n",
      "\n",
      "                    Average train loss: 0.0003686191886663437 | \n",
      "                    Train-Mae: 0.025510279461741447 |\n",
      "\n",
      "                    Average val loss: 0.001976779429242015|\n",
      "                    Val-Mae: 0.02138691209256649\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 915\n",
      "Start training for stock: 5976\n",
      "\n",
      "                    Average train loss: 0.0016885975003242493 | \n",
      "                    Train-Mae: 0.03436316177248955 |\n",
      "\n",
      "                    Average val loss: 0.0020896228961646557|\n",
      "                    Val-Mae: 0.018740952014923096\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 916\n",
      "Start training for stock: 3458\n",
      "\n",
      "                    Average train loss: 2.05133855342865e-05 | \n",
      "                    Train-Mae: 0.022847624495625496 |\n",
      "\n",
      "                    Average val loss: 0.001207009656354785|\n",
      "                    Val-Mae: 0.019306231290102005\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 917\n",
      "Start training for stock: 7990\n",
      "\n",
      "                    Average train loss: 2.0535329822450878e-05 | \n",
      "                    Train-Mae: 0.03712809830904007 |\n",
      "\n",
      "                    Average val loss: 0.03444240987300873|\n",
      "                    Val-Mae: 0.04473402351140976\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 918\n",
      "Start training for stock: 3151\n",
      "\n",
      "                    Average train loss: 0.0012994477152824403 | \n",
      "                    Train-Mae: 0.019020795822143555 |\n",
      "\n",
      "                    Average val loss: 0.014592774212360382|\n",
      "                    Val-Mae: 0.02316131815314293\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 919\n",
      "Start training for stock: 3765\n",
      "\n",
      "                    Average train loss: 7.614906644448638e-06 | \n",
      "                    Train-Mae: 0.03716927766799927 |\n",
      "\n",
      "                    Average val loss: 0.01000191643834114|\n",
      "                    Val-Mae: 0.024035993963479996\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 920\n",
      "Start training for stock: 3231\n",
      "\n",
      "                    Average train loss: 0.00038684263825416565 | \n",
      "                    Train-Mae: 0.030773211270570755 |\n",
      "\n",
      "                    Average val loss: 0.01497062761336565|\n",
      "                    Val-Mae: 0.022886205464601517\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 921\n",
      "Start training for stock: 6544\n",
      "\n",
      "                    Average train loss: 2.4725613184273242e-05 | \n",
      "                    Train-Mae: 0.04089757055044174 |\n",
      "\n",
      "                    Average val loss: 0.0009297408978454769|\n",
      "                    Val-Mae: 0.019410762935876846\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 922\n",
      "Start training for stock: 4994\n",
      "\n",
      "                    Average train loss: 0.0004017369821667671 | \n",
      "                    Train-Mae: 0.04185853525996208 |\n",
      "\n",
      "                    Average val loss: 0.026023564860224724|\n",
      "                    Val-Mae: 0.02207227610051632\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 923\n",
      "Start training for stock: 6197\n",
      "\n",
      "                    Average train loss: 0.00023044824600219728 | \n",
      "                    Train-Mae: 0.024495184421539307 |\n",
      "\n",
      "                    Average val loss: 0.002337011741474271|\n",
      "                    Val-Mae: 0.018859876319766045\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 924\n",
      "Start training for stock: 3091\n",
      "\n",
      "                    Average train loss: 2.2901534102857112e-05 | \n",
      "                    Train-Mae: 0.025322848930954933 |\n",
      "\n",
      "                    Average val loss: 0.011874260380864143|\n",
      "                    Val-Mae: 0.020361892879009247\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 925\n",
      "Start training for stock: 8061\n",
      "\n",
      "                    Average train loss: 6.736124865710735e-05 | \n",
      "                    Train-Mae: 0.021355077624320984 |\n",
      "\n",
      "                    Average val loss: 0.00599916884675622|\n",
      "                    Val-Mae: 0.020054351538419724\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 926\n",
      "Start training for stock: 6882\n",
      "\n",
      "                    Average train loss: 0.00042818937450647357 | \n",
      "                    Train-Mae: 0.026366161182522774 |\n",
      "\n",
      "                    Average val loss: 0.0011146569158881903|\n",
      "                    Val-Mae: 0.021405043080449104\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 927\n",
      "Start training for stock: 6915\n",
      "\n",
      "                    Average train loss: 0.0001421778090298176 | \n",
      "                    Train-Mae: 0.021359270438551903 |\n",
      "\n",
      "                    Average val loss: 0.0013191088801249862|\n",
      "                    Val-Mae: 0.017882879823446274\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 928\n",
      "Start training for stock: 7241\n",
      "\n",
      "                    Average train loss: 0.00017495082691311835 | \n",
      "                    Train-Mae: 0.036029476672410965 |\n",
      "\n",
      "                    Average val loss: 0.0005398612702265382|\n",
      "                    Val-Mae: 0.016482755541801453\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 929\n",
      "Start training for stock: 1921\n",
      "\n",
      "                    Average train loss: 1.8977546133100987e-05 | \n",
      "                    Train-Mae: 0.030782027170062065 |\n",
      "\n",
      "                    Average val loss: 0.005794779397547245|\n",
      "                    Val-Mae: 0.018994376063346863\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 930\n",
      "Start training for stock: 8354\n",
      "\n",
      "                    Average train loss: 0.00021280400454998016 | \n",
      "                    Train-Mae: 0.029080156236886978 |\n",
      "\n",
      "                    Average val loss: 0.0021982237230986357|\n",
      "                    Val-Mae: 0.016355685889720917\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 931\n",
      "Start training for stock: 7879\n",
      "\n",
      "                    Average train loss: 0.0015331873297691346 | \n",
      "                    Train-Mae: 0.03446434810757637 |\n",
      "\n",
      "                    Average val loss: 0.004450691863894463|\n",
      "                    Val-Mae: 0.01905203051865101\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 932\n",
      "Start training for stock: 3916\n",
      "\n",
      "                    Average train loss: 2.6261350139975548e-05 | \n",
      "                    Train-Mae: 0.0252439733594656 |\n",
      "\n",
      "                    Average val loss: 0.0011306415544822812|\n",
      "                    Val-Mae: 0.019324328750371933\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 933\n",
      "Start training for stock: 1414\n",
      "\n",
      "                    Average train loss: 0.0007017497718334198 | \n",
      "                    Train-Mae: 0.029072055593132973 |\n",
      "\n",
      "                    Average val loss: 0.03535513952374458|\n",
      "                    Val-Mae: 0.024240288883447647\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 934\n",
      "Start training for stock: 4551\n",
      "\n",
      "                    Average train loss: 0.0017437557876110077 | \n",
      "                    Train-Mae: 0.04166174679994583 |\n",
      "\n",
      "                    Average val loss: 0.0980643481016159|\n",
      "                    Val-Mae: 0.03744504600763321\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 935\n",
      "Start training for stock: 7951\n",
      "\n",
      "                    Average train loss: 0.00040692869573831557 | \n",
      "                    Train-Mae: 0.049933820962905884 |\n",
      "\n",
      "                    Average val loss: 0.0722922757267952|\n",
      "                    Val-Mae: 0.03697691112756729\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 936\n",
      "Start training for stock: 3925\n",
      "\n",
      "                    Average train loss: 0.002304433286190033 | \n",
      "                    Train-Mae: 0.025942230597138405 |\n",
      "\n",
      "                    Average val loss: 0.002377528930082917|\n",
      "                    Val-Mae: 0.028805365785956383\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 937\n",
      "Start training for stock: 8101\n",
      "\n",
      "                    Average train loss: 7.304309401661158e-05 | \n",
      "                    Train-Mae: 0.025940654799342155 |\n",
      "\n",
      "                    Average val loss: 0.002101185033097863|\n",
      "                    Val-Mae: 0.021499600261449814\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 938\n",
      "Start training for stock: 6324\n",
      "\n",
      "                    Average train loss: 0.00013796082697808742 | \n",
      "                    Train-Mae: 0.03423463925719261 |\n",
      "\n",
      "                    Average val loss: 0.000610916584264487|\n",
      "                    Val-Mae: 0.018832122907042503\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 939\n",
      "Start training for stock: 1946\n",
      "\n",
      "                    Average train loss: 6.227133329957724e-05 | \n",
      "                    Train-Mae: 0.0377875417470932 |\n",
      "\n",
      "                    Average val loss: 0.0632556676864624|\n",
      "                    Val-Mae: 0.03475465252995491\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 940\n",
      "Start training for stock: 7187\n",
      "\n",
      "                    Average train loss: 0.0009385208785533905 | \n",
      "                    Train-Mae: 0.03186945244669914 |\n",
      "\n",
      "                    Average val loss: 0.007347002159804106|\n",
      "                    Val-Mae: 0.04307122156023979\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 941\n",
      "Start training for stock: 9007\n",
      "\n",
      "                    Average train loss: 3.930272359866649e-06 | \n",
      "                    Train-Mae: 0.03470153361558914 |\n",
      "\n",
      "                    Average val loss: 0.02415982075035572|\n",
      "                    Val-Mae: 0.0265315193682909\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 942\n",
      "Start training for stock: 9663\n",
      "\n",
      "                    Average train loss: 9.44732455536723e-06 | \n",
      "                    Train-Mae: 0.04058247059583664 |\n",
      "\n",
      "                    Average val loss: 0.003330883337184787|\n",
      "                    Val-Mae: 0.019803401082754135\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 943\n",
      "Start training for stock: 1890\n",
      "\n",
      "                    Average train loss: 9.437173139303922e-06 | \n",
      "                    Train-Mae: 0.030423372983932495 |\n",
      "\n",
      "                    Average val loss: 0.05428537726402283|\n",
      "                    Val-Mae: 0.03050374798476696\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 944\n",
      "Start training for stock: 6516\n",
      "\n",
      "                    Average train loss: 0.00014539285562932493 | \n",
      "                    Train-Mae: 0.02779090218245983 |\n",
      "\n",
      "                    Average val loss: 0.020928965881466866|\n",
      "                    Val-Mae: 0.026858597993850708\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 945\n",
      "Start training for stock: 7606\n",
      "\n",
      "                    Average train loss: 1.9825496710836887e-05 | \n",
      "                    Train-Mae: 0.03584115207195282 |\n",
      "\n",
      "                    Average val loss: 0.0009936628630384803|\n",
      "                    Val-Mae: 0.02260606177151203\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 946\n",
      "Start training for stock: 9628\n",
      "\n",
      "                    Average train loss: 0.0006176652759313584 | \n",
      "                    Train-Mae: 0.030857957899570465 |\n",
      "\n",
      "                    Average val loss: 0.0030381351243704557|\n",
      "                    Val-Mae: 0.017979951575398445\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 947\n",
      "Start training for stock: 8630\n",
      "\n",
      "                    Average train loss: 0.001140105649828911 | \n",
      "                    Train-Mae: 0.02597915567457676 |\n",
      "\n",
      "                    Average val loss: 0.1013886034488678|\n",
      "                    Val-Mae: 0.03606722503900528\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 948\n",
      "Start training for stock: 3539\n",
      "\n",
      "                    Average train loss: 0.00037190873175859453 | \n",
      "                    Train-Mae: 0.025004379451274872 |\n",
      "\n",
      "                    Average val loss: 0.007504138629883528|\n",
      "                    Val-Mae: 0.01856858842074871\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 949\n",
      "Start training for stock: 7191\n",
      "\n",
      "                    Average train loss: 4.77864732965827e-05 | \n",
      "                    Train-Mae: 0.033867157995700836 |\n",
      "\n",
      "                    Average val loss: 0.0005357489571906626|\n",
      "                    Val-Mae: 0.018318835645914078\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 950\n",
      "Start training for stock: 6707\n",
      "\n",
      "                    Average train loss: 8.349071256816387e-05 | \n",
      "                    Train-Mae: 0.033284664154052734 |\n",
      "\n",
      "                    Average val loss: 0.004169754683971405|\n",
      "                    Val-Mae: 0.02577730268239975\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 951\n",
      "Start training for stock: 6135\n",
      "\n",
      "                    Average train loss: 5.5601131170988085e-05 | \n",
      "                    Train-Mae: 0.03222564235329628 |\n",
      "\n",
      "                    Average val loss: 0.0010019763140007854|\n",
      "                    Val-Mae: 0.02019294537603855\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 952\n",
      "Start training for stock: 2492\n",
      "\n",
      "                    Average train loss: 4.265270195901394e-05 | \n",
      "                    Train-Mae: 0.048078082501888275 |\n",
      "\n",
      "                    Average val loss: 0.015271078795194626|\n",
      "                    Val-Mae: 0.02914637327194214\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 953\n",
      "Start training for stock: 3106\n",
      "\n",
      "                    Average train loss: 0.00013854166492819787 | \n",
      "                    Train-Mae: 0.028747929260134697 |\n",
      "\n",
      "                    Average val loss: 0.0036724917590618134|\n",
      "                    Val-Mae: 0.016882795840501785\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 954\n",
      "Start training for stock: 4968\n",
      "\n",
      "                    Average train loss: 0.0005669770017266274 | \n",
      "                    Train-Mae: 0.022866608574986458 |\n",
      "\n",
      "                    Average val loss: 0.002217226894572377|\n",
      "                    Val-Mae: 0.015227362513542175\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 955\n",
      "Start training for stock: 3856\n",
      "\n",
      "                    Average train loss: 8.108981885015964e-05 | \n",
      "                    Train-Mae: 0.03763046860694885 |\n",
      "\n",
      "                    Average val loss: 0.007880158722400665|\n",
      "                    Val-Mae: 0.03788144141435623\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 956\n",
      "Start training for stock: 8037\n",
      "\n",
      "                    Average train loss: 5.451740231364965e-05 | \n",
      "                    Train-Mae: 0.04089978337287903 |\n",
      "\n",
      "                    Average val loss: 0.009818099439144135|\n",
      "                    Val-Mae: 0.02220020815730095\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 957\n",
      "Start training for stock: 8584\n",
      "\n",
      "                    Average train loss: 0.00029271341860294343 | \n",
      "                    Train-Mae: 0.029389038681983948 |\n",
      "\n",
      "                    Average val loss: 0.033809587359428406|\n",
      "                    Val-Mae: 0.02671506442129612\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 958\n",
      "Start training for stock: 6848\n",
      "\n",
      "                    Average train loss: 0.00013680734671652316 | \n",
      "                    Train-Mae: 0.020731650292873383 |\n",
      "\n",
      "                    Average val loss: 0.0020120982080698013|\n",
      "                    Val-Mae: 0.012542912736535072\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 959\n",
      "Start training for stock: 4021\n",
      "\n",
      "                    Average train loss: 0.00027762215584516527 | \n",
      "                    Train-Mae: 0.02612651325762272 |\n",
      "\n",
      "                    Average val loss: 0.01824827678501606|\n",
      "                    Val-Mae: 0.02566097117960453\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 960\n",
      "Start training for stock: 9699\n",
      "\n",
      "                    Average train loss: 0.00014917447231709957 | \n",
      "                    Train-Mae: 0.020227650180459023 |\n",
      "\n",
      "                    Average val loss: 0.001532325055450201|\n",
      "                    Val-Mae: 0.014081894420087337\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 961\n",
      "Start training for stock: 4485\n",
      "\n",
      "                    Average train loss: 0.00012548914179205895 | \n",
      "                    Train-Mae: 0.035910915583372116 |\n",
      "\n",
      "                    Average val loss: 0.0018673690501600504|\n",
      "                    Val-Mae: 0.032848067581653595\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 962\n",
      "Start training for stock: 5702\n",
      "\n",
      "                    Average train loss: 5.136076360940933e-05 | \n",
      "                    Train-Mae: 0.039395883679389954 |\n",
      "\n",
      "                    Average val loss: 0.11629447340965271|\n",
      "                    Val-Mae: 0.052295878529548645\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 963\n",
      "Start training for stock: 3543\n",
      "\n",
      "                    Average train loss: 0.0017274089157581329 | \n",
      "                    Train-Mae: 0.019733939319849014 |\n",
      "\n",
      "                    Average val loss: 0.04398792237043381|\n",
      "                    Val-Mae: 0.02421177551150322\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 964\n",
      "Start training for stock: 9069\n",
      "\n",
      "                    Average train loss: 0.002543775141239166 | \n",
      "                    Train-Mae: 0.03687740117311478 |\n",
      "\n",
      "                    Average val loss: 0.030781880021095276|\n",
      "                    Val-Mae: 0.02344322018325329\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 965\n",
      "Start training for stock: 5301\n",
      "\n",
      "                    Average train loss: 0.0016930128633975982 | \n",
      "                    Train-Mae: 0.02915523387491703 |\n",
      "\n",
      "                    Average val loss: 0.0026275410782545805|\n",
      "                    Val-Mae: 0.02342066913843155\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 966\n",
      "Start training for stock: 7231\n",
      "\n",
      "                    Average train loss: 1.0048944968730211e-05 | \n",
      "                    Train-Mae: 0.0253042783588171 |\n",
      "\n",
      "                    Average val loss: 0.000540312787052244|\n",
      "                    Val-Mae: 0.015029434114694595\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 967\n",
      "Start training for stock: 3201\n",
      "\n",
      "                    Average train loss: 0.0010498976707458496 | \n",
      "                    Train-Mae: 0.03159241005778313 |\n",
      "\n",
      "                    Average val loss: 0.0006475335685536265|\n",
      "                    Val-Mae: 0.012092243880033493\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 968\n",
      "Start training for stock: 8173\n",
      "\n",
      "                    Average train loss: 0.00019078860059380532 | \n",
      "                    Train-Mae: 0.03702302649617195 |\n",
      "\n",
      "                    Average val loss: 0.0032538753002882004|\n",
      "                    Val-Mae: 0.017198484390974045\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 969\n",
      "Start training for stock: 2804\n",
      "\n",
      "                    Average train loss: 0.00011924723163247109 | \n",
      "                    Train-Mae: 0.03983857110142708 |\n",
      "\n",
      "                    Average val loss: 0.005606718361377716|\n",
      "                    Val-Mae: 0.02083582989871502\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 970\n",
      "Start training for stock: 5201\n",
      "\n",
      "                    Average train loss: 3.377215703949332e-05 | \n",
      "                    Train-Mae: 0.0279377531260252 |\n",
      "\n",
      "                    Average val loss: 0.0003903082979377359|\n",
      "                    Val-Mae: 0.014970667660236359\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 971\n",
      "Start training for stock: 7466\n",
      "\n",
      "                    Average train loss: 3.7787517067044973e-06 | \n",
      "                    Train-Mae: 0.02278272993862629 |\n",
      "\n",
      "                    Average val loss: 0.0029018514323979616|\n",
      "                    Val-Mae: 0.014013071544468403\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 972\n",
      "Start training for stock: 5440\n",
      "\n",
      "                    Average train loss: 3.431266639381647e-05 | \n",
      "                    Train-Mae: 0.03396933525800705 |\n",
      "\n",
      "                    Average val loss: 0.012291072867810726|\n",
      "                    Val-Mae: 0.022867439314723015\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 973\n",
      "Start training for stock: 4221\n",
      "\n",
      "                    Average train loss: 0.0004535121470689774 | \n",
      "                    Train-Mae: 0.03407900035381317 |\n",
      "\n",
      "                    Average val loss: 0.04186483845114708|\n",
      "                    Val-Mae: 0.03143852576613426\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 974\n",
      "Start training for stock: 4662\n",
      "\n",
      "                    Average train loss: 0.004866753220558167 | \n",
      "                    Train-Mae: 0.05276935175061226 |\n",
      "\n",
      "                    Average val loss: 0.023873474448919296|\n",
      "                    Val-Mae: 0.02971024066209793\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 975\n",
      "Start training for stock: 5017\n",
      "\n",
      "                    Average train loss: 0.0010510682314634322 | \n",
      "                    Train-Mae: 0.02385469153523445 |\n",
      "\n",
      "                    Average val loss: 0.0015835082158446312|\n",
      "                    Val-Mae: 0.020127516239881516\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 976\n",
      "Start training for stock: 6191\n",
      "\n",
      "                    Average train loss: 2.735160291194916e-05 | \n",
      "                    Train-Mae: 0.04817400127649307 |\n",
      "\n",
      "                    Average val loss: 0.02614404261112213|\n",
      "                    Val-Mae: 0.04223151132464409\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 977\n",
      "Start training for stock: 7735\n",
      "\n",
      "                    Average train loss: 0.0018189436197280885 | \n",
      "                    Train-Mae: 0.030873822048306465 |\n",
      "\n",
      "                    Average val loss: 0.005533220246434212|\n",
      "                    Val-Mae: 0.02378748543560505\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 978\n",
      "Start training for stock: 3784\n",
      "\n",
      "                    Average train loss: 0.00043083280324935914 | \n",
      "                    Train-Mae: 0.034858155995607376 |\n",
      "\n",
      "                    Average val loss: 0.003995120525360107|\n",
      "                    Val-Mae: 0.020226623862981796\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 979\n",
      "Start training for stock: 8278\n",
      "\n",
      "                    Average train loss: 0.0001448753010481596 | \n",
      "                    Train-Mae: 0.022366268560290337 |\n",
      "\n",
      "                    Average val loss: 0.008294760249555111|\n",
      "                    Val-Mae: 0.019372710958123207\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 980\n",
      "Start training for stock: 2183\n",
      "\n",
      "                    Average train loss: 0.0003415856882929802 | \n",
      "                    Train-Mae: 0.02742592990398407 |\n",
      "\n",
      "                    Average val loss: 0.003110629739239812|\n",
      "                    Val-Mae: 0.021668264642357826\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 981\n",
      "Start training for stock: 1435\n",
      "\n",
      "                    Average train loss: 5.1271701231598854e-05 | \n",
      "                    Train-Mae: 0.026976710185408592 |\n",
      "\n",
      "                    Average val loss: 0.001788094057701528|\n",
      "                    Val-Mae: 0.025056317448616028\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 982\n",
      "Start training for stock: 3648\n",
      "\n",
      "                    Average train loss: 4.7957575879991055e-05 | \n",
      "                    Train-Mae: 0.020051749423146248 |\n",
      "\n",
      "                    Average val loss: 0.0001712797675281763|\n",
      "                    Val-Mae: 0.009637766517698765\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 983\n",
      "Start training for stock: 9906\n",
      "\n",
      "                    Average train loss: 0.0012122703343629838 | \n",
      "                    Train-Mae: 0.06078702211380005 |\n",
      "\n",
      "                    Average val loss: 0.0031077302992343903|\n",
      "                    Val-Mae: 0.019485192373394966\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 984\n",
      "Start training for stock: 7596\n",
      "\n",
      "                    Average train loss: 0.00010544744320213795 | \n",
      "                    Train-Mae: 0.03460961952805519 |\n",
      "\n",
      "                    Average val loss: 0.0558667853474617|\n",
      "                    Val-Mae: 0.027004698291420937\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 985\n",
      "Start training for stock: 9536\n",
      "\n",
      "                    Average train loss: 0.000420696996152401 | \n",
      "                    Train-Mae: 0.024548007175326347 |\n",
      "\n",
      "                    Average val loss: 0.0005155770340934396|\n",
      "                    Val-Mae: 0.013870595023036003\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 986\n",
      "Start training for stock: 3817\n",
      "\n",
      "                    Average train loss: 0.0009166371822357178 | \n",
      "                    Train-Mae: 0.017629599198698997 |\n",
      "\n",
      "                    Average val loss: 0.06647827476263046|\n",
      "                    Val-Mae: 0.02914178930222988\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 987\n",
      "Start training for stock: 6293\n",
      "\n",
      "                    Average train loss: 0.0026581791043281556 | \n",
      "                    Train-Mae: 0.0312321949750185 |\n",
      "\n",
      "                    Average val loss: 0.012353871949017048|\n",
      "                    Val-Mae: 0.026090754196047783\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 988\n",
      "Start training for stock: 8881\n",
      "\n",
      "                    Average train loss: 0.00039074983447790146 | \n",
      "                    Train-Mae: 0.02715587429702282 |\n",
      "\n",
      "                    Average val loss: 0.0045168716460466385|\n",
      "                    Val-Mae: 0.019118769094347954\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 989\n",
      "Start training for stock: 5715\n",
      "\n",
      "                    Average train loss: 0.0001750190369784832 | \n",
      "                    Train-Mae: 0.020526714622974396 |\n",
      "\n",
      "                    Average val loss: 0.000956761185079813|\n",
      "                    Val-Mae: 0.01459574606269598\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 990\n",
      "Start training for stock: 7013\n",
      "\n",
      "                    Average train loss: 0.000755629763007164 | \n",
      "                    Train-Mae: 0.039312757551670074 |\n",
      "\n",
      "                    Average val loss: 0.0007367293001152575|\n",
      "                    Val-Mae: 0.02024397812783718\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 991\n",
      "Start training for stock: 4668\n",
      "\n",
      "                    Average train loss: 0.0005441626161336899 | \n",
      "                    Train-Mae: 0.02610587514936924 |\n",
      "\n",
      "                    Average val loss: 0.002865185495465994|\n",
      "                    Val-Mae: 0.016256041824817657\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 992\n",
      "Start training for stock: 5262\n",
      "\n",
      "                    Average train loss: 2.9775544535368682e-05 | \n",
      "                    Train-Mae: 0.029016010463237762 |\n",
      "\n",
      "                    Average val loss: 0.005791562143713236|\n",
      "                    Val-Mae: 0.012810660526156425\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 993\n",
      "Start training for stock: 7315\n",
      "\n",
      "                    Average train loss: 0.0013126243650913238 | \n",
      "                    Train-Mae: 0.02616673707962036 |\n",
      "\n",
      "                    Average val loss: 0.002881822409108281|\n",
      "                    Val-Mae: 0.021065300330519676\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 994\n",
      "Start training for stock: 6918\n",
      "\n",
      "                    Average train loss: 0.0005580060556530952 | \n",
      "                    Train-Mae: 0.036314863711595535 |\n",
      "\n",
      "                    Average val loss: 0.008525332435965538|\n",
      "                    Val-Mae: 0.02532902918756008\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 995\n",
      "Start training for stock: 4569\n",
      "\n",
      "                    Average train loss: 0.000997440665960312 | \n",
      "                    Train-Mae: 0.031372785568237305 |\n",
      "\n",
      "                    Average val loss: 0.014888440258800983|\n",
      "                    Val-Mae: 0.018245123326778412\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 996\n",
      "Start training for stock: 5809\n",
      "\n",
      "                    Average train loss: 3.7150641437619926e-05 | \n",
      "                    Train-Mae: 0.023172253742814064 |\n",
      "\n",
      "                    Average val loss: 0.012188635766506195|\n",
      "                    Val-Mae: 0.01882694475352764\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 997\n",
      "Start training for stock: 8508\n",
      "\n",
      "                    Average train loss: 0.0013059131801128388 | \n",
      "                    Train-Mae: 0.03132394328713417 |\n",
      "\n",
      "                    Average val loss: 0.0029988216701895|\n",
      "                    Val-Mae: 0.026622602716088295\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 998\n",
      "Start training for stock: 8385\n",
      "\n",
      "                    Average train loss: 9.71368164755404e-06 | \n",
      "                    Train-Mae: 0.029118843376636505 |\n",
      "\n",
      "                    Average val loss: 0.0005423039547167718|\n",
      "                    Val-Mae: 0.013378477655351162\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 999\n",
      "Start training for stock: 4587\n",
      "\n",
      "                    Average train loss: 7.833147421479225e-05 | \n",
      "                    Train-Mae: 0.030948219820857048 |\n",
      "\n",
      "                    Average val loss: 0.014582682400941849|\n",
      "                    Val-Mae: 0.029641659930348396\n",
      "                    \n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1000\n",
      "Start training for stock: 2001\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1001\n",
      "Start training for stock: 8306\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1002\n",
      "Start training for stock: 1884\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1003\n",
      "Start training for stock: 4880\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1004\n",
      "Start training for stock: 6454\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1005\n",
      "Start training for stock: 6095\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1006\n",
      "Start training for stock: 7987\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1007\n",
      "Start training for stock: 1939\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1008\n",
      "Start training for stock: 9831\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1009\n",
      "Start training for stock: 3395\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1010\n",
      "Start training for stock: 2315\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1011\n",
      "Start training for stock: 7298\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1012\n",
      "Start training for stock: 6769\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1013\n",
      "Start training for stock: 6145\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1014\n",
      "Start training for stock: 7475\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1015\n",
      "Start training for stock: 8117\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1016\n",
      "Start training for stock: 5741\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1017\n",
      "Start training for stock: 9267\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1018\n",
      "Start training for stock: 3180\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1019\n",
      "Start training for stock: 2395\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1020\n",
      "Start training for stock: 9422\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1021\n",
      "Start training for stock: 3284\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1022\n",
      "Start training for stock: 2127\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1023\n",
      "Start training for stock: 8929\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1024\n",
      "Start training for stock: 6517\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1025\n",
      "Start training for stock: 3932\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1026\n",
      "Start training for stock: 7198\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1027\n",
      "Start training for stock: 3405\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1028\n",
      "Start training for stock: 4384\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1029\n",
      "Start training for stock: 4572\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1030\n",
      "Start training for stock: 7976\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1031\n",
      "Start training for stock: 4768\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1032\n",
      "Start training for stock: 6484\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1033\n",
      "Start training for stock: 2791\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1034\n",
      "Start training for stock: 9076\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1035\n",
      "Start training for stock: 5208\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1036\n",
      "Start training for stock: 4849\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1037\n",
      "Start training for stock: 8572\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1038\n",
      "Start training for stock: 8793\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1039\n",
      "Start training for stock: 9672\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1040\n",
      "Start training for stock: 4813\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1041\n",
      "Start training for stock: 8279\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1042\n",
      "Start training for stock: 1852\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1043\n",
      "Start training for stock: 8052\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1044\n",
      "Start training for stock: 3900\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1045\n",
      "Start training for stock: 4290\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1046\n",
      "Start training for stock: 9627\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1047\n",
      "Start training for stock: 6967\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1048\n",
      "Start training for stock: 6184\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1049\n",
      "Start training for stock: 8841\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1050\n",
      "Start training for stock: 6724\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1051\n",
      "Start training for stock: 2695\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1052\n",
      "Start training for stock: 1975\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1053\n",
      "Start training for stock: 8925\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1054\n",
      "Start training for stock: 8920\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1055\n",
      "Start training for stock: 2389\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1056\n",
      "Start training for stock: 9008\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1057\n",
      "Start training for stock: 4327\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1058\n",
      "Start training for stock: 6881\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1059\n",
      "Start training for stock: 1944\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1060\n",
      "Start training for stock: 3853\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1061\n",
      "Start training for stock: 3415\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1062\n",
      "Start training for stock: 7832\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1063\n",
      "Start training for stock: 8059\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1064\n",
      "Start training for stock: 9302\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1065\n",
      "Start training for stock: 1954\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1066\n",
      "Start training for stock: 1805\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1067\n",
      "Start training for stock: 6417\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1068\n",
      "Start training for stock: 8066\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1069\n",
      "Start training for stock: 4169\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1070\n",
      "Start training for stock: 8273\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1071\n",
      "Start training for stock: 6762\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1072\n",
      "Start training for stock: 5957\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1073\n",
      "Start training for stock: 2784\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1074\n",
      "Start training for stock: 8368\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1075\n",
      "Start training for stock: 9962\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1076\n",
      "Start training for stock: 3197\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1077\n",
      "Start training for stock: 4312\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1078\n",
      "Start training for stock: 8200\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1079\n",
      "Start training for stock: 2698\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1080\n",
      "Start training for stock: 6640\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1081\n",
      "Start training for stock: 7637\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1082\n",
      "Start training for stock: 2146\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1083\n",
      "Start training for stock: 7085\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1084\n",
      "Start training for stock: 6612\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1085\n",
      "Start training for stock: 4733\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1086\n",
      "Start training for stock: 6879\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1087\n",
      "Start training for stock: 3291\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1088\n",
      "Start training for stock: 9324\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1089\n",
      "Start training for stock: 8133\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1090\n",
      "Start training for stock: 6473\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1091\n",
      "Start training for stock: 4671\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1092\n",
      "Start training for stock: 3480\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1093\n",
      "Start training for stock: 7180\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1094\n",
      "Start training for stock: 6460\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1095\n",
      "Start training for stock: 8392\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1096\n",
      "Start training for stock: 5351\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1097\n",
      "Start training for stock: 8905\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1098\n",
      "Start training for stock: 3355\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1099\n",
      "Start training for stock: 8255\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1100\n",
      "Start training for stock: 4051\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1101\n",
      "Start training for stock: 6971\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1102\n",
      "Start training for stock: 8065\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1103\n",
      "Start training for stock: 9086\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1104\n",
      "Start training for stock: 2418\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1105\n",
      "Start training for stock: 4547\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1106\n",
      "Start training for stock: 6645\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1107\n",
      "Start training for stock: 3085\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1108\n",
      "Start training for stock: 9414\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1109\n",
      "Start training for stock: 7224\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1110\n",
      "Start training for stock: 5406\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1111\n",
      "Start training for stock: 4495\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1112\n",
      "Start training for stock: 4026\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1113\n",
      "Start training for stock: 2761\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1114\n",
      "Start training for stock: 6367\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1115\n",
      "Start training for stock: 4502\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1116\n",
      "Start training for stock: 8141\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1117\n",
      "Start training for stock: 2670\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1118\n",
      "Start training for stock: 5711\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1119\n",
      "Start training for stock: 8360\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1120\n",
      "Start training for stock: 7270\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1121\n",
      "Start training for stock: 3341\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1122\n",
      "Start training for stock: 5333\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1123\n",
      "Start training for stock: 4902\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1124\n",
      "Start training for stock: 1981\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1125\n",
      "Start training for stock: 8051\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1126\n",
      "Start training for stock: 8089\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1127\n",
      "Start training for stock: 6951\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1128\n",
      "Start training for stock: 8366\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1129\n",
      "Start training for stock: 7342\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1130\n",
      "Start training for stock: 5411\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1131\n",
      "Start training for stock: 6986\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1132\n",
      "Start training for stock: 9759\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1133\n",
      "Start training for stock: 4118\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1134\n",
      "Start training for stock: 8544\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1135\n",
      "Start training for stock: 7860\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1136\n",
      "Start training for stock: 4931\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1137\n",
      "Start training for stock: 3993\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1138\n",
      "Start training for stock: 4385\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1139\n",
      "Start training for stock: 3902\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1140\n",
      "Start training for stock: 2292\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1141\n",
      "Start training for stock: 4914\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1142\n",
      "Start training for stock: 8369\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1143\n",
      "Start training for stock: 7970\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1144\n",
      "Start training for stock: 3245\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1145\n",
      "Start training for stock: 2664\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1146\n",
      "Start training for stock: 5805\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1147\n",
      "Start training for stock: 3540\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1148\n",
      "Start training for stock: 4709\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1149\n",
      "Start training for stock: 1941\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1150\n",
      "Start training for stock: 3891\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1151\n",
      "Start training for stock: 9534\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1152\n",
      "Start training for stock: 9025\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1153\n",
      "Start training for stock: 5013\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1154\n",
      "Start training for stock: 7453\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1155\n",
      "Start training for stock: 6996\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1156\n",
      "Start training for stock: 8393\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1157\n",
      "Start training for stock: 9640\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1158\n",
      "Start training for stock: 7520\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1159\n",
      "Start training for stock: 6284\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1160\n",
      "Start training for stock: 3491\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1161\n",
      "Start training for stock: 4229\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1162\n",
      "Start training for stock: 7095\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1163\n",
      "Start training for stock: 8334\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1164\n",
      "Start training for stock: 8095\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1165\n",
      "Start training for stock: 2168\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1166\n",
      "Start training for stock: 7731\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1167\n",
      "Start training for stock: 7942\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1168\n",
      "Start training for stock: 7164\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1169\n",
      "Start training for stock: 3445\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1170\n",
      "Start training for stock: 2266\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1171\n",
      "Start training for stock: 3176\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1172\n",
      "Start training for stock: 7226\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1173\n",
      "Start training for stock: 3402\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1174\n",
      "Start training for stock: 1887\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1175\n",
      "Start training for stock: 7061\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1176\n",
      "Start training for stock: 2501\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1177\n",
      "Start training for stock: 3903\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1178\n",
      "Start training for stock: 3186\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1179\n",
      "Start training for stock: 1969\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1180\n",
      "Start training for stock: 6379\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1181\n",
      "Start training for stock: 6067\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1182\n",
      "Start training for stock: 2217\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1183\n",
      "Start training for stock: 6754\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1184\n",
      "Start training for stock: 8771\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1185\n",
      "Start training for stock: 7906\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1186\n",
      "Start training for stock: 9991\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1187\n",
      "Start training for stock: 2692\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1188\n",
      "Start training for stock: 2607\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1189\n",
      "Start training for stock: 9006\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1190\n",
      "Start training for stock: 3167\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1191\n",
      "Start training for stock: 2148\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1192\n",
      "Start training for stock: 4218\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1193\n",
      "Start training for stock: 9994\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1194\n",
      "Start training for stock: 3132\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1195\n",
      "Start training for stock: 6457\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1196\n",
      "Start training for stock: 9001\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1197\n",
      "Start training for stock: 2440\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1198\n",
      "Start training for stock: 2686\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1199\n",
      "Start training for stock: 2379\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1200\n",
      "Start training for stock: 9919\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1201\n",
      "Start training for stock: 3388\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1202\n",
      "Start training for stock: 6094\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1203\n",
      "Start training for stock: 9697\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1204\n",
      "Start training for stock: 4523\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1205\n",
      "Start training for stock: 8616\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1206\n",
      "Start training for stock: 9449\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1207\n",
      "Start training for stock: 3116\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1208\n",
      "Start training for stock: 4337\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1209\n",
      "Start training for stock: 6305\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1210\n",
      "Start training for stock: 2802\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1211\n",
      "Start training for stock: 6381\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1212\n",
      "Start training for stock: 9766\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1213\n",
      "Start training for stock: 4058\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1214\n",
      "Start training for stock: 6622\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1215\n",
      "Start training for stock: 6938\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1216\n",
      "Start training for stock: 2003\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1217\n",
      "Start training for stock: 7762\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1218\n",
      "Start training for stock: 9740\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1219\n",
      "Start training for stock: 4410\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1220\n",
      "Start training for stock: 4549\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1221\n",
      "Start training for stock: 1663\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1222\n",
      "Start training for stock: 5384\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1223\n",
      "Start training for stock: 2715\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1224\n",
      "Start training for stock: 1835\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1225\n",
      "Start training for stock: 6768\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1226\n",
      "Start training for stock: 5821\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1227\n",
      "Start training for stock: 3656\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1228\n",
      "Start training for stock: 4599\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1229\n",
      "Start training for stock: 7192\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1230\n",
      "Start training for stock: 7717\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1231\n",
      "Start training for stock: 5008\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1232\n",
      "Start training for stock: 3001\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1233\n",
      "Start training for stock: 2335\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1234\n",
      "Start training for stock: 2899\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1235\n",
      "Start training for stock: 5909\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1236\n",
      "Start training for stock: 9416\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1237\n",
      "Start training for stock: 6912\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1238\n",
      "Start training for stock: 3166\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1239\n",
      "Start training for stock: 3034\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1240\n",
      "Start training for stock: 9842\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1241\n",
      "Start training for stock: 5918\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1242\n",
      "Start training for stock: 9022\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1243\n",
      "Start training for stock: 2325\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1244\n",
      "Start training for stock: 3548\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1245\n",
      "Start training for stock: 2651\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1246\n",
      "Start training for stock: 1419\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1247\n",
      "Start training for stock: 8795\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1248\n",
      "Start training for stock: 6464\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1249\n",
      "Start training for stock: 1961\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1250\n",
      "Start training for stock: 8012\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1251\n",
      "Start training for stock: 8361\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1252\n",
      "Start training for stock: 5290\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1253\n",
      "Start training for stock: 8624\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1254\n",
      "Start training for stock: 8622\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1255\n",
      "Start training for stock: 3028\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1256\n",
      "Start training for stock: 9605\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1257\n",
      "Start training for stock: 8395\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1258\n",
      "Start training for stock: 9744\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1259\n",
      "Start training for stock: 9716\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1260\n",
      "Start training for stock: 6905\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1261\n",
      "Start training for stock: 3865\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1262\n",
      "Start training for stock: 1929\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1263\n",
      "Start training for stock: 3962\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1264\n",
      "Start training for stock: 6471\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1265\n",
      "Start training for stock: 4109\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1266\n",
      "Start training for stock: 2374\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1267\n",
      "Start training for stock: 2060\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1268\n",
      "Start training for stock: 2124\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1269\n",
      "Start training for stock: 2925\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1270\n",
      "Start training for stock: 6480\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1271\n",
      "Start training for stock: 6413\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1272\n",
      "Start training for stock: 4461\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1273\n",
      "Start training for stock: 4816\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1274\n",
      "Start training for stock: 8382\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1275\n",
      "Start training for stock: 7550\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1276\n",
      "Start training for stock: 4368\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1277\n",
      "Start training for stock: 8303\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1278\n",
      "Start training for stock: 8308\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1279\n",
      "Start training for stock: 3479\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1280\n",
      "Start training for stock: 4435\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1281\n",
      "Start training for stock: 9882\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1282\n",
      "Start training for stock: 2914\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1283\n",
      "Start training for stock: 9033\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1284\n",
      "Start training for stock: 6753\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1285\n",
      "Start training for stock: 3150\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1286\n",
      "Start training for stock: 9856\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1287\n",
      "Start training for stock: 9619\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1288\n",
      "Start training for stock: 6257\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1289\n",
      "Start training for stock: 1820\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1290\n",
      "Start training for stock: 4722\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1291\n",
      "Start training for stock: 7739\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1292\n",
      "Start training for stock: 4743\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1293\n",
      "Start training for stock: 3733\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1294\n",
      "Start training for stock: 9977\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1295\n",
      "Start training for stock: 8160\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1296\n",
      "Start training for stock: 9837\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1297\n",
      "Start training for stock: 8276\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1298\n",
      "Start training for stock: 3558\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1299\n",
      "Start training for stock: 3103\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1300\n",
      "Start training for stock: 4506\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1301\n",
      "Start training for stock: 3182\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1302\n",
      "Start training for stock: 3665\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1303\n",
      "Start training for stock: 7313\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1304\n",
      "Start training for stock: 6332\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1305\n",
      "Start training for stock: 9535\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1306\n",
      "Start training for stock: 7636\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1307\n",
      "Start training for stock: 6637\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1308\n",
      "Start training for stock: 9861\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1309\n",
      "Start training for stock: 4745\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1310\n",
      "Start training for stock: 2207\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1311\n",
      "Start training for stock: 3676\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1312\n",
      "Start training for stock: 6794\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1313\n",
      "Start training for stock: 4579\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1314\n",
      "Start training for stock: 6653\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1315\n",
      "Start training for stock: 8604\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1316\n",
      "Start training for stock: 5101\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1317\n",
      "Start training for stock: 6482\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1318\n",
      "Start training for stock: 6028\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1319\n",
      "Start training for stock: 6273\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1320\n",
      "Start training for stock: 8934\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1321\n",
      "Start training for stock: 3407\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1322\n",
      "Start training for stock: 9682\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1323\n",
      "Start training for stock: 8345\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1324\n",
      "Start training for stock: 6744\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1325\n",
      "Start training for stock: 9450\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1326\n",
      "Start training for stock: 6958\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1327\n",
      "Start training for stock: 8609\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1328\n",
      "Start training for stock: 1712\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1329\n",
      "Start training for stock: 7184\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1330\n",
      "Start training for stock: 4792\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1331\n",
      "Start training for stock: 3397\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1332\n",
      "Start training for stock: 2749\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1333\n",
      "Start training for stock: 6995\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1334\n",
      "Start training for stock: 7921\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1335\n",
      "Start training for stock: 6376\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1336\n",
      "Start training for stock: 4527\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1337\n",
      "Start training for stock: 9900\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1338\n",
      "Start training for stock: 7958\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1339\n",
      "Start training for stock: 7445\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1340\n",
      "Start training for stock: 6588\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1341\n",
      "Start training for stock: 5357\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1342\n",
      "Start training for stock: 4301\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1343\n",
      "Start training for stock: 7463\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1344\n",
      "Start training for stock: 8359\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1345\n",
      "Start training for stock: 4390\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1346\n",
      "Start training for stock: 5713\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1347\n",
      "Start training for stock: 5288\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1348\n",
      "Start training for stock: 6798\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1349\n",
      "Start training for stock: 6976\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1350\n",
      "Start training for stock: 4581\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1351\n",
      "Start training for stock: 9028\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1352\n",
      "Start training for stock: 8093\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1353\n",
      "Start training for stock: 4612\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1354\n",
      "Start training for stock: 9850\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1355\n",
      "Start training for stock: 3092\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1356\n",
      "Start training for stock: 8198\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1357\n",
      "Start training for stock: 9052\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1358\n",
      "Start training for stock: 6750\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1359\n",
      "Start training for stock: 8628\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1360\n",
      "Start training for stock: 4382\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1361\n",
      "Start training for stock: 8806\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1362\n",
      "Start training for stock: 2158\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1363\n",
      "Start training for stock: 6254\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1364\n",
      "Start training for stock: 6462\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1365\n",
      "Start training for stock: 5217\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1366\n",
      "Start training for stock: 4839\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1367\n",
      "Start training for stock: 4307\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1368\n",
      "Start training for stock: 9928\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1369\n",
      "Start training for stock: 6814\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1370\n",
      "Start training for stock: 8377\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1371\n",
      "Start training for stock: 3498\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1372\n",
      "Start training for stock: 1980\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1373\n",
      "Start training for stock: 6999\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1374\n",
      "Start training for stock: 8103\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1375\n",
      "Start training for stock: 4708\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1376\n",
      "Start training for stock: 3139\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1377\n",
      "Start training for stock: 9057\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1378\n",
      "Start training for stock: 8387\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1379\n",
      "Start training for stock: 5121\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1380\n",
      "Start training for stock: 5110\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1381\n",
      "Start training for stock: 6937\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1382\n",
      "Start training for stock: 9413\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1383\n",
      "Start training for stock: 5982\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1384\n",
      "Start training for stock: 7250\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1385\n",
      "Start training for stock: 8923\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1386\n",
      "Start training for stock: 9531\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1387\n",
      "Start training for stock: 6997\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1388\n",
      "Start training for stock: 7745\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1389\n",
      "Start training for stock: 8850\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1390\n",
      "Start training for stock: 4448\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1391\n",
      "Start training for stock: 2002\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1392\n",
      "Start training for stock: 4980\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1393\n",
      "Start training for stock: 6199\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1394\n",
      "Start training for stock: 6419\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1395\n",
      "Start training for stock: 7459\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1396\n",
      "Start training for stock: 9539\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1397\n",
      "Start training for stock: 3697\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1398\n",
      "Start training for stock: 6349\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1399\n",
      "Start training for stock: 7532\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1400\n",
      "Start training for stock: 6929\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1401\n",
      "Start training for stock: 4212\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1402\n",
      "Start training for stock: 7605\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1403\n",
      "Start training for stock: 7685\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1404\n",
      "Start training for stock: 7504\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1405\n",
      "Start training for stock: 6890\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1406\n",
      "Start training for stock: 3906\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1407\n",
      "Start training for stock: 4584\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1408\n",
      "Start training for stock: 3302\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1409\n",
      "Start training for stock: 6113\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1410\n",
      "Start training for stock: 6834\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1411\n",
      "Start training for stock: 8081\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1412\n",
      "Start training for stock: 3449\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1413\n",
      "Start training for stock: 3546\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1414\n",
      "Start training for stock: 7803\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1415\n",
      "Start training for stock: 8830\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1416\n",
      "Start training for stock: 6652\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1417\n",
      "Start training for stock: 2337\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1418\n",
      "Start training for stock: 4563\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1419\n",
      "Start training for stock: 5019\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1420\n",
      "Start training for stock: 3580\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1421\n",
      "Start training for stock: 7912\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1422\n",
      "Start training for stock: 6617\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1423\n",
      "Start training for stock: 8842\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1424\n",
      "Start training for stock: 4633\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1425\n",
      "Start training for stock: 2884\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1426\n",
      "Start training for stock: 7956\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1427\n",
      "Start training for stock: 6538\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1428\n",
      "Start training for stock: 8002\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1429\n",
      "Start training for stock: 4434\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1430\n",
      "Start training for stock: 4694\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1431\n",
      "Start training for stock: 3915\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1432\n",
      "Start training for stock: 6474\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1433\n",
      "Start training for stock: 6507\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1434\n",
      "Start training for stock: 4565\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1435\n",
      "Start training for stock: 7917\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1436\n",
      "Start training for stock: 1301\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1437\n",
      "Start training for stock: 7609\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1438\n",
      "Start training for stock: 6737\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1439\n",
      "Start training for stock: 5933\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1440\n",
      "Start training for stock: 6584\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1441\n",
      "Start training for stock: 8418\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1442\n",
      "Start training for stock: 8140\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1443\n",
      "Start training for stock: 6947\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1444\n",
      "Start training for stock: 8154\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1445\n",
      "Start training for stock: 3105\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1446\n",
      "Start training for stock: 1982\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1447\n",
      "Start training for stock: 7287\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1448\n",
      "Start training for stock: 2540\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1449\n",
      "Start training for stock: 6670\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1450\n",
      "Start training for stock: 5261\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1451\n",
      "Start training for stock: 2733\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1452\n",
      "Start training for stock: 9896\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1453\n",
      "Start training for stock: 8275\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1454\n",
      "Start training for stock: 9143\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1455\n",
      "Start training for stock: 7984\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1456\n",
      "Start training for stock: 8541\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1457\n",
      "Start training for stock: 6877\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1458\n",
      "Start training for stock: 3244\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1459\n",
      "Start training for stock: 2737\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1460\n",
      "Start training for stock: 4687\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1461\n",
      "Start training for stock: 1723\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1462\n",
      "Start training for stock: 5142\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1463\n",
      "Start training for stock: 8163\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1464\n",
      "Start training for stock: 7726\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1465\n",
      "Start training for stock: 9260\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1466\n",
      "Start training for stock: 4544\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1467\n",
      "Start training for stock: 8053\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1468\n",
      "Start training for stock: 9110\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1469\n",
      "Start training for stock: 1375\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1470\n",
      "Start training for stock: 2198\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1471\n",
      "Start training for stock: 5161\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1472\n",
      "Start training for stock: 3196\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1473\n",
      "Start training for stock: 2923\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1474\n",
      "Start training for stock: 4578\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1475\n",
      "Start training for stock: 6357\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1476\n",
      "Start training for stock: 8706\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1477\n",
      "Start training for stock: 9974\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1478\n",
      "Start training for stock: 3264\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1479\n",
      "Start training for stock: 9021\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1480\n",
      "Start training for stock: 8364\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1481\n",
      "Start training for stock: 6952\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1482\n",
      "Start training for stock: 2653\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1483\n",
      "Start training for stock: 7513\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1484\n",
      "Start training for stock: 7169\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1485\n",
      "Start training for stock: 3153\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1486\n",
      "Start training for stock: 7730\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1487\n",
      "Start training for stock: 8798\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1488\n",
      "Start training for stock: 4298\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1489\n",
      "Start training for stock: 7816\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1490\n",
      "Start training for stock: 9795\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1491\n",
      "Start training for stock: 3679\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1492\n",
      "Start training for stock: 1888\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1493\n",
      "Start training for stock: 6178\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1494\n",
      "Start training for stock: 7480\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1495\n",
      "Start training for stock: 2694\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1496\n",
      "Start training for stock: 4478\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1497\n",
      "Start training for stock: 2114\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1498\n",
      "Start training for stock: 9880\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1499\n",
      "Start training for stock: 8159\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1500\n",
      "Start training for stock: 8410\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1501\n",
      "Start training for stock: 4188\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1502\n",
      "Start training for stock: 2160\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1503\n",
      "Start training for stock: 7065\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1504\n",
      "Start training for stock: 6246\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1505\n",
      "Start training for stock: 8715\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1506\n",
      "Start training for stock: 8174\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1507\n",
      "Start training for stock: 8424\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1508\n",
      "Start training for stock: 5233\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1509\n",
      "Start training for stock: 4571\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1510\n",
      "Start training for stock: 2206\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1511\n",
      "Start training for stock: 6247\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1512\n",
      "Start training for stock: 8282\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1513\n",
      "Start training for stock: 1381\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1514\n",
      "Start training for stock: 3921\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1515\n",
      "Start training for stock: 5269\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1516\n",
      "Start training for stock: 6013\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1517\n",
      "Start training for stock: 4423\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1518\n",
      "Start training for stock: 9270\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1519\n",
      "Start training for stock: 5945\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1520\n",
      "Start training for stock: 8386\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1521\n",
      "Start training for stock: 9401\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1522\n",
      "Start training for stock: 3465\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1523\n",
      "Start training for stock: 9793\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1524\n",
      "Start training for stock: 3198\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1525\n",
      "Start training for stock: 7458\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1526\n",
      "Start training for stock: 2269\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1527\n",
      "Start training for stock: 3159\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1528\n",
      "Start training for stock: 3031\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1529\n",
      "Start training for stock: 9072\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1530\n",
      "Start training for stock: 4326\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1531\n",
      "Start training for stock: 8131\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1532\n",
      "Start training for stock: 2875\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1533\n",
      "Start training for stock: 8766\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1534\n",
      "Start training for stock: 9749\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1535\n",
      "Start training for stock: 6436\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1536\n",
      "Start training for stock: 3433\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1537\n",
      "Start training for stock: 7931\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1538\n",
      "Start training for stock: 3771\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1539\n",
      "Start training for stock: 7846\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1540\n",
      "Start training for stock: 6908\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1541\n",
      "Start training for stock: 3923\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1542\n",
      "Start training for stock: 4041\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1543\n",
      "Start training for stock: 6268\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1544\n",
      "Start training for stock: 5714\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1545\n",
      "Start training for stock: 8202\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1546\n",
      "Start training for stock: 4080\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1547\n",
      "Start training for stock: 9058\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1548\n",
      "Start training for stock: 7236\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1549\n",
      "Start training for stock: 8304\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1550\n",
      "Start training for stock: 6580\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1551\n",
      "Start training for stock: 5999\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1552\n",
      "Start training for stock: 2307\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1553\n",
      "Start training for stock: 3148\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1554\n",
      "Start training for stock: 1882\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1555\n",
      "Start training for stock: 6533\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1556\n",
      "Start training for stock: 9505\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1557\n",
      "Start training for stock: 9739\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1558\n",
      "Start training for stock: 7972\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1559\n",
      "Start training for stock: 9009\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1560\n",
      "Start training for stock: 3673\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1561\n",
      "Start training for stock: 5273\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1562\n",
      "Start training for stock: 9273\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1563\n",
      "Start training for stock: 8096\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1564\n",
      "Start training for stock: 9066\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1565\n",
      "Start training for stock: 8015\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1566\n",
      "Start training for stock: 3635\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1567\n",
      "Start training for stock: 7202\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1568\n",
      "Start training for stock: 7522\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1569\n",
      "Start training for stock: 4901\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1570\n",
      "Start training for stock: 5401\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1571\n",
      "Start training for stock: 9412\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1572\n",
      "Start training for stock: 4996\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1573\n",
      "Start training for stock: 6932\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1574\n",
      "Start training for stock: 7752\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1575\n",
      "Start training for stock: 6240\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1576\n",
      "Start training for stock: 4215\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1577\n",
      "Start training for stock: 7186\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1578\n",
      "Start training for stock: 5988\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1579\n",
      "Start training for stock: 3179\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1580\n",
      "Start training for stock: 8346\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1581\n",
      "Start training for stock: 6301\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1582\n",
      "Start training for stock: 6702\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1583\n",
      "Start training for stock: 3738\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1584\n",
      "Start training for stock: 6904\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1585\n",
      "Start training for stock: 6674\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1586\n",
      "Start training for stock: 9508\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1587\n",
      "Start training for stock: 8038\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1588\n",
      "Start training for stock: 4481\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1589\n",
      "Start training for stock: 4183\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1590\n",
      "Start training for stock: 4471\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1591\n",
      "Start training for stock: 4246\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1592\n",
      "Start training for stock: 5541\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1593\n",
      "Start training for stock: 9600\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1594\n",
      "Start training for stock: 8074\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1595\n",
      "Start training for stock: 7292\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1596\n",
      "Start training for stock: 7173\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1597\n",
      "Start training for stock: 7189\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1598\n",
      "Start training for stock: 3774\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1599\n",
      "Start training for stock: 7740\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1600\n",
      "Start training for stock: 4934\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1601\n",
      "Start training for stock: 2882\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1602\n",
      "Start training for stock: 5949\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1603\n",
      "Start training for stock: 4680\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1604\n",
      "Start training for stock: 4626\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1605\n",
      "Start training for stock: 5108\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1606\n",
      "Start training for stock: 6030\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1607\n",
      "Start training for stock: 6626\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1608\n",
      "Start training for stock: 7269\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1609\n",
      "Start training for stock: 6326\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1610\n",
      "Start training for stock: 8227\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1611\n",
      "Start training for stock: 3681\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1612\n",
      "Start training for stock: 4208\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1613\n",
      "Start training for stock: 2226\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1614\n",
      "Start training for stock: 2296\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1615\n",
      "Start training for stock: 6504\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1616\n",
      "Start training for stock: 4732\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1617\n",
      "Start training for stock: 6532\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1618\n",
      "Start training for stock: 5302\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1619\n",
      "Start training for stock: 6035\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1620\n",
      "Start training for stock: 8515\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1621\n",
      "Start training for stock: 7245\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1622\n",
      "Start training for stock: 6859\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1623\n",
      "Start training for stock: 6850\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1624\n",
      "Start training for stock: 4401\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1625\n",
      "Start training for stock: 8078\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1626\n",
      "Start training for stock: 4308\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1627\n",
      "Start training for stock: 2309\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1628\n",
      "Start training for stock: 2004\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1629\n",
      "Start training for stock: 6331\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1630\n",
      "Start training for stock: 8167\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1631\n",
      "Start training for stock: 4345\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1632\n",
      "Start training for stock: 8473\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1633\n",
      "Start training for stock: 8086\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1634\n",
      "Start training for stock: 3107\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1635\n",
      "Start training for stock: 3836\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1636\n",
      "Start training for stock: 3914\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1637\n",
      "Start training for stock: 9468\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1638\n",
      "Start training for stock: 7683\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1639\n",
      "Start training for stock: 8725\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1640\n",
      "Start training for stock: 1967\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1641\n",
      "Start training for stock: 4970\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1642\n",
      "Start training for stock: 3612\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1643\n",
      "Start training for stock: 6498\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1644\n",
      "Start training for stock: 1813\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1645\n",
      "Start training for stock: 5304\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1646\n",
      "Start training for stock: 8935\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1647\n",
      "Start training for stock: 6089\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1648\n",
      "Start training for stock: 4613\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1649\n",
      "Start training for stock: 7721\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1650\n",
      "Start training for stock: 8113\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1651\n",
      "Start training for stock: 9823\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1652\n",
      "Start training for stock: 7412\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1653\n",
      "Start training for stock: 9661\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1654\n",
      "Start training for stock: 8341\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1655\n",
      "Start training for stock: 7283\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1656\n",
      "Start training for stock: 4781\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1657\n",
      "Start training for stock: 5471\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1658\n",
      "Start training for stock: 4095\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1659\n",
      "Start training for stock: 9639\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1660\n",
      "Start training for stock: 7467\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1661\n",
      "Start training for stock: 1914\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1662\n",
      "Start training for stock: 3951\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1663\n",
      "Start training for stock: 3937\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1664\n",
      "Start training for stock: 3154\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1665\n",
      "Start training for stock: 2602\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1666\n",
      "Start training for stock: 7167\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1667\n",
      "Start training for stock: 2222\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1668\n",
      "Start training for stock: 7201\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1669\n",
      "Start training for stock: 6366\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1670\n",
      "Start training for stock: 6616\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1671\n",
      "Start training for stock: 4956\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1672\n",
      "Start training for stock: 3934\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1673\n",
      "Start training for stock: 9075\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1674\n",
      "Start training for stock: 8079\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1675\n",
      "Start training for stock: 2359\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1676\n",
      "Start training for stock: 4958\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1677\n",
      "Start training for stock: 2326\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1678\n",
      "Start training for stock: 7438\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1679\n",
      "Start training for stock: 7545\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1680\n",
      "Start training for stock: 8869\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1681\n",
      "Start training for stock: 7512\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1682\n",
      "Start training for stock: 9405\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1683\n",
      "Start training for stock: 2175\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1684\n",
      "Start training for stock: 2427\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1685\n",
      "Start training for stock: 2204\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1686\n",
      "Start training for stock: 7818\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1687\n",
      "Start training for stock: 9304\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1688\n",
      "Start training for stock: 7036\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1689\n",
      "Start training for stock: 5632\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1690\n",
      "Start training for stock: 2462\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1691\n",
      "Start training for stock: 2918\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1692\n",
      "Start training for stock: 9887\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1693\n",
      "Start training for stock: 1802\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1694\n",
      "Start training for stock: 4800\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1695\n",
      "Start training for stock: 2678\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1696\n",
      "Start training for stock: 4463\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1697\n",
      "Start training for stock: 1793\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1698\n",
      "Start training for stock: 6506\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1699\n",
      "Start training for stock: 9743\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1700\n",
      "Start training for stock: 6407\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1701\n",
      "Start training for stock: 5334\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1702\n",
      "Start training for stock: 3156\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1703\n",
      "Start training for stock: 6455\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1704\n",
      "Start training for stock: 7734\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1705\n",
      "Start training for stock: 2471\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1706\n",
      "Start training for stock: 3591\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1707\n",
      "Start training for stock: 8772\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1708\n",
      "Start training for stock: 7613\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1709\n",
      "Start training for stock: 9889\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1710\n",
      "Start training for stock: 5410\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1711\n",
      "Start training for stock: 4674\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1712\n",
      "Start training for stock: 5902\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1713\n",
      "Start training for stock: 2932\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1714\n",
      "Start training for stock: 1928\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1715\n",
      "Start training for stock: 7611\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1716\n",
      "Start training for stock: 4967\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1717\n",
      "Start training for stock: 4062\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1718\n",
      "Start training for stock: 8179\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1719\n",
      "Start training for stock: 8088\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1720\n",
      "Start training for stock: 6027\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1721\n",
      "Start training for stock: 9409\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1722\n",
      "Start training for stock: 9274\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1723\n",
      "Start training for stock: 9305\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1724\n",
      "Start training for stock: 4998\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1725\n",
      "Start training for stock: 4503\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1726\n",
      "Start training for stock: 6925\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1727\n",
      "Start training for stock: 8084\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1728\n",
      "Start training for stock: 9142\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1729\n",
      "Start training for stock: 9729\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1730\n",
      "Start training for stock: 4369\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1731\n",
      "Start training for stock: 8550\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1732\n",
      "Start training for stock: 8367\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1733\n",
      "Start training for stock: 7732\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1734\n",
      "Start training for stock: 8708\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1735\n",
      "Start training for stock: 6701\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1736\n",
      "Start training for stock: 2533\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1737\n",
      "Start training for stock: 8309\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1738\n",
      "Start training for stock: 6323\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1739\n",
      "Start training for stock: 9303\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1740\n",
      "Start training for stock: 9441\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1741\n",
      "Start training for stock: 4666\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1742\n",
      "Start training for stock: 9869\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1743\n",
      "Start training for stock: 4582\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1744\n",
      "Start training for stock: 6279\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1745\n",
      "Start training for stock: 9687\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1746\n",
      "Start training for stock: 8844\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1747\n",
      "Start training for stock: 2685\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1748\n",
      "Start training for stock: 6245\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1749\n",
      "Start training for stock: 6134\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1750\n",
      "Start training for stock: 1899\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1751\n",
      "Start training for stock: 1720\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1752\n",
      "Start training for stock: 7570\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1753\n",
      "Start training for stock: 2587\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1754\n",
      "Start training for stock: 4974\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1755\n",
      "Start training for stock: 4686\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1756\n",
      "Start training for stock: 6644\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1757\n",
      "Start training for stock: 7447\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1758\n",
      "Start training for stock: 2109\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1759\n",
      "Start training for stock: 2317\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1760\n",
      "Start training for stock: 9678\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1761\n",
      "Start training for stock: 2498\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1762\n",
      "Start training for stock: 7779\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1763\n",
      "Start training for stock: 8114\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1764\n",
      "Start training for stock: 2815\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1765\n",
      "Start training for stock: 1811\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1766\n",
      "Start training for stock: 4228\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1767\n",
      "Start training for stock: 9046\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1768\n",
      "Start training for stock: 8714\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1769\n",
      "Start training for stock: 4004\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1770\n",
      "Start training for stock: 2910\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1771\n",
      "Start training for stock: 3772\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1772\n",
      "Start training for stock: 7296\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1773\n",
      "Start training for stock: 2150\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1774\n",
      "Start training for stock: 9989\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1775\n",
      "Start training for stock: 8014\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1776\n",
      "Start training for stock: 6957\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1777\n",
      "Start training for stock: 5943\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1778\n",
      "Start training for stock: 4530\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1779\n",
      "Start training for stock: 8244\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1780\n",
      "Start training for stock: 7817\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1781\n",
      "Start training for stock: 6620\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1782\n",
      "Start training for stock: 5480\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1783\n",
      "Start training for stock: 6055\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1784\n",
      "Start training for stock: 7905\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1785\n",
      "Start training for stock: 1721\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1786\n",
      "Start training for stock: 6590\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1787\n",
      "Start training for stock: 2264\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1788\n",
      "Start training for stock: 5932\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1789\n",
      "Start training for stock: 6742\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1790\n",
      "Start training for stock: 8060\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1791\n",
      "Start training for stock: 4574\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1792\n",
      "Start training for stock: 5195\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1793\n",
      "Start training for stock: 8337\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1794\n",
      "Start training for stock: 5486\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1795\n",
      "Start training for stock: 7874\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1796\n",
      "Start training for stock: 4272\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1797\n",
      "Start training for stock: 6277\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1798\n",
      "Start training for stock: 2208\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1799\n",
      "Start training for stock: 4726\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1800\n",
      "Start training for stock: 7071\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1801\n",
      "Start training for stock: 6237\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1802\n",
      "Start training for stock: 3099\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1803\n",
      "Start training for stock: 2378\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1804\n",
      "Start training for stock: 7004\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1805\n",
      "Start training for stock: 3675\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1806\n",
      "Start training for stock: 7715\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1807\n",
      "Start training for stock: 4310\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1808\n",
      "Start training for stock: 6339\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1809\n",
      "Start training for stock: 7309\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1810\n",
      "Start training for stock: 2931\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1811\n",
      "Start training for stock: 7105\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1812\n",
      "Start training for stock: 6954\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1813\n",
      "Start training for stock: 1968\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1814\n",
      "Start training for stock: 8035\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1815\n",
      "Start training for stock: 9308\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1816\n",
      "Start training for stock: 4436\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1817\n",
      "Start training for stock: 7182\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1818\n",
      "Start training for stock: 2908\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1819\n",
      "Start training for stock: 8218\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1820\n",
      "Start training for stock: 3861\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1821\n",
      "Start training for stock: 3660\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1822\n",
      "Start training for stock: 6832\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1823\n",
      "Start training for stock: 7518\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1824\n",
      "Start training for stock: 9502\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1825\n",
      "Start training for stock: 6806\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1826\n",
      "Start training for stock: 2819\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1827\n",
      "Start training for stock: 4966\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1828\n",
      "Start training for stock: 6641\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1829\n",
      "Start training for stock: 6823\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1830\n",
      "Start training for stock: 1787\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1831\n",
      "Start training for stock: 6485\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1832\n",
      "Start training for stock: 3036\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1833\n",
      "Start training for stock: 4812\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1834\n",
      "Start training for stock: 1417\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1835\n",
      "Start training for stock: 5393\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1836\n",
      "Start training for stock: 6406\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1837\n",
      "Start training for stock: 1951\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1838\n",
      "Start training for stock: 4832\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1839\n",
      "Start training for stock: 6378\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1840\n",
      "Start training for stock: 9945\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1841\n",
      "Start training for stock: 6444\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1842\n",
      "Start training for stock: 6387\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1843\n",
      "Start training for stock: 4848\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1844\n",
      "Start training for stock: 7716\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1845\n",
      "Start training for stock: 4112\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1846\n",
      "Start training for stock: 2502\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1847\n",
      "Start training for stock: 6736\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1848\n",
      "Start training for stock: 4699\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1849\n",
      "Start training for stock: 4238\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1850\n",
      "Start training for stock: 2154\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1851\n",
      "Start training for stock: 4684\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1852\n",
      "Start training for stock: 5947\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1853\n",
      "Start training for stock: 8165\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1854\n",
      "Start training for stock: 1976\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1855\n",
      "Start training for stock: 3319\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1856\n",
      "Start training for stock: 2181\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1857\n",
      "Start training for stock: 8739\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1858\n",
      "Start training for stock: 1719\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1859\n",
      "Start training for stock: 7581\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1860\n",
      "Start training for stock: 9551\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1861\n",
      "Start training for stock: 4094\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1862\n",
      "Start training for stock: 3276\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1863\n",
      "Start training for stock: 8022\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1864\n",
      "Start training for stock: 3360\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1865\n",
      "Start training for stock: 2477\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1866\n",
      "Start training for stock: 5857\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1867\n",
      "Start training for stock: 3254\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1868\n",
      "Start training for stock: 6103\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1869\n",
      "Start training for stock: 8125\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1870\n",
      "Start training for stock: 8289\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1871\n",
      "Start training for stock: 3382\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1872\n",
      "Start training for stock: 4985\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1873\n",
      "Start training for stock: 7205\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1874\n",
      "Start training for stock: 8698\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1875\n",
      "Start training for stock: 2763\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1876\n",
      "Start training for stock: 8281\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1877\n",
      "Start training for stock: 6866\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1878\n",
      "Start training for stock: 6535\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1879\n",
      "Start training for stock: 7821\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1880\n",
      "Start training for stock: 8591\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1881\n",
      "Start training for stock: 2327\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1882\n",
      "Start training for stock: 8185\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1883\n",
      "Start training for stock: 7242\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1884\n",
      "Start training for stock: 4107\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1885\n",
      "Start training for stock: 9511\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1886\n",
      "Start training for stock: 3289\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1887\n",
      "Start training for stock: 5801\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1888\n",
      "Start training for stock: 4634\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1889\n",
      "Start training for stock: 4917\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1890\n",
      "Start training for stock: 6047\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1891\n",
      "Start training for stock: 6955\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1892\n",
      "Start training for stock: 8511\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1893\n",
      "Start training for stock: 6718\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1894\n",
      "Start training for stock: 9503\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1895\n",
      "Start training for stock: 6817\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1896\n",
      "Start training for stock: 5352\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1897\n",
      "Start training for stock: 6101\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1898\n",
      "Start training for stock: 6651\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1899\n",
      "Start training for stock: 9790\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1900\n",
      "Start training for stock: 6412\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1901\n",
      "Start training for stock: 6080\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1902\n",
      "Start training for stock: 4820\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1903\n",
      "Start training for stock: 3101\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1904\n",
      "Start training for stock: 2489\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1905\n",
      "Start training for stock: 1949\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1906\n",
      "Start training for stock: 4431\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1907\n",
      "Start training for stock: 5757\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1908\n",
      "Start training for stock: 8151\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1909\n",
      "Start training for stock: 4324\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1910\n",
      "Start training for stock: 3421\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1911\n",
      "Start training for stock: 1963\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1912\n",
      "Start training for stock: 6490\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1913\n",
      "Start training for stock: 3593\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1914\n",
      "Start training for stock: 4837\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1915\n",
      "Start training for stock: 6625\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1916\n",
      "Start training for stock: 9603\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1917\n",
      "Start training for stock: 2922\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1918\n",
      "Start training for stock: 1878\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1919\n",
      "Start training for stock: 7282\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1920\n",
      "Start training for stock: 2767\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1921\n",
      "Start training for stock: 5482\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1922\n",
      "Start training for stock: 9787\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1923\n",
      "Start training for stock: 7809\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1924\n",
      "Start training for stock: 6395\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1925\n",
      "Start training for stock: 8316\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1926\n",
      "Start training for stock: 3387\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1927\n",
      "Start training for stock: 3141\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1928\n",
      "Start training for stock: 2814\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1929\n",
      "Start training for stock: 4751\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1930\n",
      "Start training for stock: 7966\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1931\n",
      "Start training for stock: 8111\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1932\n",
      "Start training for stock: 9717\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1933\n",
      "Start training for stock: 6425\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1934\n",
      "Start training for stock: 9742\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1935\n",
      "Start training for stock: 2170\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1936\n",
      "Start training for stock: 4955\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1937\n",
      "Start training for stock: 1762\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1938\n",
      "Start training for stock: 6824\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1939\n",
      "Start training for stock: 5451\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1940\n",
      "Start training for stock: 7867\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1941\n",
      "Start training for stock: 3939\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1942\n",
      "Start training for stock: 4536\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1943\n",
      "Start training for stock: 2267\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1944\n",
      "Start training for stock: 2729\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1945\n",
      "Start training for stock: 4621\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1946\n",
      "Start training for stock: 4054\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1947\n",
      "Start training for stock: 4056\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1948\n",
      "Start training for stock: 4446\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1949\n",
      "Start training for stock: 4577\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1950\n",
      "Start training for stock: 7092\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1951\n",
      "Start training for stock: 7199\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1952\n",
      "Start training for stock: 3553\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1953\n",
      "Start training for stock: 5802\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1954\n",
      "Start training for stock: 6728\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1955\n",
      "Start training for stock: 4493\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1956\n",
      "Start training for stock: 4928\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1957\n",
      "Start training for stock: 9873\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1958\n",
      "Start training for stock: 6810\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1959\n",
      "Start training for stock: 1979\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1960\n",
      "Start training for stock: 5232\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1961\n",
      "Start training for stock: 3668\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1962\n",
      "Start training for stock: 7749\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1963\n",
      "Start training for stock: 9504\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1964\n",
      "Start training for stock: 8803\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1965\n",
      "Start training for stock: 4746\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1966\n",
      "Start training for stock: 6118\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1967\n",
      "Start training for stock: 2121\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1968\n",
      "Start training for stock: 9755\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1969\n",
      "Start training for stock: 4828\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1970\n",
      "Start training for stock: 1926\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1971\n",
      "Start training for stock: 5202\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1972\n",
      "Start training for stock: 4044\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1973\n",
      "Start training for stock: 8595\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1974\n",
      "Start training for stock: 5218\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1975\n",
      "Start training for stock: 8267\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1976\n",
      "Start training for stock: 2349\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1977\n",
      "Start training for stock: 1952\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1978\n",
      "Start training for stock: 4082\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1979\n",
      "Start training for stock: 7962\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1980\n",
      "Start training for stock: 4593\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1981\n",
      "Start training for stock: 3075\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1982\n",
      "Start training for stock: 7618\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1983\n",
      "Start training for stock: 4286\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1984\n",
      "Start training for stock: 7925\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1985\n",
      "Start training for stock: 6470\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1986\n",
      "Start training for stock: 4275\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1987\n",
      "Start training for stock: 9301\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1988\n",
      "Start training for stock: 9024\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1989\n",
      "Start training for stock: 2831\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1990\n",
      "Start training for stock: 8876\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1991\n",
      "Start training for stock: 6310\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1992\n",
      "Start training for stock: 7476\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1993\n",
      "Start training for stock: 8801\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1994\n",
      "Start training for stock: 4772\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1995\n",
      "Start training for stock: 5122\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1996\n",
      "Start training for stock: 6855\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1997\n",
      "Start training for stock: 8355\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1998\n",
      "Start training for stock: 4100\n",
      "####################\n",
      "\n",
      "Stock-iteratation: 1999\n",
      "Start training for stock: 4550\n",
      "####################\n",
      "\n",
      "CPU times: user 9h 39min 10s, sys: 7min 2s, total: 9h 46min 13s\n",
      "Wall time: 4h 54min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stocks = train_df['SecuritiesCode'].unique()\n",
    "count = 0\n",
    "\n",
    "scaler_dict = {}\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, \n",
    "    optimizer_name='rmsprop', \n",
    "    lr=1.3333e-5, \n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "train_loss_list = []\n",
    "train_mae_list = []\n",
    "valid_loss_list = []\n",
    "valid_mae_list = []\n",
    "\n",
    "\"\"\"\n",
    "SHUFFLE STOCKS WHEN TRAINING\n",
    "\"\"\"\n",
    "np.random.seed(0)\n",
    "\"\"\"\n",
    "DO RANDOM CHOICE OF STOCKS.\n",
    "Run only once\n",
    "\"\"\"\n",
    "np.random.shuffle(stocks) # SHUFFLE STOCKS IN PLACE\n",
    "\n",
    "TRAIN_ON_STOCKS = stocks[: 1000]\n",
    "print(stocks)\n",
    "for no_stock, stock in enumerate(stocks):\n",
    "    try:\n",
    "        train_loader, val_dataloader = None, None\n",
    "        print(f'Stock-iteratation: {no_stock}')\n",
    "        print(f'Start training for stock: {stock}')\n",
    "        train_dataloader, val_dataloader, scaler = dataloader_by_stock(\n",
    "            train_df, \n",
    "            stock, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            continous_cols=CONT_COLS,\n",
    "            return_scaler=True,\n",
    "            transform=MaxAbsScaler         \n",
    "        )\n",
    "        scaler_dict[stock] = scaler\n",
    "\n",
    "        if stock in TRAIN_ON_STOCKS:\n",
    "            train_loss, train_mae, val_loss, val_mae = trainer.fit_epochs(\n",
    "                train_dataloader, \n",
    "                val_dataloader, \n",
    "                use_cyclic_lr=True, \n",
    "                x_cat=True, \n",
    "                epochs=EPOCHS\n",
    "            )\n",
    "            train_loss_list.extend(train_loss)\n",
    "            train_mae_list.extend(train_mae)\n",
    "            valid_loss_list.extend(val_loss)\n",
    "            valid_mae_list.extend(val_mae)\n",
    "        \n",
    "        print('#' * 20)\n",
    "        print()\n",
    "#         count += 1\n",
    "    except Exception as e:\n",
    "        print(f'Training loop: {e}')\n",
    "    \n",
    "# with open('scaler_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(scaler_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5f6a8",
   "metadata": {
    "papermill": {
     "duration": 0.449148,
     "end_time": "2022-07-04T15:53:35.172450",
     "exception": false,
     "start_time": "2022-07-04T15:53:34.723302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004589c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T15:53:36.071968Z",
     "iopub.status.busy": "2022-07-04T15:53:36.071298Z",
     "iopub.status.idle": "2022-07-04T15:53:36.245312Z",
     "shell.execute_reply": "2022-07-04T15:53:36.244754Z",
     "shell.execute_reply.started": "2022-07-04T10:42:05.977227Z"
    },
    "papermill": {
     "duration": 0.625346,
     "end_time": "2022-07-04T15:53:36.245460",
     "exception": false,
     "start_time": "2022-07-04T15:53:35.620114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/trained_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7487d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T15:53:37.150388Z",
     "iopub.status.busy": "2022-07-04T15:53:37.149337Z",
     "iopub.status.idle": "2022-07-04T15:53:37.725048Z",
     "shell.execute_reply": "2022-07-04T15:53:37.724505Z",
     "shell.execute_reply.started": "2022-07-04T10:42:06.291089Z"
    },
    "papermill": {
     "duration": 1.034317,
     "end_time": "2022-07-04T15:53:37.725188",
     "exception": false,
     "start_time": "2022-07-04T15:53:36.690871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.title('Train loss');\n",
    "plt.show()\n",
    "\n",
    "plt.plot(valid_loss_list)\n",
    "plt.title('Valid loss')\n",
    "plt.show()\n",
    "\n",
    "plot_loss(train_loss_list, valid_loss_list, 'Train-loss', 'Valid-loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2380ac15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T15:53:38.647695Z",
     "iopub.status.busy": "2022-07-04T15:53:38.646900Z",
     "iopub.status.idle": "2022-07-04T15:53:39.224856Z",
     "shell.execute_reply": "2022-07-04T15:53:39.225547Z",
     "shell.execute_reply.started": "2022-07-04T10:42:06.860684Z"
    },
    "papermill": {
     "duration": 1.047063,
     "end_time": "2022-07-04T15:53:39.225718",
     "exception": false,
     "start_time": "2022-07-04T15:53:38.178655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_mae_list)\n",
    "plt.title('Train MAE');\n",
    "plt.show()\n",
    "\n",
    "plt.plot(valid_mae_list)\n",
    "plt.title('Valid MAE')\n",
    "plt.show()\n",
    "\n",
    "plot_loss(train_mae_list, valid_mae_list, 'Train-MAE', 'Valid-MAE')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9201cac",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.454853,
     "end_time": "2022-07-04T15:53:40.132958",
     "exception": false,
     "start_time": "2022-07-04T15:53:39.678105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbbc1e3",
   "metadata": {
    "papermill": {
     "duration": 0.453595,
     "end_time": "2022-07-04T15:53:41.038246",
     "exception": false,
     "start_time": "2022-07-04T15:53:40.584651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make predictions and Submit Results \n",
    "* TODO: train_dataloader should save all scalers during training even though we not train on all stocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2b6b3",
   "metadata": {
    "papermill": {
     "duration": 0.458263,
     "end_time": "2022-07-04T15:53:41.954840",
     "exception": false,
     "start_time": "2022-07-04T15:53:41.496577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fbaf88",
   "metadata": {
    "papermill": {
     "duration": 0.461976,
     "end_time": "2022-07-04T15:53:42.874488",
     "exception": false,
     "start_time": "2022-07-04T15:53:42.412512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rank stocks from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d564dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T15:53:43.796438Z",
     "iopub.status.busy": "2022-07-04T15:53:43.794962Z",
     "iopub.status.idle": "2022-07-04T15:53:43.798984Z",
     "shell.execute_reply": "2022-07-04T15:53:43.799561Z",
     "shell.execute_reply.started": "2022-07-04T10:42:07.438954Z"
    },
    "papermill": {
     "duration": 0.468445,
     "end_time": "2022-07-04T15:53:43.799738",
     "exception": false,
     "start_time": "2022-07-04T15:53:43.331293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import jpx_tokyo_market_prediction\n",
    "# env = jpx_tokyo_market_prediction.make_env()\n",
    "# iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48010f07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T15:53:44.745328Z",
     "iopub.status.busy": "2022-07-04T15:53:44.744285Z",
     "iopub.status.idle": "2022-07-04T15:57:23.988124Z",
     "shell.execute_reply": "2022-07-04T15:57:23.988701Z",
     "shell.execute_reply.started": "2022-07-04T10:42:07.449654Z"
    },
    "papermill": {
     "duration": 219.720902,
     "end_time": "2022-07-04T15:57:23.988919",
     "exception": false,
     "start_time": "2022-07-04T15:53:44.268017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "train_df.head(10):\n",
      "            Section/Products  33SectorName  17SectorName  Universe0  \\\n",
      "Date                                                                  \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-06                 2             6             8          0   \n",
      "2021-12-06                 2             3             3          0   \n",
      "2021-12-06                 0             3             3          0   \n",
      "\n",
      "            MarketCapitalization  SecuritiesCode          RowId    Open  \\\n",
      "Date                                                                      \n",
      "2021-12-06          3.365911e+10            1301  20211206_1301  2982.0   \n",
      "2021-12-06          1.696496e+11            1332  20211206_1332   592.0   \n",
      "2021-12-06          1.266399e+11            1333  20211206_1333  2368.0   \n",
      "2021-12-06          4.773320e+10            1375  20211206_1375  1230.0   \n",
      "2021-12-06          1.770603e+10            1376  20211206_1376  1339.0   \n",
      "2021-12-06          1.557443e+11            1377  20211206_1377  3185.0   \n",
      "2021-12-06          6.364905e+10            1379  20211206_1379  1890.0   \n",
      "2021-12-06          1.820070e+10            1381  20211206_1381  3200.0   \n",
      "2021-12-06          2.637375e+11            1407  20211206_1407  6100.0   \n",
      "2021-12-06          2.976998e+10            1413  20211206_1413  2185.0   \n",
      "\n",
      "              High     Low   Close   Volume  AdjustmentFactor  \\\n",
      "Date                                                            \n",
      "2021-12-06  2982.0  2965.0  2971.0     8900               1.0   \n",
      "2021-12-06   599.0   588.0   589.0  1360800               1.0   \n",
      "2021-12-06  2388.0  2360.0  2377.0   125900               1.0   \n",
      "2021-12-06  1239.0  1224.0  1224.0    81100               1.0   \n",
      "2021-12-06  1372.0  1339.0  1351.0     6200               1.0   \n",
      "2021-12-06  3215.0  3180.0  3200.0    77000               1.0   \n",
      "2021-12-06  1898.0  1885.0  1889.0    48500               1.0   \n",
      "2021-12-06  3200.0  3150.0  3150.0     1600               1.0   \n",
      "2021-12-06  6290.0  6010.0  6220.0   246700               1.0   \n",
      "2021-12-06  2211.0  2181.0  2190.0     9200               1.0   \n",
      "\n",
      "            ExpectedDividend  SupervisionFlag  \n",
      "Date                                           \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "Iteretation: 0\n",
      "Iteretation: 1\n",
      "Iteretation: 2\n",
      "Iteretation: 3\n",
      "Iteretation: 4\n",
      "Iteretation: 5\n",
      "Iteretation: 6\n",
      "Iteretation: 7\n",
      "Iteretation: 8\n",
      "Iteretation: 9\n",
      "Iteretation: 10\n",
      "Iteretation: 11\n",
      "Iteretation: 12\n",
      "Iteretation: 13\n",
      "Iteretation: 14\n",
      "Iteretation: 15\n",
      "Iteretation: 16\n",
      "Iteretation: 17\n",
      "Iteretation: 18\n",
      "Iteretation: 19\n",
      "Iteretation: 20\n",
      "Iteretation: 21\n",
      "Iteretation: 22\n",
      "Iteretation: 23\n",
      "Iteretation: 24\n",
      "Iteretation: 25\n",
      "Iteretation: 26\n",
      "Iteretation: 27\n",
      "Iteretation: 28\n",
      "Iteretation: 29\n",
      "Iteretation: 30\n",
      "Iteretation: 31\n",
      "Iteretation: 32\n",
      "Iteretation: 33\n",
      "Iteretation: 34\n",
      "Iteretation: 35\n",
      "Iteretation: 36\n",
      "Iteretation: 37\n",
      "Iteretation: 38\n",
      "Iteretation: 39\n",
      "Iteretation: 40\n",
      "Iteretation: 41\n",
      "Iteretation: 42\n",
      "Iteretation: 43\n",
      "Iteretation: 44\n",
      "Iteretation: 45\n",
      "Iteretation: 46\n",
      "Iteretation: 47\n",
      "Iteretation: 48\n",
      "Iteretation: 49\n",
      "Iteretation: 50\n",
      "Iteretation: 51\n",
      "Iteretation: 52\n",
      "Iteretation: 53\n",
      "Iteretation: 54\n",
      "Iteretation: 55\n",
      "Iteretation: 56\n",
      "Iteretation: 57\n",
      "Iteretation: 58\n",
      "Iteretation: 59\n",
      "Iteretation: 60\n",
      "Iteretation: 61\n",
      "Iteretation: 62\n",
      "Iteretation: 63\n",
      "Iteretation: 64\n",
      "Iteretation: 65\n",
      "Iteretation: 66\n",
      "Iteretation: 67\n",
      "Iteretation: 68\n",
      "Iteretation: 69\n",
      "Iteretation: 70\n",
      "Iteretation: 71\n",
      "Iteretation: 72\n",
      "Iteretation: 73\n",
      "Iteretation: 74\n",
      "Iteretation: 75\n",
      "Iteretation: 76\n",
      "Iteretation: 77\n",
      "Iteretation: 78\n",
      "Iteretation: 79\n",
      "Iteretation: 80\n",
      "Iteretation: 81\n",
      "Iteretation: 82\n",
      "Iteretation: 83\n",
      "Iteretation: 84\n",
      "Iteretation: 85\n",
      "Iteretation: 86\n",
      "Iteretation: 87\n",
      "Iteretation: 88\n",
      "Iteretation: 89\n",
      "Iteretation: 90\n",
      "Iteretation: 91\n",
      "Iteretation: 92\n",
      "Iteretation: 93\n",
      "Iteretation: 94\n",
      "Iteretation: 95\n",
      "Iteretation: 96\n",
      "Iteretation: 97\n",
      "Iteretation: 98\n",
      "Iteretation: 99\n",
      "Iteretation: 100\n",
      "Iteretation: 101\n",
      "Iteretation: 102\n",
      "Iteretation: 103\n",
      "Iteretation: 104\n",
      "Iteretation: 105\n",
      "Iteretation: 106\n",
      "Iteretation: 107\n",
      "Iteretation: 108\n",
      "Iteretation: 109\n",
      "Iteretation: 110\n",
      "Iteretation: 111\n",
      "Iteretation: 112\n",
      "Iteretation: 113\n",
      "Iteretation: 114\n",
      "Iteretation: 115\n",
      "Iteretation: 116\n",
      "Iteretation: 117\n",
      "Iteretation: 118\n",
      "Iteretation: 119\n",
      "Iteretation: 120\n",
      "Iteretation: 121\n",
      "Iteretation: 122\n",
      "Iteretation: 123\n",
      "Iteretation: 124\n",
      "Iteretation: 125\n",
      "Iteretation: 126\n",
      "Iteretation: 127\n",
      "Iteretation: 128\n",
      "Iteretation: 129\n",
      "Iteretation: 130\n",
      "Iteretation: 131\n",
      "Iteretation: 132\n",
      "Iteretation: 133\n",
      "Iteretation: 134\n",
      "Iteretation: 135\n",
      "Iteretation: 136\n",
      "Iteretation: 137\n",
      "Iteretation: 138\n",
      "Iteretation: 139\n",
      "Iteretation: 140\n",
      "Iteretation: 141\n",
      "Iteretation: 142\n",
      "Iteretation: 143\n",
      "Iteretation: 144\n",
      "Iteretation: 145\n",
      "Iteretation: 146\n",
      "Iteretation: 147\n",
      "Iteretation: 148\n",
      "Iteretation: 149\n",
      "Iteretation: 150\n",
      "Iteretation: 151\n",
      "Iteretation: 152\n",
      "Iteretation: 153\n",
      "Iteretation: 154\n",
      "Iteretation: 155\n",
      "Iteretation: 156\n",
      "Iteretation: 157\n",
      "Iteretation: 158\n",
      "Iteretation: 159\n",
      "Iteretation: 160\n",
      "Iteretation: 161\n",
      "Iteretation: 162\n",
      "Iteretation: 163\n",
      "Iteretation: 164\n",
      "Iteretation: 165\n",
      "Iteretation: 166\n",
      "Iteretation: 167\n",
      "Iteretation: 168\n",
      "Iteretation: 169\n",
      "Iteretation: 170\n",
      "Iteretation: 171\n",
      "Iteretation: 172\n",
      "Iteretation: 173\n",
      "Iteretation: 174\n",
      "Iteretation: 175\n",
      "Iteretation: 176\n",
      "Iteretation: 177\n",
      "Iteretation: 178\n",
      "Iteretation: 179\n",
      "Iteretation: 180\n",
      "Iteretation: 181\n",
      "Iteretation: 182\n",
      "Iteretation: 183\n",
      "Iteretation: 184\n",
      "Iteretation: 185\n",
      "Iteretation: 186\n",
      "Iteretation: 187\n",
      "Iteretation: 188\n",
      "Iteretation: 189\n",
      "Iteretation: 190\n",
      "Iteretation: 191\n",
      "Iteretation: 192\n",
      "Iteretation: 193\n",
      "Iteretation: 194\n",
      "Iteretation: 195\n",
      "Iteretation: 196\n",
      "Iteretation: 197\n",
      "Iteretation: 198\n",
      "Iteretation: 199\n",
      "Iteretation: 200\n",
      "Iteretation: 201\n",
      "Iteretation: 202\n",
      "Iteretation: 203\n",
      "Iteretation: 204\n",
      "Iteretation: 205\n",
      "Iteretation: 206\n",
      "Iteretation: 207\n",
      "Iteretation: 208\n",
      "Iteretation: 209\n",
      "Iteretation: 210\n",
      "Iteretation: 211\n",
      "Iteretation: 212\n",
      "Iteretation: 213\n",
      "Iteretation: 214\n",
      "Iteretation: 215\n",
      "Iteretation: 216\n",
      "Iteretation: 217\n",
      "Iteretation: 218\n",
      "Iteretation: 219\n",
      "Iteretation: 220\n",
      "Iteretation: 221\n",
      "Iteretation: 222\n",
      "Iteretation: 223\n",
      "Iteretation: 224\n",
      "Iteretation: 225\n",
      "Iteretation: 226\n",
      "Iteretation: 227\n",
      "Iteretation: 228\n",
      "Iteretation: 229\n",
      "Iteretation: 230\n",
      "Iteretation: 231\n",
      "Iteretation: 232\n",
      "Iteretation: 233\n",
      "Iteretation: 234\n",
      "Iteretation: 235\n",
      "Iteretation: 236\n",
      "Iteretation: 237\n",
      "Iteretation: 238\n",
      "Iteretation: 239\n",
      "Iteretation: 240\n",
      "Iteretation: 241\n",
      "Iteretation: 242\n",
      "Iteretation: 243\n",
      "Iteretation: 244\n",
      "Iteretation: 245\n",
      "Iteretation: 246\n",
      "Iteretation: 247\n",
      "Iteretation: 248\n",
      "Iteretation: 249\n",
      "Iteretation: 250\n",
      "Iteretation: 251\n",
      "Iteretation: 252\n",
      "Iteretation: 253\n",
      "Iteretation: 254\n",
      "Iteretation: 255\n",
      "Iteretation: 256\n",
      "Iteretation: 257\n",
      "Iteretation: 258\n",
      "Iteretation: 259\n",
      "Iteretation: 260\n",
      "Iteretation: 261\n",
      "Iteretation: 262\n",
      "Iteretation: 263\n",
      "Iteretation: 264\n",
      "Iteretation: 265\n",
      "Iteretation: 266\n",
      "Iteretation: 267\n",
      "Iteretation: 268\n",
      "Iteretation: 269\n",
      "Iteretation: 270\n",
      "Iteretation: 271\n",
      "Iteretation: 272\n",
      "Iteretation: 273\n",
      "Iteretation: 274\n",
      "Iteretation: 275\n",
      "Iteretation: 276\n",
      "Iteretation: 277\n",
      "Iteretation: 278\n",
      "Iteretation: 279\n",
      "Iteretation: 280\n",
      "Iteretation: 281\n",
      "Iteretation: 282\n",
      "Iteretation: 283\n",
      "Iteretation: 284\n",
      "Iteretation: 285\n",
      "Iteretation: 286\n",
      "Iteretation: 287\n",
      "Iteretation: 288\n",
      "Iteretation: 289\n",
      "Iteretation: 290\n",
      "Iteretation: 291\n",
      "Iteretation: 292\n",
      "Iteretation: 293\n",
      "Iteretation: 294\n",
      "Iteretation: 295\n",
      "Iteretation: 296\n",
      "Iteretation: 297\n",
      "Iteretation: 298\n",
      "Iteretation: 299\n",
      "Iteretation: 300\n",
      "Iteretation: 301\n",
      "Iteretation: 302\n",
      "Iteretation: 303\n",
      "Iteretation: 304\n",
      "Iteretation: 305\n",
      "Iteretation: 306\n",
      "Iteretation: 307\n",
      "Iteretation: 308\n",
      "Iteretation: 309\n",
      "Iteretation: 310\n",
      "Iteretation: 311\n",
      "Iteretation: 312\n",
      "Iteretation: 313\n",
      "Iteretation: 314\n",
      "Iteretation: 315\n",
      "Iteretation: 316\n",
      "Iteretation: 317\n",
      "Iteretation: 318\n",
      "Iteretation: 319\n",
      "Iteretation: 320\n",
      "Iteretation: 321\n",
      "Iteretation: 322\n",
      "Iteretation: 323\n",
      "Iteretation: 324\n",
      "Iteretation: 325\n",
      "Iteretation: 326\n",
      "Iteretation: 327\n",
      "Iteretation: 328\n",
      "Iteretation: 329\n",
      "Iteretation: 330\n",
      "Iteretation: 331\n",
      "Iteretation: 332\n",
      "Iteretation: 333\n",
      "Iteretation: 334\n",
      "Iteretation: 335\n",
      "Iteretation: 336\n",
      "Iteretation: 337\n",
      "Iteretation: 338\n",
      "Iteretation: 339\n",
      "Iteretation: 340\n",
      "Iteretation: 341\n",
      "Iteretation: 342\n",
      "Iteretation: 343\n",
      "Iteretation: 344\n",
      "Iteretation: 345\n",
      "Iteretation: 346\n",
      "Iteretation: 347\n",
      "Iteretation: 348\n",
      "Iteretation: 349\n",
      "Iteretation: 350\n",
      "Iteretation: 351\n",
      "Iteretation: 352\n",
      "Iteretation: 353\n",
      "Iteretation: 354\n",
      "Iteretation: 355\n",
      "Iteretation: 356\n",
      "Iteretation: 357\n",
      "Iteretation: 358\n",
      "Iteretation: 359\n",
      "Iteretation: 360\n",
      "Iteretation: 361\n",
      "Iteretation: 362\n",
      "Iteretation: 363\n",
      "Iteretation: 364\n",
      "Iteretation: 365\n",
      "Iteretation: 366\n",
      "Iteretation: 367\n",
      "Iteretation: 368\n",
      "Iteretation: 369\n",
      "Iteretation: 370\n",
      "Iteretation: 371\n",
      "Iteretation: 372\n",
      "Iteretation: 373\n",
      "Iteretation: 374\n",
      "Iteretation: 375\n",
      "Iteretation: 376\n",
      "Iteretation: 377\n",
      "Iteretation: 378\n",
      "Iteretation: 379\n",
      "Iteretation: 380\n",
      "Iteretation: 381\n",
      "Iteretation: 382\n",
      "Iteretation: 383\n",
      "Iteretation: 384\n",
      "Iteretation: 385\n",
      "Iteretation: 386\n",
      "Iteretation: 387\n",
      "Iteretation: 388\n",
      "Iteretation: 389\n",
      "Iteretation: 390\n",
      "Iteretation: 391\n",
      "Iteretation: 392\n",
      "Iteretation: 393\n",
      "Iteretation: 394\n",
      "Iteretation: 395\n",
      "Iteretation: 396\n",
      "Iteretation: 397\n",
      "Iteretation: 398\n",
      "Iteretation: 399\n",
      "Iteretation: 400\n",
      "Iteretation: 401\n",
      "Iteretation: 402\n",
      "Iteretation: 403\n",
      "Iteretation: 404\n",
      "Iteretation: 405\n",
      "Iteretation: 406\n",
      "Iteretation: 407\n",
      "Iteretation: 408\n",
      "Iteretation: 409\n",
      "Iteretation: 410\n",
      "Iteretation: 411\n",
      "Iteretation: 412\n",
      "Iteretation: 413\n",
      "Iteretation: 414\n",
      "Iteretation: 415\n",
      "Iteretation: 416\n",
      "Iteretation: 417\n",
      "Iteretation: 418\n",
      "Iteretation: 419\n",
      "Iteretation: 420\n",
      "Iteretation: 421\n",
      "Iteretation: 422\n",
      "Iteretation: 423\n",
      "Iteretation: 424\n",
      "Iteretation: 425\n",
      "Iteretation: 426\n",
      "Iteretation: 427\n",
      "Iteretation: 428\n",
      "Iteretation: 429\n",
      "Iteretation: 430\n",
      "Iteretation: 431\n",
      "Iteretation: 432\n",
      "Iteretation: 433\n",
      "Iteretation: 434\n",
      "Iteretation: 435\n",
      "Iteretation: 436\n",
      "Iteretation: 437\n",
      "Iteretation: 438\n",
      "Iteretation: 439\n",
      "Iteretation: 440\n",
      "Iteretation: 441\n",
      "Iteretation: 442\n",
      "Iteretation: 443\n",
      "Iteretation: 444\n",
      "Iteretation: 445\n",
      "Iteretation: 446\n",
      "Iteretation: 447\n",
      "Iteretation: 448\n",
      "Iteretation: 449\n",
      "Iteretation: 450\n",
      "Iteretation: 451\n",
      "Iteretation: 452\n",
      "Iteretation: 453\n",
      "Iteretation: 454\n",
      "Iteretation: 455\n",
      "Iteretation: 456\n",
      "Iteretation: 457\n",
      "Iteretation: 458\n",
      "Iteretation: 459\n",
      "Iteretation: 460\n",
      "Iteretation: 461\n",
      "Iteretation: 462\n",
      "Iteretation: 463\n",
      "Iteretation: 464\n",
      "Iteretation: 465\n",
      "Iteretation: 466\n",
      "Iteretation: 467\n",
      "Iteretation: 468\n",
      "Iteretation: 469\n",
      "Iteretation: 470\n",
      "Iteretation: 471\n",
      "Iteretation: 472\n",
      "Iteretation: 473\n",
      "Iteretation: 474\n",
      "Iteretation: 475\n",
      "Iteretation: 476\n",
      "Iteretation: 477\n",
      "Iteretation: 478\n",
      "Iteretation: 479\n",
      "Iteretation: 480\n",
      "Iteretation: 481\n",
      "Iteretation: 482\n",
      "Iteretation: 483\n",
      "Iteretation: 484\n",
      "Iteretation: 485\n",
      "Iteretation: 486\n",
      "Iteretation: 487\n",
      "Iteretation: 488\n",
      "Iteretation: 489\n",
      "Iteretation: 490\n",
      "Iteretation: 491\n",
      "Iteretation: 492\n",
      "Iteretation: 493\n",
      "Iteretation: 494\n",
      "Iteretation: 495\n",
      "Iteretation: 496\n",
      "Iteretation: 497\n",
      "Iteretation: 498\n",
      "Iteretation: 499\n",
      "Iteretation: 500\n",
      "Iteretation: 501\n",
      "Iteretation: 502\n",
      "Iteretation: 503\n",
      "Iteretation: 504\n",
      "Iteretation: 505\n",
      "Iteretation: 506\n",
      "Iteretation: 507\n",
      "Iteretation: 508\n",
      "Iteretation: 509\n",
      "Iteretation: 510\n",
      "Iteretation: 511\n",
      "Iteretation: 512\n",
      "Iteretation: 513\n",
      "Iteretation: 514\n",
      "Iteretation: 515\n",
      "Iteretation: 516\n",
      "Iteretation: 517\n",
      "Iteretation: 518\n",
      "Iteretation: 519\n",
      "Iteretation: 520\n",
      "Iteretation: 521\n",
      "Iteretation: 522\n",
      "Iteretation: 523\n",
      "Iteretation: 524\n",
      "Iteretation: 525\n",
      "Iteretation: 526\n",
      "Iteretation: 527\n",
      "Iteretation: 528\n",
      "Iteretation: 529\n",
      "Iteretation: 530\n",
      "Iteretation: 531\n",
      "Iteretation: 532\n",
      "Iteretation: 533\n",
      "Iteretation: 534\n",
      "Iteretation: 535\n",
      "Iteretation: 536\n",
      "Iteretation: 537\n",
      "Iteretation: 538\n",
      "Iteretation: 539\n",
      "Iteretation: 540\n",
      "Iteretation: 541\n",
      "Iteretation: 542\n",
      "Iteretation: 543\n",
      "Iteretation: 544\n",
      "Iteretation: 545\n",
      "Iteretation: 546\n",
      "Iteretation: 547\n",
      "Iteretation: 548\n",
      "Iteretation: 549\n",
      "Iteretation: 550\n",
      "Iteretation: 551\n",
      "Iteretation: 552\n",
      "Iteretation: 553\n",
      "Iteretation: 554\n",
      "Iteretation: 555\n",
      "Iteretation: 556\n",
      "Iteretation: 557\n",
      "Iteretation: 558\n",
      "Iteretation: 559\n",
      "Iteretation: 560\n",
      "Iteretation: 561\n",
      "Iteretation: 562\n",
      "Iteretation: 563\n",
      "Iteretation: 564\n",
      "Iteretation: 565\n",
      "Iteretation: 566\n",
      "Iteretation: 567\n",
      "Iteretation: 568\n",
      "Iteretation: 569\n",
      "Iteretation: 570\n",
      "Iteretation: 571\n",
      "Iteretation: 572\n",
      "Iteretation: 573\n",
      "Iteretation: 574\n",
      "Iteretation: 575\n",
      "Iteretation: 576\n",
      "Iteretation: 577\n",
      "Iteretation: 578\n",
      "Iteretation: 579\n",
      "Iteretation: 580\n",
      "Iteretation: 581\n",
      "Iteretation: 582\n",
      "Iteretation: 583\n",
      "Iteretation: 584\n",
      "Iteretation: 585\n",
      "Iteretation: 586\n",
      "Iteretation: 587\n",
      "Iteretation: 588\n",
      "Iteretation: 589\n",
      "Iteretation: 590\n",
      "Iteretation: 591\n",
      "Iteretation: 592\n",
      "Iteretation: 593\n",
      "Iteretation: 594\n",
      "Iteretation: 595\n",
      "Iteretation: 596\n",
      "Iteretation: 597\n",
      "Iteretation: 598\n",
      "Iteretation: 599\n",
      "Iteretation: 600\n",
      "Iteretation: 601\n",
      "Iteretation: 602\n",
      "Iteretation: 603\n",
      "Iteretation: 604\n",
      "Iteretation: 605\n",
      "Iteretation: 606\n",
      "Iteretation: 607\n",
      "Iteretation: 608\n",
      "Iteretation: 609\n",
      "Iteretation: 610\n",
      "Iteretation: 611\n",
      "Iteretation: 612\n",
      "Iteretation: 613\n",
      "Iteretation: 614\n",
      "Iteretation: 615\n",
      "Iteretation: 616\n",
      "Iteretation: 617\n",
      "Iteretation: 618\n",
      "Iteretation: 619\n",
      "Iteretation: 620\n",
      "Iteretation: 621\n",
      "Iteretation: 622\n",
      "Iteretation: 623\n",
      "Iteretation: 624\n",
      "Iteretation: 625\n",
      "Iteretation: 626\n",
      "Iteretation: 627\n",
      "Iteretation: 628\n",
      "Iteretation: 629\n",
      "Iteretation: 630\n",
      "Iteretation: 631\n",
      "Iteretation: 632\n",
      "Iteretation: 633\n",
      "Iteretation: 634\n",
      "Iteretation: 635\n",
      "Iteretation: 636\n",
      "Iteretation: 637\n",
      "Iteretation: 638\n",
      "Iteretation: 639\n",
      "Iteretation: 640\n",
      "Iteretation: 641\n",
      "Iteretation: 642\n",
      "Iteretation: 643\n",
      "Iteretation: 644\n",
      "Iteretation: 645\n",
      "Iteretation: 646\n",
      "Iteretation: 647\n",
      "Iteretation: 648\n",
      "Iteretation: 649\n",
      "Iteretation: 650\n",
      "Iteretation: 651\n",
      "Iteretation: 652\n",
      "Iteretation: 653\n",
      "Iteretation: 654\n",
      "Iteretation: 655\n",
      "Iteretation: 656\n",
      "Iteretation: 657\n",
      "Iteretation: 658\n",
      "Iteretation: 659\n",
      "Iteretation: 660\n",
      "Iteretation: 661\n",
      "Iteretation: 662\n",
      "Iteretation: 663\n",
      "Iteretation: 664\n",
      "Iteretation: 665\n",
      "Iteretation: 666\n",
      "Iteretation: 667\n",
      "Iteretation: 668\n",
      "Iteretation: 669\n",
      "Iteretation: 670\n",
      "Iteretation: 671\n",
      "Iteretation: 672\n",
      "Iteretation: 673\n",
      "Iteretation: 674\n",
      "Iteretation: 675\n",
      "Iteretation: 676\n",
      "Iteretation: 677\n",
      "Iteretation: 678\n",
      "Iteretation: 679\n",
      "Iteretation: 680\n",
      "Iteretation: 681\n",
      "Iteretation: 682\n",
      "Iteretation: 683\n",
      "Iteretation: 684\n",
      "Iteretation: 685\n",
      "Iteretation: 686\n",
      "Iteretation: 687\n",
      "Iteretation: 688\n",
      "Iteretation: 689\n",
      "Iteretation: 690\n",
      "Iteretation: 691\n",
      "Iteretation: 692\n",
      "Iteretation: 693\n",
      "Iteretation: 694\n",
      "Iteretation: 695\n",
      "Iteretation: 696\n",
      "Iteretation: 697\n",
      "Iteretation: 698\n",
      "Iteretation: 699\n",
      "Iteretation: 700\n",
      "Iteretation: 701\n",
      "Iteretation: 702\n",
      "Iteretation: 703\n",
      "Iteretation: 704\n",
      "Iteretation: 705\n",
      "Iteretation: 706\n",
      "Iteretation: 707\n",
      "Iteretation: 708\n",
      "Iteretation: 709\n",
      "Iteretation: 710\n",
      "Iteretation: 711\n",
      "Iteretation: 712\n",
      "Iteretation: 713\n",
      "Iteretation: 714\n",
      "Iteretation: 715\n",
      "Iteretation: 716\n",
      "Iteretation: 717\n",
      "Iteretation: 718\n",
      "Iteretation: 719\n",
      "Iteretation: 720\n",
      "Iteretation: 721\n",
      "Iteretation: 722\n",
      "Iteretation: 723\n",
      "Iteretation: 724\n",
      "Iteretation: 725\n",
      "Iteretation: 726\n",
      "Iteretation: 727\n",
      "Iteretation: 728\n",
      "Iteretation: 729\n",
      "Iteretation: 730\n",
      "Iteretation: 731\n",
      "Iteretation: 732\n",
      "Iteretation: 733\n",
      "Iteretation: 734\n",
      "Iteretation: 735\n",
      "Iteretation: 736\n",
      "Iteretation: 737\n",
      "Iteretation: 738\n",
      "Iteretation: 739\n",
      "Iteretation: 740\n",
      "Iteretation: 741\n",
      "Iteretation: 742\n",
      "Iteretation: 743\n",
      "Iteretation: 744\n",
      "Iteretation: 745\n",
      "Iteretation: 746\n",
      "Iteretation: 747\n",
      "Iteretation: 748\n",
      "Iteretation: 749\n",
      "Iteretation: 750\n",
      "Iteretation: 751\n",
      "Iteretation: 752\n",
      "Iteretation: 753\n",
      "Iteretation: 754\n",
      "Iteretation: 755\n",
      "Iteretation: 756\n",
      "Iteretation: 757\n",
      "Iteretation: 758\n",
      "Iteretation: 759\n",
      "Iteretation: 760\n",
      "Iteretation: 761\n",
      "Iteretation: 762\n",
      "Iteretation: 763\n",
      "Iteretation: 764\n",
      "Iteretation: 765\n",
      "Iteretation: 766\n",
      "Iteretation: 767\n",
      "Iteretation: 768\n",
      "Iteretation: 769\n",
      "Iteretation: 770\n",
      "Iteretation: 771\n",
      "Iteretation: 772\n",
      "Iteretation: 773\n",
      "Iteretation: 774\n",
      "Iteretation: 775\n",
      "Iteretation: 776\n",
      "Iteretation: 777\n",
      "Iteretation: 778\n",
      "Iteretation: 779\n",
      "Iteretation: 780\n",
      "Iteretation: 781\n",
      "Iteretation: 782\n",
      "Iteretation: 783\n",
      "Iteretation: 784\n",
      "Iteretation: 785\n",
      "Iteretation: 786\n",
      "Iteretation: 787\n",
      "Iteretation: 788\n",
      "Iteretation: 789\n",
      "Iteretation: 790\n",
      "Iteretation: 791\n",
      "Iteretation: 792\n",
      "Iteretation: 793\n",
      "Iteretation: 794\n",
      "Iteretation: 795\n",
      "Iteretation: 796\n",
      "Iteretation: 797\n",
      "Iteretation: 798\n",
      "Iteretation: 799\n",
      "Iteretation: 800\n",
      "Iteretation: 801\n",
      "Iteretation: 802\n",
      "Iteretation: 803\n",
      "Iteretation: 804\n",
      "Iteretation: 805\n",
      "Iteretation: 806\n",
      "Iteretation: 807\n",
      "Iteretation: 808\n",
      "Iteretation: 809\n",
      "Iteretation: 810\n",
      "Iteretation: 811\n",
      "Iteretation: 812\n",
      "Iteretation: 813\n",
      "Iteretation: 814\n",
      "Iteretation: 815\n",
      "Iteretation: 816\n",
      "Iteretation: 817\n",
      "Iteretation: 818\n",
      "Iteretation: 819\n",
      "Iteretation: 820\n",
      "Iteretation: 821\n",
      "Iteretation: 822\n",
      "Iteretation: 823\n",
      "Iteretation: 824\n",
      "Iteretation: 825\n",
      "Iteretation: 826\n",
      "Iteretation: 827\n",
      "Iteretation: 828\n",
      "Iteretation: 829\n",
      "Iteretation: 830\n",
      "Iteretation: 831\n",
      "Iteretation: 832\n",
      "Iteretation: 833\n",
      "Iteretation: 834\n",
      "Iteretation: 835\n",
      "Iteretation: 836\n",
      "Iteretation: 837\n",
      "Iteretation: 838\n",
      "Iteretation: 839\n",
      "Iteretation: 840\n",
      "Iteretation: 841\n",
      "Iteretation: 842\n",
      "Iteretation: 843\n",
      "Iteretation: 844\n",
      "Iteretation: 845\n",
      "Iteretation: 846\n",
      "Iteretation: 847\n",
      "Iteretation: 848\n",
      "Iteretation: 849\n",
      "Iteretation: 850\n",
      "Iteretation: 851\n",
      "Iteretation: 852\n",
      "Iteretation: 853\n",
      "Iteretation: 854\n",
      "Iteretation: 855\n",
      "Iteretation: 856\n",
      "Iteretation: 857\n",
      "Iteretation: 858\n",
      "Iteretation: 859\n",
      "Iteretation: 860\n",
      "Iteretation: 861\n",
      "Iteretation: 862\n",
      "Iteretation: 863\n",
      "Iteretation: 864\n",
      "Iteretation: 865\n",
      "Iteretation: 866\n",
      "Iteretation: 867\n",
      "Iteretation: 868\n",
      "Iteretation: 869\n",
      "Iteretation: 870\n",
      "Iteretation: 871\n",
      "Iteretation: 872\n",
      "Iteretation: 873\n",
      "Iteretation: 874\n",
      "Iteretation: 875\n",
      "Iteretation: 876\n",
      "Iteretation: 877\n",
      "Iteretation: 878\n",
      "Iteretation: 879\n",
      "Iteretation: 880\n",
      "Iteretation: 881\n",
      "Iteretation: 882\n",
      "Iteretation: 883\n",
      "Iteretation: 884\n",
      "Iteretation: 885\n",
      "Iteretation: 886\n",
      "Iteretation: 887\n",
      "Iteretation: 888\n",
      "Iteretation: 889\n",
      "Iteretation: 890\n",
      "Iteretation: 891\n",
      "Iteretation: 892\n",
      "Iteretation: 893\n",
      "Iteretation: 894\n",
      "Iteretation: 895\n",
      "Iteretation: 896\n",
      "Iteretation: 897\n",
      "Iteretation: 898\n",
      "Iteretation: 899\n",
      "Iteretation: 900\n",
      "Iteretation: 901\n",
      "Iteretation: 902\n",
      "Iteretation: 903\n",
      "Iteretation: 904\n",
      "Iteretation: 905\n",
      "Iteretation: 906\n",
      "Iteretation: 907\n",
      "Iteretation: 908\n",
      "Iteretation: 909\n",
      "Iteretation: 910\n",
      "Iteretation: 911\n",
      "Iteretation: 912\n",
      "Iteretation: 913\n",
      "Iteretation: 914\n",
      "Iteretation: 915\n",
      "Iteretation: 916\n",
      "Iteretation: 917\n",
      "Iteretation: 918\n",
      "Iteretation: 919\n",
      "Iteretation: 920\n",
      "Iteretation: 921\n",
      "Iteretation: 922\n",
      "Iteretation: 923\n",
      "Iteretation: 924\n",
      "Iteretation: 925\n",
      "Iteretation: 926\n",
      "Iteretation: 927\n",
      "Iteretation: 928\n",
      "Iteretation: 929\n",
      "Iteretation: 930\n",
      "Iteretation: 931\n",
      "Iteretation: 932\n",
      "Iteretation: 933\n",
      "Iteretation: 934\n",
      "Iteretation: 935\n",
      "Iteretation: 936\n",
      "Iteretation: 937\n",
      "Iteretation: 938\n",
      "Iteretation: 939\n",
      "Iteretation: 940\n",
      "Iteretation: 941\n",
      "Iteretation: 942\n",
      "Iteretation: 943\n",
      "Iteretation: 944\n",
      "Iteretation: 945\n",
      "Iteretation: 946\n",
      "Iteretation: 947\n",
      "Iteretation: 948\n",
      "Iteretation: 949\n",
      "Iteretation: 950\n",
      "Iteretation: 951\n",
      "Iteretation: 952\n",
      "Iteretation: 953\n",
      "Iteretation: 954\n",
      "Iteretation: 955\n",
      "Iteretation: 956\n",
      "Iteretation: 957\n",
      "Iteretation: 958\n",
      "Iteretation: 959\n",
      "Iteretation: 960\n",
      "Iteretation: 961\n",
      "Iteretation: 962\n",
      "Iteretation: 963\n",
      "Iteretation: 964\n",
      "Iteretation: 965\n",
      "Iteretation: 966\n",
      "Iteretation: 967\n",
      "Iteretation: 968\n",
      "Iteretation: 969\n",
      "Iteretation: 970\n",
      "Iteretation: 971\n",
      "Iteretation: 972\n",
      "Iteretation: 973\n",
      "Iteretation: 974\n",
      "Iteretation: 975\n",
      "Iteretation: 976\n",
      "Iteretation: 977\n",
      "Iteretation: 978\n",
      "Iteretation: 979\n",
      "Iteretation: 980\n",
      "Iteretation: 981\n",
      "Iteretation: 982\n",
      "Iteretation: 983\n",
      "Iteretation: 984\n",
      "Iteretation: 985\n",
      "Iteretation: 986\n",
      "Iteretation: 987\n",
      "Iteretation: 988\n",
      "Iteretation: 989\n",
      "Iteretation: 990\n",
      "Iteretation: 991\n",
      "Iteretation: 992\n",
      "Iteretation: 993\n",
      "Iteretation: 994\n",
      "Iteretation: 995\n",
      "Iteretation: 996\n",
      "Iteretation: 997\n",
      "Iteretation: 998\n",
      "Iteretation: 999\n",
      "Iteretation: 1000\n",
      "Iteretation: 1001\n",
      "Iteretation: 1002\n",
      "Iteretation: 1003\n",
      "Iteretation: 1004\n",
      "Iteretation: 1005\n",
      "Iteretation: 1006\n",
      "Iteretation: 1007\n",
      "Iteretation: 1008\n",
      "Iteretation: 1009\n",
      "Iteretation: 1010\n",
      "Iteretation: 1011\n",
      "Iteretation: 1012\n",
      "Iteretation: 1013\n",
      "Iteretation: 1014\n",
      "Iteretation: 1015\n",
      "Iteretation: 1016\n",
      "Iteretation: 1017\n",
      "Iteretation: 1018\n",
      "Iteretation: 1019\n",
      "Iteretation: 1020\n",
      "Iteretation: 1021\n",
      "Iteretation: 1022\n",
      "Iteretation: 1023\n",
      "Iteretation: 1024\n",
      "Iteretation: 1025\n",
      "Iteretation: 1026\n",
      "Iteretation: 1027\n",
      "Iteretation: 1028\n",
      "Iteretation: 1029\n",
      "Iteretation: 1030\n",
      "Iteretation: 1031\n",
      "Iteretation: 1032\n",
      "Iteretation: 1033\n",
      "Iteretation: 1034\n",
      "Iteretation: 1035\n",
      "Iteretation: 1036\n",
      "Iteretation: 1037\n",
      "Iteretation: 1038\n",
      "Iteretation: 1039\n",
      "Iteretation: 1040\n",
      "Iteretation: 1041\n",
      "Iteretation: 1042\n",
      "Iteretation: 1043\n",
      "Iteretation: 1044\n",
      "Iteretation: 1045\n",
      "Iteretation: 1046\n",
      "Iteretation: 1047\n",
      "Iteretation: 1048\n",
      "Iteretation: 1049\n",
      "Iteretation: 1050\n",
      "Iteretation: 1051\n",
      "Iteretation: 1052\n",
      "Iteretation: 1053\n",
      "Iteretation: 1054\n",
      "Iteretation: 1055\n",
      "Iteretation: 1056\n",
      "Iteretation: 1057\n",
      "Iteretation: 1058\n",
      "Iteretation: 1059\n",
      "Iteretation: 1060\n",
      "Iteretation: 1061\n",
      "Iteretation: 1062\n",
      "Iteretation: 1063\n",
      "Iteretation: 1064\n",
      "Iteretation: 1065\n",
      "Iteretation: 1066\n",
      "Iteretation: 1067\n",
      "Iteretation: 1068\n",
      "Iteretation: 1069\n",
      "Iteretation: 1070\n",
      "Iteretation: 1071\n",
      "Iteretation: 1072\n",
      "Iteretation: 1073\n",
      "Iteretation: 1074\n",
      "Iteretation: 1075\n",
      "Iteretation: 1076\n",
      "Iteretation: 1077\n",
      "Iteretation: 1078\n",
      "Iteretation: 1079\n",
      "Iteretation: 1080\n",
      "Iteretation: 1081\n",
      "Iteretation: 1082\n",
      "Iteretation: 1083\n",
      "Iteretation: 1084\n",
      "Iteretation: 1085\n",
      "Iteretation: 1086\n",
      "Iteretation: 1087\n",
      "Iteretation: 1088\n",
      "Iteretation: 1089\n",
      "Iteretation: 1090\n",
      "Iteretation: 1091\n",
      "Iteretation: 1092\n",
      "Iteretation: 1093\n",
      "Iteretation: 1094\n",
      "Iteretation: 1095\n",
      "Iteretation: 1096\n",
      "Iteretation: 1097\n",
      "Iteretation: 1098\n",
      "Iteretation: 1099\n",
      "Iteretation: 1100\n",
      "Iteretation: 1101\n",
      "Iteretation: 1102\n",
      "Iteretation: 1103\n",
      "Iteretation: 1104\n",
      "Iteretation: 1105\n",
      "Iteretation: 1106\n",
      "Iteretation: 1107\n",
      "Iteretation: 1108\n",
      "Iteretation: 1109\n",
      "Iteretation: 1110\n",
      "Iteretation: 1111\n",
      "Iteretation: 1112\n",
      "Iteretation: 1113\n",
      "Iteretation: 1114\n",
      "Iteretation: 1115\n",
      "Iteretation: 1116\n",
      "Iteretation: 1117\n",
      "Iteretation: 1118\n",
      "Iteretation: 1119\n",
      "Iteretation: 1120\n",
      "Iteretation: 1121\n",
      "Iteretation: 1122\n",
      "Iteretation: 1123\n",
      "Iteretation: 1124\n",
      "Iteretation: 1125\n",
      "Iteretation: 1126\n",
      "Iteretation: 1127\n",
      "Iteretation: 1128\n",
      "Iteretation: 1129\n",
      "Iteretation: 1130\n",
      "Iteretation: 1131\n",
      "Iteretation: 1132\n",
      "Iteretation: 1133\n",
      "Iteretation: 1134\n",
      "Iteretation: 1135\n",
      "Iteretation: 1136\n",
      "Iteretation: 1137\n",
      "Iteretation: 1138\n",
      "Iteretation: 1139\n",
      "Iteretation: 1140\n",
      "Iteretation: 1141\n",
      "Iteretation: 1142\n",
      "Iteretation: 1143\n",
      "Iteretation: 1144\n",
      "Iteretation: 1145\n",
      "Iteretation: 1146\n",
      "Iteretation: 1147\n",
      "Iteretation: 1148\n",
      "Iteretation: 1149\n",
      "Iteretation: 1150\n",
      "Iteretation: 1151\n",
      "Iteretation: 1152\n",
      "Iteretation: 1153\n",
      "Iteretation: 1154\n",
      "Iteretation: 1155\n",
      "Iteretation: 1156\n",
      "Iteretation: 1157\n",
      "Iteretation: 1158\n",
      "Iteretation: 1159\n",
      "Iteretation: 1160\n",
      "Iteretation: 1161\n",
      "Iteretation: 1162\n",
      "Iteretation: 1163\n",
      "Iteretation: 1164\n",
      "Iteretation: 1165\n",
      "Iteretation: 1166\n",
      "Iteretation: 1167\n",
      "Iteretation: 1168\n",
      "Iteretation: 1169\n",
      "Iteretation: 1170\n",
      "Iteretation: 1171\n",
      "Iteretation: 1172\n",
      "Iteretation: 1173\n",
      "Iteretation: 1174\n",
      "Iteretation: 1175\n",
      "Iteretation: 1176\n",
      "Iteretation: 1177\n",
      "Iteretation: 1178\n",
      "Iteretation: 1179\n",
      "Iteretation: 1180\n",
      "Iteretation: 1181\n",
      "Iteretation: 1182\n",
      "Iteretation: 1183\n",
      "Iteretation: 1184\n",
      "Iteretation: 1185\n",
      "Iteretation: 1186\n",
      "Iteretation: 1187\n",
      "Iteretation: 1188\n",
      "Iteretation: 1189\n",
      "Iteretation: 1190\n",
      "Iteretation: 1191\n",
      "Iteretation: 1192\n",
      "Iteretation: 1193\n",
      "Iteretation: 1194\n",
      "Iteretation: 1195\n",
      "Iteretation: 1196\n",
      "Iteretation: 1197\n",
      "Iteretation: 1198\n",
      "Iteretation: 1199\n",
      "Iteretation: 1200\n",
      "Iteretation: 1201\n",
      "Iteretation: 1202\n",
      "Iteretation: 1203\n",
      "Iteretation: 1204\n",
      "Iteretation: 1205\n",
      "Iteretation: 1206\n",
      "Iteretation: 1207\n",
      "Iteretation: 1208\n",
      "Iteretation: 1209\n",
      "Iteretation: 1210\n",
      "Iteretation: 1211\n",
      "Iteretation: 1212\n",
      "Iteretation: 1213\n",
      "Iteretation: 1214\n",
      "Iteretation: 1215\n",
      "Iteretation: 1216\n",
      "Iteretation: 1217\n",
      "Iteretation: 1218\n",
      "Iteretation: 1219\n",
      "Iteretation: 1220\n",
      "Iteretation: 1221\n",
      "Iteretation: 1222\n",
      "Iteretation: 1223\n",
      "Iteretation: 1224\n",
      "Iteretation: 1225\n",
      "Iteretation: 1226\n",
      "Iteretation: 1227\n",
      "Iteretation: 1228\n",
      "Iteretation: 1229\n",
      "Iteretation: 1230\n",
      "Iteretation: 1231\n",
      "Iteretation: 1232\n",
      "Iteretation: 1233\n",
      "Iteretation: 1234\n",
      "Iteretation: 1235\n",
      "Iteretation: 1236\n",
      "Iteretation: 1237\n",
      "Iteretation: 1238\n",
      "Iteretation: 1239\n",
      "Iteretation: 1240\n",
      "Iteretation: 1241\n",
      "Iteretation: 1242\n",
      "Iteretation: 1243\n",
      "Iteretation: 1244\n",
      "Iteretation: 1245\n",
      "Iteretation: 1246\n",
      "Iteretation: 1247\n",
      "Iteretation: 1248\n",
      "Iteretation: 1249\n",
      "Iteretation: 1250\n",
      "Iteretation: 1251\n",
      "Iteretation: 1252\n",
      "Iteretation: 1253\n",
      "Iteretation: 1254\n",
      "Iteretation: 1255\n",
      "Iteretation: 1256\n",
      "Iteretation: 1257\n",
      "Iteretation: 1258\n",
      "Iteretation: 1259\n",
      "Iteretation: 1260\n",
      "Iteretation: 1261\n",
      "Iteretation: 1262\n",
      "Iteretation: 1263\n",
      "Iteretation: 1264\n",
      "Iteretation: 1265\n",
      "Iteretation: 1266\n",
      "Iteretation: 1267\n",
      "Iteretation: 1268\n",
      "Iteretation: 1269\n",
      "Iteretation: 1270\n",
      "Iteretation: 1271\n",
      "Iteretation: 1272\n",
      "Iteretation: 1273\n",
      "Iteretation: 1274\n",
      "Iteretation: 1275\n",
      "Iteretation: 1276\n",
      "Iteretation: 1277\n",
      "Iteretation: 1278\n",
      "Iteretation: 1279\n",
      "Iteretation: 1280\n",
      "Iteretation: 1281\n",
      "Iteretation: 1282\n",
      "Iteretation: 1283\n",
      "Iteretation: 1284\n",
      "Iteretation: 1285\n",
      "Iteretation: 1286\n",
      "Iteretation: 1287\n",
      "Iteretation: 1288\n",
      "Iteretation: 1289\n",
      "Iteretation: 1290\n",
      "Iteretation: 1291\n",
      "Iteretation: 1292\n",
      "Iteretation: 1293\n",
      "Iteretation: 1294\n",
      "Iteretation: 1295\n",
      "Iteretation: 1296\n",
      "Iteretation: 1297\n",
      "Iteretation: 1298\n",
      "Iteretation: 1299\n",
      "Iteretation: 1300\n",
      "Iteretation: 1301\n",
      "Iteretation: 1302\n",
      "Iteretation: 1303\n",
      "Iteretation: 1304\n",
      "Iteretation: 1305\n",
      "Iteretation: 1306\n",
      "Iteretation: 1307\n",
      "Iteretation: 1308\n",
      "Iteretation: 1309\n",
      "Iteretation: 1310\n",
      "Iteretation: 1311\n",
      "Iteretation: 1312\n",
      "Iteretation: 1313\n",
      "Iteretation: 1314\n",
      "Iteretation: 1315\n",
      "Iteretation: 1316\n",
      "Iteretation: 1317\n",
      "Iteretation: 1318\n",
      "Iteretation: 1319\n",
      "Iteretation: 1320\n",
      "Iteretation: 1321\n",
      "Iteretation: 1322\n",
      "Iteretation: 1323\n",
      "Iteretation: 1324\n",
      "Iteretation: 1325\n",
      "Iteretation: 1326\n",
      "Iteretation: 1327\n",
      "Iteretation: 1328\n",
      "Iteretation: 1329\n",
      "Iteretation: 1330\n",
      "Iteretation: 1331\n",
      "Iteretation: 1332\n",
      "Iteretation: 1333\n",
      "Iteretation: 1334\n",
      "Iteretation: 1335\n",
      "Iteretation: 1336\n",
      "Iteretation: 1337\n",
      "Iteretation: 1338\n",
      "Iteretation: 1339\n",
      "Iteretation: 1340\n",
      "Iteretation: 1341\n",
      "Iteretation: 1342\n",
      "Iteretation: 1343\n",
      "Iteretation: 1344\n",
      "Iteretation: 1345\n",
      "Iteretation: 1346\n",
      "Iteretation: 1347\n",
      "Iteretation: 1348\n",
      "Iteretation: 1349\n",
      "Iteretation: 1350\n",
      "Iteretation: 1351\n",
      "Iteretation: 1352\n",
      "Iteretation: 1353\n",
      "Iteretation: 1354\n",
      "Iteretation: 1355\n",
      "Iteretation: 1356\n",
      "Iteretation: 1357\n",
      "Iteretation: 1358\n",
      "Iteretation: 1359\n",
      "Iteretation: 1360\n",
      "Iteretation: 1361\n",
      "Iteretation: 1362\n",
      "Iteretation: 1363\n",
      "Iteretation: 1364\n",
      "Iteretation: 1365\n",
      "Iteretation: 1366\n",
      "Iteretation: 1367\n",
      "Iteretation: 1368\n",
      "Iteretation: 1369\n",
      "Iteretation: 1370\n",
      "Iteretation: 1371\n",
      "Iteretation: 1372\n",
      "Iteretation: 1373\n",
      "Iteretation: 1374\n",
      "Iteretation: 1375\n",
      "Iteretation: 1376\n",
      "Iteretation: 1377\n",
      "Iteretation: 1378\n",
      "Iteretation: 1379\n",
      "Iteretation: 1380\n",
      "Iteretation: 1381\n",
      "Iteretation: 1382\n",
      "Iteretation: 1383\n",
      "Iteretation: 1384\n",
      "Iteretation: 1385\n",
      "Iteretation: 1386\n",
      "Iteretation: 1387\n",
      "Iteretation: 1388\n",
      "Iteretation: 1389\n",
      "Iteretation: 1390\n",
      "Iteretation: 1391\n",
      "Iteretation: 1392\n",
      "Iteretation: 1393\n",
      "Iteretation: 1394\n",
      "Iteretation: 1395\n",
      "Iteretation: 1396\n",
      "Iteretation: 1397\n",
      "Iteretation: 1398\n",
      "Iteretation: 1399\n",
      "Iteretation: 1400\n",
      "Iteretation: 1401\n",
      "Iteretation: 1402\n",
      "Iteretation: 1403\n",
      "Iteretation: 1404\n",
      "Iteretation: 1405\n",
      "Iteretation: 1406\n",
      "Iteretation: 1407\n",
      "Iteretation: 1408\n",
      "Iteretation: 1409\n",
      "Iteretation: 1410\n",
      "Iteretation: 1411\n",
      "Iteretation: 1412\n",
      "Iteretation: 1413\n",
      "Iteretation: 1414\n",
      "Iteretation: 1415\n",
      "Iteretation: 1416\n",
      "Iteretation: 1417\n",
      "Iteretation: 1418\n",
      "Iteretation: 1419\n",
      "Iteretation: 1420\n",
      "Iteretation: 1421\n",
      "Iteretation: 1422\n",
      "Iteretation: 1423\n",
      "Iteretation: 1424\n",
      "Iteretation: 1425\n",
      "Iteretation: 1426\n",
      "Iteretation: 1427\n",
      "Iteretation: 1428\n",
      "Iteretation: 1429\n",
      "Iteretation: 1430\n",
      "Iteretation: 1431\n",
      "Iteretation: 1432\n",
      "Iteretation: 1433\n",
      "Iteretation: 1434\n",
      "Iteretation: 1435\n",
      "Iteretation: 1436\n",
      "Iteretation: 1437\n",
      "Iteretation: 1438\n",
      "Iteretation: 1439\n",
      "Iteretation: 1440\n",
      "Iteretation: 1441\n",
      "Iteretation: 1442\n",
      "Iteretation: 1443\n",
      "Iteretation: 1444\n",
      "Iteretation: 1445\n",
      "Iteretation: 1446\n",
      "Iteretation: 1447\n",
      "Iteretation: 1448\n",
      "Iteretation: 1449\n",
      "Iteretation: 1450\n",
      "Iteretation: 1451\n",
      "Iteretation: 1452\n",
      "Iteretation: 1453\n",
      "Iteretation: 1454\n",
      "Iteretation: 1455\n",
      "Iteretation: 1456\n",
      "Iteretation: 1457\n",
      "Iteretation: 1458\n",
      "Iteretation: 1459\n",
      "Iteretation: 1460\n",
      "Iteretation: 1461\n",
      "Iteretation: 1462\n",
      "Iteretation: 1463\n",
      "Iteretation: 1464\n",
      "Iteretation: 1465\n",
      "Iteretation: 1466\n",
      "Iteretation: 1467\n",
      "Iteretation: 1468\n",
      "Iteretation: 1469\n",
      "Iteretation: 1470\n",
      "Iteretation: 1471\n",
      "Iteretation: 1472\n",
      "Iteretation: 1473\n",
      "Iteretation: 1474\n",
      "Iteretation: 1475\n",
      "Iteretation: 1476\n",
      "Iteretation: 1477\n",
      "Iteretation: 1478\n",
      "Iteretation: 1479\n",
      "Iteretation: 1480\n",
      "Iteretation: 1481\n",
      "Iteretation: 1482\n",
      "Iteretation: 1483\n",
      "Iteretation: 1484\n",
      "Iteretation: 1485\n",
      "Iteretation: 1486\n",
      "Iteretation: 1487\n",
      "Iteretation: 1488\n",
      "Iteretation: 1489\n",
      "Iteretation: 1490\n",
      "Iteretation: 1491\n",
      "Iteretation: 1492\n",
      "Iteretation: 1493\n",
      "Iteretation: 1494\n",
      "Iteretation: 1495\n",
      "Iteretation: 1496\n",
      "Iteretation: 1497\n",
      "Iteretation: 1498\n",
      "Iteretation: 1499\n",
      "Iteretation: 1500\n",
      "Iteretation: 1501\n",
      "Iteretation: 1502\n",
      "Iteretation: 1503\n",
      "Iteretation: 1504\n",
      "Iteretation: 1505\n",
      "Iteretation: 1506\n",
      "Iteretation: 1507\n",
      "Iteretation: 1508\n",
      "Iteretation: 1509\n",
      "Iteretation: 1510\n",
      "Iteretation: 1511\n",
      "Iteretation: 1512\n",
      "Iteretation: 1513\n",
      "Iteretation: 1514\n",
      "Iteretation: 1515\n",
      "Iteretation: 1516\n",
      "Iteretation: 1517\n",
      "Iteretation: 1518\n",
      "Iteretation: 1519\n",
      "Iteretation: 1520\n",
      "Iteretation: 1521\n",
      "Iteretation: 1522\n",
      "Iteretation: 1523\n",
      "Iteretation: 1524\n",
      "Iteretation: 1525\n",
      "Iteretation: 1526\n",
      "Iteretation: 1527\n",
      "Iteretation: 1528\n",
      "Iteretation: 1529\n",
      "Iteretation: 1530\n",
      "Iteretation: 1531\n",
      "Iteretation: 1532\n",
      "Iteretation: 1533\n",
      "Iteretation: 1534\n",
      "Iteretation: 1535\n",
      "Iteretation: 1536\n",
      "Iteretation: 1537\n",
      "Iteretation: 1538\n",
      "Iteretation: 1539\n",
      "Iteretation: 1540\n",
      "Iteretation: 1541\n",
      "Iteretation: 1542\n",
      "Iteretation: 1543\n",
      "Iteretation: 1544\n",
      "Iteretation: 1545\n",
      "Iteretation: 1546\n",
      "Iteretation: 1547\n",
      "Iteretation: 1548\n",
      "Iteretation: 1549\n",
      "Iteretation: 1550\n",
      "Iteretation: 1551\n",
      "Iteretation: 1552\n",
      "Iteretation: 1553\n",
      "Iteretation: 1554\n",
      "Iteretation: 1555\n",
      "Iteretation: 1556\n",
      "Iteretation: 1557\n",
      "Iteretation: 1558\n",
      "Iteretation: 1559\n",
      "Iteretation: 1560\n",
      "Iteretation: 1561\n",
      "Iteretation: 1562\n",
      "Iteretation: 1563\n",
      "Iteretation: 1564\n",
      "Iteretation: 1565\n",
      "Iteretation: 1566\n",
      "Iteretation: 1567\n",
      "Iteretation: 1568\n",
      "Iteretation: 1569\n",
      "Iteretation: 1570\n",
      "Iteretation: 1571\n",
      "Iteretation: 1572\n",
      "Iteretation: 1573\n",
      "Iteretation: 1574\n",
      "Iteretation: 1575\n",
      "Iteretation: 1576\n",
      "Iteretation: 1577\n",
      "Iteretation: 1578\n",
      "Iteretation: 1579\n",
      "Iteretation: 1580\n",
      "Iteretation: 1581\n",
      "Iteretation: 1582\n",
      "Iteretation: 1583\n",
      "Iteretation: 1584\n",
      "Iteretation: 1585\n",
      "Iteretation: 1586\n",
      "Iteretation: 1587\n",
      "Iteretation: 1588\n",
      "Iteretation: 1589\n",
      "Iteretation: 1590\n",
      "Iteretation: 1591\n",
      "Iteretation: 1592\n",
      "Iteretation: 1593\n",
      "Iteretation: 1594\n",
      "Iteretation: 1595\n",
      "Iteretation: 1596\n",
      "Iteretation: 1597\n",
      "Iteretation: 1598\n",
      "Iteretation: 1599\n",
      "Iteretation: 1600\n",
      "Iteretation: 1601\n",
      "Iteretation: 1602\n",
      "Iteretation: 1603\n",
      "Iteretation: 1604\n",
      "Iteretation: 1605\n",
      "Iteretation: 1606\n",
      "Iteretation: 1607\n",
      "Iteretation: 1608\n",
      "Iteretation: 1609\n",
      "Iteretation: 1610\n",
      "Iteretation: 1611\n",
      "Iteretation: 1612\n",
      "Iteretation: 1613\n",
      "Iteretation: 1614\n",
      "Iteretation: 1615\n",
      "Iteretation: 1616\n",
      "Iteretation: 1617\n",
      "Iteretation: 1618\n",
      "Iteretation: 1619\n",
      "Iteretation: 1620\n",
      "Iteretation: 1621\n",
      "Iteretation: 1622\n",
      "Iteretation: 1623\n",
      "Iteretation: 1624\n",
      "Iteretation: 1625\n",
      "Iteretation: 1626\n",
      "Iteretation: 1627\n",
      "Iteretation: 1628\n",
      "Iteretation: 1629\n",
      "Iteretation: 1630\n",
      "Iteretation: 1631\n",
      "Iteretation: 1632\n",
      "Iteretation: 1633\n",
      "Iteretation: 1634\n",
      "Iteretation: 1635\n",
      "Iteretation: 1636\n",
      "Iteretation: 1637\n",
      "Iteretation: 1638\n",
      "Iteretation: 1639\n",
      "Iteretation: 1640\n",
      "Iteretation: 1641\n",
      "Iteretation: 1642\n",
      "Iteretation: 1643\n",
      "Iteretation: 1644\n",
      "Iteretation: 1645\n",
      "Iteretation: 1646\n",
      "Iteretation: 1647\n",
      "Iteretation: 1648\n",
      "Iteretation: 1649\n",
      "Iteretation: 1650\n",
      "Iteretation: 1651\n",
      "Iteretation: 1652\n",
      "Iteretation: 1653\n",
      "Iteretation: 1654\n",
      "Iteretation: 1655\n",
      "Iteretation: 1656\n",
      "Iteretation: 1657\n",
      "Iteretation: 1658\n",
      "Iteretation: 1659\n",
      "Iteretation: 1660\n",
      "Iteretation: 1661\n",
      "Iteretation: 1662\n",
      "Iteretation: 1663\n",
      "Iteretation: 1664\n",
      "Iteretation: 1665\n",
      "Iteretation: 1666\n",
      "Iteretation: 1667\n",
      "Iteretation: 1668\n",
      "Iteretation: 1669\n",
      "Iteretation: 1670\n",
      "Iteretation: 1671\n",
      "Iteretation: 1672\n",
      "Iteretation: 1673\n",
      "Iteretation: 1674\n",
      "Iteretation: 1675\n",
      "Iteretation: 1676\n",
      "Iteretation: 1677\n",
      "Iteretation: 1678\n",
      "Iteretation: 1679\n",
      "Iteretation: 1680\n",
      "Iteretation: 1681\n",
      "Iteretation: 1682\n",
      "Iteretation: 1683\n",
      "Iteretation: 1684\n",
      "Iteretation: 1685\n",
      "Iteretation: 1686\n",
      "Iteretation: 1687\n",
      "Iteretation: 1688\n",
      "Iteretation: 1689\n",
      "Iteretation: 1690\n",
      "Iteretation: 1691\n",
      "Iteretation: 1692\n",
      "Iteretation: 1693\n",
      "Iteretation: 1694\n",
      "Iteretation: 1695\n",
      "Iteretation: 1696\n",
      "Iteretation: 1697\n",
      "Iteretation: 1698\n",
      "Iteretation: 1699\n",
      "Iteretation: 1700\n",
      "Iteretation: 1701\n",
      "Iteretation: 1702\n",
      "Iteretation: 1703\n",
      "Iteretation: 1704\n",
      "Iteretation: 1705\n",
      "Iteretation: 1706\n",
      "Iteretation: 1707\n",
      "Iteretation: 1708\n",
      "Iteretation: 1709\n",
      "Iteretation: 1710\n",
      "Iteretation: 1711\n",
      "Iteretation: 1712\n",
      "Iteretation: 1713\n",
      "Iteretation: 1714\n",
      "Iteretation: 1715\n",
      "Iteretation: 1716\n",
      "Iteretation: 1717\n",
      "Iteretation: 1718\n",
      "Iteretation: 1719\n",
      "Iteretation: 1720\n",
      "Iteretation: 1721\n",
      "Iteretation: 1722\n",
      "Iteretation: 1723\n",
      "Iteretation: 1724\n",
      "Iteretation: 1725\n",
      "Iteretation: 1726\n",
      "Iteretation: 1727\n",
      "Iteretation: 1728\n",
      "Iteretation: 1729\n",
      "Iteretation: 1730\n",
      "Iteretation: 1731\n",
      "Iteretation: 1732\n",
      "Iteretation: 1733\n",
      "Iteretation: 1734\n",
      "Iteretation: 1735\n",
      "Iteretation: 1736\n",
      "Iteretation: 1737\n",
      "Iteretation: 1738\n",
      "Iteretation: 1739\n",
      "Iteretation: 1740\n",
      "Iteretation: 1741\n",
      "Iteretation: 1742\n",
      "Iteretation: 1743\n",
      "Iteretation: 1744\n",
      "Iteretation: 1745\n",
      "Iteretation: 1746\n",
      "Iteretation: 1747\n",
      "Iteretation: 1748\n",
      "Iteretation: 1749\n",
      "Iteretation: 1750\n",
      "Iteretation: 1751\n",
      "Iteretation: 1752\n",
      "Iteretation: 1753\n",
      "Iteretation: 1754\n",
      "Iteretation: 1755\n",
      "Iteretation: 1756\n",
      "Iteretation: 1757\n",
      "Iteretation: 1758\n",
      "Iteretation: 1759\n",
      "Iteretation: 1760\n",
      "Iteretation: 1761\n",
      "Iteretation: 1762\n",
      "Iteretation: 1763\n",
      "Iteretation: 1764\n",
      "Iteretation: 1765\n",
      "Iteretation: 1766\n",
      "Iteretation: 1767\n",
      "Iteretation: 1768\n",
      "Iteretation: 1769\n",
      "Iteretation: 1770\n",
      "Iteretation: 1771\n",
      "Iteretation: 1772\n",
      "Iteretation: 1773\n",
      "Iteretation: 1774\n",
      "Iteretation: 1775\n",
      "Iteretation: 1776\n",
      "Iteretation: 1777\n",
      "Iteretation: 1778\n",
      "Iteretation: 1779\n",
      "Iteretation: 1780\n",
      "Iteretation: 1781\n",
      "Iteretation: 1782\n",
      "Iteretation: 1783\n",
      "Iteretation: 1784\n",
      "Iteretation: 1785\n",
      "Iteretation: 1786\n",
      "Iteretation: 1787\n",
      "Iteretation: 1788\n",
      "Iteretation: 1789\n",
      "Iteretation: 1790\n",
      "Iteretation: 1791\n",
      "Iteretation: 1792\n",
      "Iteretation: 1793\n",
      "Iteretation: 1794\n",
      "Iteretation: 1795\n",
      "Iteretation: 1796\n",
      "Iteretation: 1797\n",
      "Iteretation: 1798\n",
      "Iteretation: 1799\n",
      "Iteretation: 1800\n",
      "Iteretation: 1801\n",
      "Iteretation: 1802\n",
      "Iteretation: 1803\n",
      "Iteretation: 1804\n",
      "Iteretation: 1805\n",
      "Iteretation: 1806\n",
      "Iteretation: 1807\n",
      "Iteretation: 1808\n",
      "Iteretation: 1809\n",
      "Iteretation: 1810\n",
      "Iteretation: 1811\n",
      "Iteretation: 1812\n",
      "Iteretation: 1813\n",
      "Iteretation: 1814\n",
      "Iteretation: 1815\n",
      "Iteretation: 1816\n",
      "Iteretation: 1817\n",
      "Iteretation: 1818\n",
      "Iteretation: 1819\n",
      "Iteretation: 1820\n",
      "Iteretation: 1821\n",
      "Iteretation: 1822\n",
      "Iteretation: 1823\n",
      "Iteretation: 1824\n",
      "Iteretation: 1825\n",
      "Iteretation: 1826\n",
      "Iteretation: 1827\n",
      "Iteretation: 1828\n",
      "Iteretation: 1829\n",
      "Iteretation: 1830\n",
      "Iteretation: 1831\n",
      "Iteretation: 1832\n",
      "Iteretation: 1833\n",
      "Iteretation: 1834\n",
      "Iteretation: 1835\n",
      "Iteretation: 1836\n",
      "Iteretation: 1837\n",
      "Iteretation: 1838\n",
      "Iteretation: 1839\n",
      "Iteretation: 1840\n",
      "Iteretation: 1841\n",
      "Iteretation: 1842\n",
      "Iteretation: 1843\n",
      "Iteretation: 1844\n",
      "Iteretation: 1845\n",
      "Iteretation: 1846\n",
      "Iteretation: 1847\n",
      "Iteretation: 1848\n",
      "Iteretation: 1849\n",
      "Iteretation: 1850\n",
      "Iteretation: 1851\n",
      "Iteretation: 1852\n",
      "Iteretation: 1853\n",
      "Iteretation: 1854\n",
      "Iteretation: 1855\n",
      "Iteretation: 1856\n",
      "Iteretation: 1857\n",
      "Iteretation: 1858\n",
      "Iteretation: 1859\n",
      "Iteretation: 1860\n",
      "Iteretation: 1861\n",
      "Iteretation: 1862\n",
      "Iteretation: 1863\n",
      "Iteretation: 1864\n",
      "Iteretation: 1865\n",
      "Iteretation: 1866\n",
      "Iteretation: 1867\n",
      "Iteretation: 1868\n",
      "Iteretation: 1869\n",
      "Iteretation: 1870\n",
      "Iteretation: 1871\n",
      "Iteretation: 1872\n",
      "Iteretation: 1873\n",
      "Iteretation: 1874\n",
      "Iteretation: 1875\n",
      "Iteretation: 1876\n",
      "Iteretation: 1877\n",
      "Iteretation: 1878\n",
      "Iteretation: 1879\n",
      "Iteretation: 1880\n",
      "Iteretation: 1881\n",
      "Iteretation: 1882\n",
      "Iteretation: 1883\n",
      "Iteretation: 1884\n",
      "Iteretation: 1885\n",
      "Iteretation: 1886\n",
      "Iteretation: 1887\n",
      "Iteretation: 1888\n",
      "Iteretation: 1889\n",
      "Iteretation: 1890\n",
      "Iteretation: 1891\n",
      "Iteretation: 1892\n",
      "Iteretation: 1893\n",
      "Iteretation: 1894\n",
      "Iteretation: 1895\n",
      "Iteretation: 1896\n",
      "Iteretation: 1897\n",
      "Iteretation: 1898\n",
      "Iteretation: 1899\n",
      "Iteretation: 1900\n",
      "Iteretation: 1901\n",
      "Iteretation: 1902\n",
      "Iteretation: 1903\n",
      "Iteretation: 1904\n",
      "Iteretation: 1905\n",
      "Iteretation: 1906\n",
      "Iteretation: 1907\n",
      "Iteretation: 1908\n",
      "Iteretation: 1909\n",
      "Iteretation: 1910\n",
      "Iteretation: 1911\n",
      "Iteretation: 1912\n",
      "Iteretation: 1913\n",
      "Iteretation: 1914\n",
      "Iteretation: 1915\n",
      "Iteretation: 1916\n",
      "Iteretation: 1917\n",
      "Iteretation: 1918\n",
      "Iteretation: 1919\n",
      "Iteretation: 1920\n",
      "Iteretation: 1921\n",
      "Iteretation: 1922\n",
      "Iteretation: 1923\n",
      "Iteretation: 1924\n",
      "Iteretation: 1925\n",
      "Iteretation: 1926\n",
      "Iteretation: 1927\n",
      "Iteretation: 1928\n",
      "Iteretation: 1929\n",
      "Iteretation: 1930\n",
      "Iteretation: 1931\n",
      "Iteretation: 1932\n",
      "Iteretation: 1933\n",
      "Iteretation: 1934\n",
      "Iteretation: 1935\n",
      "Iteretation: 1936\n",
      "Iteretation: 1937\n",
      "Iteretation: 1938\n",
      "Iteretation: 1939\n",
      "Iteretation: 1940\n",
      "Iteretation: 1941\n",
      "Iteretation: 1942\n",
      "Iteretation: 1943\n",
      "Iteretation: 1944\n",
      "Iteretation: 1945\n",
      "Iteretation: 1946\n",
      "Iteretation: 1947\n",
      "Iteretation: 1948\n",
      "Iteretation: 1949\n",
      "Iteretation: 1950\n",
      "Iteretation: 1951\n",
      "Iteretation: 1952\n",
      "Iteretation: 1953\n",
      "Iteretation: 1954\n",
      "Iteretation: 1955\n",
      "Iteretation: 1956\n",
      "Iteretation: 1957\n",
      "Iteretation: 1958\n",
      "Iteretation: 1959\n",
      "Iteretation: 1960\n",
      "Iteretation: 1961\n",
      "Iteretation: 1962\n",
      "Iteretation: 1963\n",
      "Iteretation: 1964\n",
      "Iteretation: 1965\n",
      "Iteretation: 1966\n",
      "Iteretation: 1967\n",
      "Iteretation: 1968\n",
      "Iteretation: 1969\n",
      "Iteretation: 1970\n",
      "Iteretation: 1971\n",
      "Iteretation: 1972\n",
      "Iteretation: 1973\n",
      "Iteretation: 1974\n",
      "Iteretation: 1975\n",
      "Iteretation: 1976\n",
      "Iteretation: 1977\n",
      "Iteretation: 1978\n",
      "Iteretation: 1979\n",
      "Iteretation: 1980\n",
      "Iteretation: 1981\n",
      "Iteretation: 1982\n",
      "Iteretation: 1983\n",
      "Iteretation: 1984\n",
      "Iteretation: 1985\n",
      "Iteretation: 1986\n",
      "Iteretation: 1987\n",
      "Iteretation: 1988\n",
      "Iteretation: 1989\n",
      "Iteretation: 1990\n",
      "Iteretation: 1991\n",
      "Iteretation: 1992\n",
      "Iteretation: 1993\n",
      "Iteretation: 1994\n",
      "Iteretation: 1995\n",
      "Iteretation: 1996\n",
      "Iteretation: 1997\n",
      "Iteretation: 1998\n",
      "Iteretation: 1999\n",
      "            Date  SecuritiesCode  Rank\n",
      "0     2021-12-06            1301   842\n",
      "1     2021-12-06            1332   786\n",
      "2     2021-12-06            1333  1285\n",
      "3     2021-12-06            1375  1140\n",
      "4     2021-12-06            1376   582\n",
      "...          ...             ...   ...\n",
      "1995  2021-12-06            9990  1737\n",
      "1996  2021-12-06            9991  1200\n",
      "1997  2021-12-06            9993   356\n",
      "1998  2021-12-06            9994  1105\n",
      "1999  2021-12-06            9997  1463\n",
      "\n",
      "[2000 rows x 3 columns]\n",
      "train_df.head(10):\n",
      "            Section/Products  33SectorName  17SectorName  Universe0  \\\n",
      "Date                                                                  \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-07                 2             6             8          0   \n",
      "2021-12-07                 2             3             3          0   \n",
      "2021-12-07                 0             3             3          0   \n",
      "\n",
      "            MarketCapitalization  SecuritiesCode          RowId    Open  \\\n",
      "Date                                                                      \n",
      "2021-12-07          3.365911e+10            1301  20211207_1301  2998.0   \n",
      "2021-12-07          1.696496e+11            1332  20211207_1332   569.0   \n",
      "2021-12-07          1.266399e+11            1333  20211207_1333  2382.0   \n",
      "2021-12-07          4.773320e+10            1375  20211207_1375  1227.0   \n",
      "2021-12-07          1.770603e+10            1376  20211207_1376  1374.0   \n",
      "2021-12-07          1.557443e+11            1377  20211207_1377  3250.0   \n",
      "2021-12-07          6.364905e+10            1379  20211207_1379  1900.0   \n",
      "2021-12-07          1.820070e+10            1381  20211207_1381  3175.0   \n",
      "2021-12-07          2.637375e+11            1407  20211207_1407  6140.0   \n",
      "2021-12-07          2.976998e+10            1413  20211207_1413  2217.0   \n",
      "\n",
      "              High     Low   Close   Volume  AdjustmentFactor  \\\n",
      "Date                                                            \n",
      "2021-12-07  3065.0  2990.0  3065.0    19100               1.0   \n",
      "2021-12-07   569.0   535.0   556.0  6449200               1.0   \n",
      "2021-12-07  2417.0  2371.0  2409.0   127300               1.0   \n",
      "2021-12-07  1266.0  1227.0  1264.0   128600               1.0   \n",
      "2021-12-07  1395.0  1366.0  1395.0     5800               1.0   \n",
      "2021-12-07  3295.0  3220.0  3285.0    80700               1.0   \n",
      "2021-12-07  1931.0  1893.0  1925.0    72200               1.0   \n",
      "2021-12-07  3185.0  3145.0  3165.0     1000               1.0   \n",
      "2021-12-07  6370.0  6110.0  6340.0   217500               1.0   \n",
      "2021-12-07  2250.0  2204.0  2250.0    11300               1.0   \n",
      "\n",
      "            ExpectedDividend  SupervisionFlag  \n",
      "Date                                           \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "Iteretation: 0\n",
      "Iteretation: 1\n",
      "Iteretation: 2\n",
      "Iteretation: 3\n",
      "Iteretation: 4\n",
      "Iteretation: 5\n",
      "Iteretation: 6\n",
      "Iteretation: 7\n",
      "Iteretation: 8\n",
      "Iteretation: 9\n",
      "Iteretation: 10\n",
      "Iteretation: 11\n",
      "Iteretation: 12\n",
      "Iteretation: 13\n",
      "Iteretation: 14\n",
      "Iteretation: 15\n",
      "Iteretation: 16\n",
      "Iteretation: 17\n",
      "Iteretation: 18\n",
      "Iteretation: 19\n",
      "Iteretation: 20\n",
      "Iteretation: 21\n",
      "Iteretation: 22\n",
      "Iteretation: 23\n",
      "Iteretation: 24\n",
      "Iteretation: 25\n",
      "Iteretation: 26\n",
      "Iteretation: 27\n",
      "Iteretation: 28\n",
      "Iteretation: 29\n",
      "Iteretation: 30\n",
      "Iteretation: 31\n",
      "Iteretation: 32\n",
      "Iteretation: 33\n",
      "Iteretation: 34\n",
      "Iteretation: 35\n",
      "Iteretation: 36\n",
      "Iteretation: 37\n",
      "Iteretation: 38\n",
      "Iteretation: 39\n",
      "Iteretation: 40\n",
      "Iteretation: 41\n",
      "Iteretation: 42\n",
      "Iteretation: 43\n",
      "Iteretation: 44\n",
      "Iteretation: 45\n",
      "Iteretation: 46\n",
      "Iteretation: 47\n",
      "Iteretation: 48\n",
      "Iteretation: 49\n",
      "Iteretation: 50\n",
      "Iteretation: 51\n",
      "Iteretation: 52\n",
      "Iteretation: 53\n",
      "Iteretation: 54\n",
      "Iteretation: 55\n",
      "Iteretation: 56\n",
      "Iteretation: 57\n",
      "Iteretation: 58\n",
      "Iteretation: 59\n",
      "Iteretation: 60\n",
      "Iteretation: 61\n",
      "Iteretation: 62\n",
      "Iteretation: 63\n",
      "Iteretation: 64\n",
      "Iteretation: 65\n",
      "Iteretation: 66\n",
      "Iteretation: 67\n",
      "Iteretation: 68\n",
      "Iteretation: 69\n",
      "Iteretation: 70\n",
      "Iteretation: 71\n",
      "Iteretation: 72\n",
      "Iteretation: 73\n",
      "Iteretation: 74\n",
      "Iteretation: 75\n",
      "Iteretation: 76\n",
      "Iteretation: 77\n",
      "Iteretation: 78\n",
      "Iteretation: 79\n",
      "Iteretation: 80\n",
      "Iteretation: 81\n",
      "Iteretation: 82\n",
      "Iteretation: 83\n",
      "Iteretation: 84\n",
      "Iteretation: 85\n",
      "Iteretation: 86\n",
      "Iteretation: 87\n",
      "Iteretation: 88\n",
      "Iteretation: 89\n",
      "Iteretation: 90\n",
      "Iteretation: 91\n",
      "Iteretation: 92\n",
      "Iteretation: 93\n",
      "Iteretation: 94\n",
      "Iteretation: 95\n",
      "Iteretation: 96\n",
      "Iteretation: 97\n",
      "Iteretation: 98\n",
      "Iteretation: 99\n",
      "Iteretation: 100\n",
      "Iteretation: 101\n",
      "Iteretation: 102\n",
      "Iteretation: 103\n",
      "Iteretation: 104\n",
      "Iteretation: 105\n",
      "Iteretation: 106\n",
      "Iteretation: 107\n",
      "Iteretation: 108\n",
      "Iteretation: 109\n",
      "Iteretation: 110\n",
      "Iteretation: 111\n",
      "Iteretation: 112\n",
      "Iteretation: 113\n",
      "Iteretation: 114\n",
      "Iteretation: 115\n",
      "Iteretation: 116\n",
      "Iteretation: 117\n",
      "Iteretation: 118\n",
      "Iteretation: 119\n",
      "Iteretation: 120\n",
      "Iteretation: 121\n",
      "Iteretation: 122\n",
      "Iteretation: 123\n",
      "Iteretation: 124\n",
      "Iteretation: 125\n",
      "Iteretation: 126\n",
      "Iteretation: 127\n",
      "Iteretation: 128\n",
      "Iteretation: 129\n",
      "Iteretation: 130\n",
      "Iteretation: 131\n",
      "Iteretation: 132\n",
      "Iteretation: 133\n",
      "Iteretation: 134\n",
      "Iteretation: 135\n",
      "Iteretation: 136\n",
      "Iteretation: 137\n",
      "Iteretation: 138\n",
      "Iteretation: 139\n",
      "Iteretation: 140\n",
      "Iteretation: 141\n",
      "Iteretation: 142\n",
      "Iteretation: 143\n",
      "Iteretation: 144\n",
      "Iteretation: 145\n",
      "Iteretation: 146\n",
      "Iteretation: 147\n",
      "Iteretation: 148\n",
      "Iteretation: 149\n",
      "Iteretation: 150\n",
      "Iteretation: 151\n",
      "Iteretation: 152\n",
      "Iteretation: 153\n",
      "Iteretation: 154\n",
      "Iteretation: 155\n",
      "Iteretation: 156\n",
      "Iteretation: 157\n",
      "Iteretation: 158\n",
      "Iteretation: 159\n",
      "Iteretation: 160\n",
      "Iteretation: 161\n",
      "Iteretation: 162\n",
      "Iteretation: 163\n",
      "Iteretation: 164\n",
      "Iteretation: 165\n",
      "Iteretation: 166\n",
      "Iteretation: 167\n",
      "Iteretation: 168\n",
      "Iteretation: 169\n",
      "Iteretation: 170\n",
      "Iteretation: 171\n",
      "Iteretation: 172\n",
      "Iteretation: 173\n",
      "Iteretation: 174\n",
      "Iteretation: 175\n",
      "Iteretation: 176\n",
      "Iteretation: 177\n",
      "Iteretation: 178\n",
      "Iteretation: 179\n",
      "Iteretation: 180\n",
      "Iteretation: 181\n",
      "Iteretation: 182\n",
      "Iteretation: 183\n",
      "Iteretation: 184\n",
      "Iteretation: 185\n",
      "Iteretation: 186\n",
      "Iteretation: 187\n",
      "Iteretation: 188\n",
      "Iteretation: 189\n",
      "Iteretation: 190\n",
      "Iteretation: 191\n",
      "Iteretation: 192\n",
      "Iteretation: 193\n",
      "Iteretation: 194\n",
      "Iteretation: 195\n",
      "Iteretation: 196\n",
      "Iteretation: 197\n",
      "Iteretation: 198\n",
      "Iteretation: 199\n",
      "Iteretation: 200\n",
      "Iteretation: 201\n",
      "Iteretation: 202\n",
      "Iteretation: 203\n",
      "Iteretation: 204\n",
      "Iteretation: 205\n",
      "Iteretation: 206\n",
      "Iteretation: 207\n",
      "Iteretation: 208\n",
      "Iteretation: 209\n",
      "Iteretation: 210\n",
      "Iteretation: 211\n",
      "Iteretation: 212\n",
      "Iteretation: 213\n",
      "Iteretation: 214\n",
      "Iteretation: 215\n",
      "Iteretation: 216\n",
      "Iteretation: 217\n",
      "Iteretation: 218\n",
      "Iteretation: 219\n",
      "Iteretation: 220\n",
      "Iteretation: 221\n",
      "Iteretation: 222\n",
      "Iteretation: 223\n",
      "Iteretation: 224\n",
      "Iteretation: 225\n",
      "Iteretation: 226\n",
      "Iteretation: 227\n",
      "Iteretation: 228\n",
      "Iteretation: 229\n",
      "Iteretation: 230\n",
      "Iteretation: 231\n",
      "Iteretation: 232\n",
      "Iteretation: 233\n",
      "Iteretation: 234\n",
      "Iteretation: 235\n",
      "Iteretation: 236\n",
      "Iteretation: 237\n",
      "Iteretation: 238\n",
      "Iteretation: 239\n",
      "Iteretation: 240\n",
      "Iteretation: 241\n",
      "Iteretation: 242\n",
      "Iteretation: 243\n",
      "Iteretation: 244\n",
      "Iteretation: 245\n",
      "Iteretation: 246\n",
      "Iteretation: 247\n",
      "Iteretation: 248\n",
      "Iteretation: 249\n",
      "Iteretation: 250\n",
      "Iteretation: 251\n",
      "Iteretation: 252\n",
      "Iteretation: 253\n",
      "Iteretation: 254\n",
      "Iteretation: 255\n",
      "Iteretation: 256\n",
      "Iteretation: 257\n",
      "Iteretation: 258\n",
      "Iteretation: 259\n",
      "Iteretation: 260\n",
      "Iteretation: 261\n",
      "Iteretation: 262\n",
      "Iteretation: 263\n",
      "Iteretation: 264\n",
      "Iteretation: 265\n",
      "Iteretation: 266\n",
      "Iteretation: 267\n",
      "Iteretation: 268\n",
      "Iteretation: 269\n",
      "Iteretation: 270\n",
      "Iteretation: 271\n",
      "Iteretation: 272\n",
      "Iteretation: 273\n",
      "Iteretation: 274\n",
      "Iteretation: 275\n",
      "Iteretation: 276\n",
      "Iteretation: 277\n",
      "Iteretation: 278\n",
      "Iteretation: 279\n",
      "Iteretation: 280\n",
      "Iteretation: 281\n",
      "Iteretation: 282\n",
      "Iteretation: 283\n",
      "Iteretation: 284\n",
      "Iteretation: 285\n",
      "Iteretation: 286\n",
      "Iteretation: 287\n",
      "Iteretation: 288\n",
      "Iteretation: 289\n",
      "Iteretation: 290\n",
      "Iteretation: 291\n",
      "Iteretation: 292\n",
      "Iteretation: 293\n",
      "Iteretation: 294\n",
      "Iteretation: 295\n",
      "Iteretation: 296\n",
      "Iteretation: 297\n",
      "Iteretation: 298\n",
      "Iteretation: 299\n",
      "Iteretation: 300\n",
      "Iteretation: 301\n",
      "Iteretation: 302\n",
      "Iteretation: 303\n",
      "Iteretation: 304\n",
      "Iteretation: 305\n",
      "Iteretation: 306\n",
      "Iteretation: 307\n",
      "Iteretation: 308\n",
      "Iteretation: 309\n",
      "Iteretation: 310\n",
      "Iteretation: 311\n",
      "Iteretation: 312\n",
      "Iteretation: 313\n",
      "Iteretation: 314\n",
      "Iteretation: 315\n",
      "Iteretation: 316\n",
      "Iteretation: 317\n",
      "Iteretation: 318\n",
      "Iteretation: 319\n",
      "Iteretation: 320\n",
      "Iteretation: 321\n",
      "Iteretation: 322\n",
      "Iteretation: 323\n",
      "Iteretation: 324\n",
      "Iteretation: 325\n",
      "Iteretation: 326\n",
      "Iteretation: 327\n",
      "Iteretation: 328\n",
      "Iteretation: 329\n",
      "Iteretation: 330\n",
      "Iteretation: 331\n",
      "Iteretation: 332\n",
      "Iteretation: 333\n",
      "Iteretation: 334\n",
      "Iteretation: 335\n",
      "Iteretation: 336\n",
      "Iteretation: 337\n",
      "Iteretation: 338\n",
      "Iteretation: 339\n",
      "Iteretation: 340\n",
      "Iteretation: 341\n",
      "Iteretation: 342\n",
      "Iteretation: 343\n",
      "Iteretation: 344\n",
      "Iteretation: 345\n",
      "Iteretation: 346\n",
      "Iteretation: 347\n",
      "Iteretation: 348\n",
      "Iteretation: 349\n",
      "Iteretation: 350\n",
      "Iteretation: 351\n",
      "Iteretation: 352\n",
      "Iteretation: 353\n",
      "Iteretation: 354\n",
      "Iteretation: 355\n",
      "Iteretation: 356\n",
      "Iteretation: 357\n",
      "Iteretation: 358\n",
      "Iteretation: 359\n",
      "Iteretation: 360\n",
      "Iteretation: 361\n",
      "Iteretation: 362\n",
      "Iteretation: 363\n",
      "Iteretation: 364\n",
      "Iteretation: 365\n",
      "Iteretation: 366\n",
      "Iteretation: 367\n",
      "Iteretation: 368\n",
      "Iteretation: 369\n",
      "Iteretation: 370\n",
      "Iteretation: 371\n",
      "Iteretation: 372\n",
      "Iteretation: 373\n",
      "Iteretation: 374\n",
      "Iteretation: 375\n",
      "Iteretation: 376\n",
      "Iteretation: 377\n",
      "Iteretation: 378\n",
      "Iteretation: 379\n",
      "Iteretation: 380\n",
      "Iteretation: 381\n",
      "Iteretation: 382\n",
      "Iteretation: 383\n",
      "Iteretation: 384\n",
      "Iteretation: 385\n",
      "Iteretation: 386\n",
      "Iteretation: 387\n",
      "Iteretation: 388\n",
      "Iteretation: 389\n",
      "Iteretation: 390\n",
      "Iteretation: 391\n",
      "Iteretation: 392\n",
      "Iteretation: 393\n",
      "Iteretation: 394\n",
      "Iteretation: 395\n",
      "Iteretation: 396\n",
      "Iteretation: 397\n",
      "Iteretation: 398\n",
      "Iteretation: 399\n",
      "Iteretation: 400\n",
      "Iteretation: 401\n",
      "Iteretation: 402\n",
      "Iteretation: 403\n",
      "Iteretation: 404\n",
      "Iteretation: 405\n",
      "Iteretation: 406\n",
      "Iteretation: 407\n",
      "Iteretation: 408\n",
      "Iteretation: 409\n",
      "Iteretation: 410\n",
      "Iteretation: 411\n",
      "Iteretation: 412\n",
      "Iteretation: 413\n",
      "Iteretation: 414\n",
      "Iteretation: 415\n",
      "Iteretation: 416\n",
      "Iteretation: 417\n",
      "Iteretation: 418\n",
      "Iteretation: 419\n",
      "Iteretation: 420\n",
      "Iteretation: 421\n",
      "Iteretation: 422\n",
      "Iteretation: 423\n",
      "Iteretation: 424\n",
      "Iteretation: 425\n",
      "Iteretation: 426\n",
      "Iteretation: 427\n",
      "Iteretation: 428\n",
      "Iteretation: 429\n",
      "Iteretation: 430\n",
      "Iteretation: 431\n",
      "Iteretation: 432\n",
      "Iteretation: 433\n",
      "Iteretation: 434\n",
      "Iteretation: 435\n",
      "Iteretation: 436\n",
      "Iteretation: 437\n",
      "Iteretation: 438\n",
      "Iteretation: 439\n",
      "Iteretation: 440\n",
      "Iteretation: 441\n",
      "Iteretation: 442\n",
      "Iteretation: 443\n",
      "Iteretation: 444\n",
      "Iteretation: 445\n",
      "Iteretation: 446\n",
      "Iteretation: 447\n",
      "Iteretation: 448\n",
      "Iteretation: 449\n",
      "Iteretation: 450\n",
      "Iteretation: 451\n",
      "Iteretation: 452\n",
      "Iteretation: 453\n",
      "Iteretation: 454\n",
      "Iteretation: 455\n",
      "Iteretation: 456\n",
      "Iteretation: 457\n",
      "Iteretation: 458\n",
      "Iteretation: 459\n",
      "Iteretation: 460\n",
      "Iteretation: 461\n",
      "Iteretation: 462\n",
      "Iteretation: 463\n",
      "Iteretation: 464\n",
      "Iteretation: 465\n",
      "Iteretation: 466\n",
      "Iteretation: 467\n",
      "Iteretation: 468\n",
      "Iteretation: 469\n",
      "Iteretation: 470\n",
      "Iteretation: 471\n",
      "Iteretation: 472\n",
      "Iteretation: 473\n",
      "Iteretation: 474\n",
      "Iteretation: 475\n",
      "Iteretation: 476\n",
      "Iteretation: 477\n",
      "Iteretation: 478\n",
      "Iteretation: 479\n",
      "Iteretation: 480\n",
      "Iteretation: 481\n",
      "Iteretation: 482\n",
      "Iteretation: 483\n",
      "Iteretation: 484\n",
      "Iteretation: 485\n",
      "Iteretation: 486\n",
      "Iteretation: 487\n",
      "Iteretation: 488\n",
      "Iteretation: 489\n",
      "Iteretation: 490\n",
      "Iteretation: 491\n",
      "Iteretation: 492\n",
      "Iteretation: 493\n",
      "Iteretation: 494\n",
      "Iteretation: 495\n",
      "Iteretation: 496\n",
      "Iteretation: 497\n",
      "Iteretation: 498\n",
      "Iteretation: 499\n",
      "Iteretation: 500\n",
      "Iteretation: 501\n",
      "Iteretation: 502\n",
      "Iteretation: 503\n",
      "Iteretation: 504\n",
      "Iteretation: 505\n",
      "Iteretation: 506\n",
      "Iteretation: 507\n",
      "Iteretation: 508\n",
      "Iteretation: 509\n",
      "Iteretation: 510\n",
      "Iteretation: 511\n",
      "Iteretation: 512\n",
      "Iteretation: 513\n",
      "Iteretation: 514\n",
      "Iteretation: 515\n",
      "Iteretation: 516\n",
      "Iteretation: 517\n",
      "Iteretation: 518\n",
      "Iteretation: 519\n",
      "Iteretation: 520\n",
      "Iteretation: 521\n",
      "Iteretation: 522\n",
      "Iteretation: 523\n",
      "Iteretation: 524\n",
      "Iteretation: 525\n",
      "Iteretation: 526\n",
      "Iteretation: 527\n",
      "Iteretation: 528\n",
      "Iteretation: 529\n",
      "Iteretation: 530\n",
      "Iteretation: 531\n",
      "Iteretation: 532\n",
      "Iteretation: 533\n",
      "Iteretation: 534\n",
      "Iteretation: 535\n",
      "Iteretation: 536\n",
      "Iteretation: 537\n",
      "Iteretation: 538\n",
      "Iteretation: 539\n",
      "Iteretation: 540\n",
      "Iteretation: 541\n",
      "Iteretation: 542\n",
      "Iteretation: 543\n",
      "Iteretation: 544\n",
      "Iteretation: 545\n",
      "Iteretation: 546\n",
      "Iteretation: 547\n",
      "Iteretation: 548\n",
      "Iteretation: 549\n",
      "Iteretation: 550\n",
      "Iteretation: 551\n",
      "Iteretation: 552\n",
      "Iteretation: 553\n",
      "Iteretation: 554\n",
      "Iteretation: 555\n",
      "Iteretation: 556\n",
      "Iteretation: 557\n",
      "Iteretation: 558\n",
      "Iteretation: 559\n",
      "Iteretation: 560\n",
      "Iteretation: 561\n",
      "Iteretation: 562\n",
      "Iteretation: 563\n",
      "Iteretation: 564\n",
      "Iteretation: 565\n",
      "Iteretation: 566\n",
      "Iteretation: 567\n",
      "Iteretation: 568\n",
      "Iteretation: 569\n",
      "Iteretation: 570\n",
      "Iteretation: 571\n",
      "Iteretation: 572\n",
      "Iteretation: 573\n",
      "Iteretation: 574\n",
      "Iteretation: 575\n",
      "Iteretation: 576\n",
      "Iteretation: 577\n",
      "Iteretation: 578\n",
      "Iteretation: 579\n",
      "Iteretation: 580\n",
      "Iteretation: 581\n",
      "Iteretation: 582\n",
      "Iteretation: 583\n",
      "Iteretation: 584\n",
      "Iteretation: 585\n",
      "Iteretation: 586\n",
      "Iteretation: 587\n",
      "Iteretation: 588\n",
      "Iteretation: 589\n",
      "Iteretation: 590\n",
      "Iteretation: 591\n",
      "Iteretation: 592\n",
      "Iteretation: 593\n",
      "Iteretation: 594\n",
      "Iteretation: 595\n",
      "Iteretation: 596\n",
      "Iteretation: 597\n",
      "Iteretation: 598\n",
      "Iteretation: 599\n",
      "Iteretation: 600\n",
      "Iteretation: 601\n",
      "Iteretation: 602\n",
      "Iteretation: 603\n",
      "Iteretation: 604\n",
      "Iteretation: 605\n",
      "Iteretation: 606\n",
      "Iteretation: 607\n",
      "Iteretation: 608\n",
      "Iteretation: 609\n",
      "Iteretation: 610\n",
      "Iteretation: 611\n",
      "Iteretation: 612\n",
      "Iteretation: 613\n",
      "Iteretation: 614\n",
      "Iteretation: 615\n",
      "Iteretation: 616\n",
      "Iteretation: 617\n",
      "Iteretation: 618\n",
      "Iteretation: 619\n",
      "Iteretation: 620\n",
      "Iteretation: 621\n",
      "Iteretation: 622\n",
      "Iteretation: 623\n",
      "Iteretation: 624\n",
      "Iteretation: 625\n",
      "Iteretation: 626\n",
      "Iteretation: 627\n",
      "Iteretation: 628\n",
      "Iteretation: 629\n",
      "Iteretation: 630\n",
      "Iteretation: 631\n",
      "Iteretation: 632\n",
      "Iteretation: 633\n",
      "Iteretation: 634\n",
      "Iteretation: 635\n",
      "Iteretation: 636\n",
      "Iteretation: 637\n",
      "Iteretation: 638\n",
      "Iteretation: 639\n",
      "Iteretation: 640\n",
      "Iteretation: 641\n",
      "Iteretation: 642\n",
      "Iteretation: 643\n",
      "Iteretation: 644\n",
      "Iteretation: 645\n",
      "Iteretation: 646\n",
      "Iteretation: 647\n",
      "Iteretation: 648\n",
      "Iteretation: 649\n",
      "Iteretation: 650\n",
      "Iteretation: 651\n",
      "Iteretation: 652\n",
      "Iteretation: 653\n",
      "Iteretation: 654\n",
      "Iteretation: 655\n",
      "Iteretation: 656\n",
      "Iteretation: 657\n",
      "Iteretation: 658\n",
      "Iteretation: 659\n",
      "Iteretation: 660\n",
      "Iteretation: 661\n",
      "Iteretation: 662\n",
      "Iteretation: 663\n",
      "Iteretation: 664\n",
      "Iteretation: 665\n",
      "Iteretation: 666\n",
      "Iteretation: 667\n",
      "Iteretation: 668\n",
      "Iteretation: 669\n",
      "Iteretation: 670\n",
      "Iteretation: 671\n",
      "Iteretation: 672\n",
      "Iteretation: 673\n",
      "Iteretation: 674\n",
      "Iteretation: 675\n",
      "Iteretation: 676\n",
      "Iteretation: 677\n",
      "Iteretation: 678\n",
      "Iteretation: 679\n",
      "Iteretation: 680\n",
      "Iteretation: 681\n",
      "Iteretation: 682\n",
      "Iteretation: 683\n",
      "Iteretation: 684\n",
      "Iteretation: 685\n",
      "Iteretation: 686\n",
      "Iteretation: 687\n",
      "Iteretation: 688\n",
      "Iteretation: 689\n",
      "Iteretation: 690\n",
      "Iteretation: 691\n",
      "Iteretation: 692\n",
      "Iteretation: 693\n",
      "Iteretation: 694\n",
      "Iteretation: 695\n",
      "Iteretation: 696\n",
      "Iteretation: 697\n",
      "Iteretation: 698\n",
      "Iteretation: 699\n",
      "Iteretation: 700\n",
      "Iteretation: 701\n",
      "Iteretation: 702\n",
      "Iteretation: 703\n",
      "Iteretation: 704\n",
      "Iteretation: 705\n",
      "Iteretation: 706\n",
      "Iteretation: 707\n",
      "Iteretation: 708\n",
      "Iteretation: 709\n",
      "Iteretation: 710\n",
      "Iteretation: 711\n",
      "Iteretation: 712\n",
      "Iteretation: 713\n",
      "Iteretation: 714\n",
      "Iteretation: 715\n",
      "Iteretation: 716\n",
      "Iteretation: 717\n",
      "Iteretation: 718\n",
      "Iteretation: 719\n",
      "Iteretation: 720\n",
      "Iteretation: 721\n",
      "Iteretation: 722\n",
      "Iteretation: 723\n",
      "Iteretation: 724\n",
      "Iteretation: 725\n",
      "Iteretation: 726\n",
      "Iteretation: 727\n",
      "Iteretation: 728\n",
      "Iteretation: 729\n",
      "Iteretation: 730\n",
      "Iteretation: 731\n",
      "Iteretation: 732\n",
      "Iteretation: 733\n",
      "Iteretation: 734\n",
      "Iteretation: 735\n",
      "Iteretation: 736\n",
      "Iteretation: 737\n",
      "Iteretation: 738\n",
      "Iteretation: 739\n",
      "Iteretation: 740\n",
      "Iteretation: 741\n",
      "Iteretation: 742\n",
      "Iteretation: 743\n",
      "Iteretation: 744\n",
      "Iteretation: 745\n",
      "Iteretation: 746\n",
      "Iteretation: 747\n",
      "Iteretation: 748\n",
      "Iteretation: 749\n",
      "Iteretation: 750\n",
      "Iteretation: 751\n",
      "Iteretation: 752\n",
      "Iteretation: 753\n",
      "Iteretation: 754\n",
      "Iteretation: 755\n",
      "Iteretation: 756\n",
      "Iteretation: 757\n",
      "Iteretation: 758\n",
      "Iteretation: 759\n",
      "Iteretation: 760\n",
      "Iteretation: 761\n",
      "Iteretation: 762\n",
      "Iteretation: 763\n",
      "Iteretation: 764\n",
      "Iteretation: 765\n",
      "Iteretation: 766\n",
      "Iteretation: 767\n",
      "Iteretation: 768\n",
      "Iteretation: 769\n",
      "Iteretation: 770\n",
      "Iteretation: 771\n",
      "Iteretation: 772\n",
      "Iteretation: 773\n",
      "Iteretation: 774\n",
      "Iteretation: 775\n",
      "Iteretation: 776\n",
      "Iteretation: 777\n",
      "Iteretation: 778\n",
      "Iteretation: 779\n",
      "Iteretation: 780\n",
      "Iteretation: 781\n",
      "Iteretation: 782\n",
      "Iteretation: 783\n",
      "Iteretation: 784\n",
      "Iteretation: 785\n",
      "Iteretation: 786\n",
      "Iteretation: 787\n",
      "Iteretation: 788\n",
      "Iteretation: 789\n",
      "Iteretation: 790\n",
      "Iteretation: 791\n",
      "Iteretation: 792\n",
      "Iteretation: 793\n",
      "Iteretation: 794\n",
      "Iteretation: 795\n",
      "Iteretation: 796\n",
      "Iteretation: 797\n",
      "Iteretation: 798\n",
      "Iteretation: 799\n",
      "Iteretation: 800\n",
      "Iteretation: 801\n",
      "Iteretation: 802\n",
      "Iteretation: 803\n",
      "Iteretation: 804\n",
      "Iteretation: 805\n",
      "Iteretation: 806\n",
      "Iteretation: 807\n",
      "Iteretation: 808\n",
      "Iteretation: 809\n",
      "Iteretation: 810\n",
      "Iteretation: 811\n",
      "Iteretation: 812\n",
      "Iteretation: 813\n",
      "Iteretation: 814\n",
      "Iteretation: 815\n",
      "Iteretation: 816\n",
      "Iteretation: 817\n",
      "Iteretation: 818\n",
      "Iteretation: 819\n",
      "Iteretation: 820\n",
      "Iteretation: 821\n",
      "Iteretation: 822\n",
      "Iteretation: 823\n",
      "Iteretation: 824\n",
      "Iteretation: 825\n",
      "Iteretation: 826\n",
      "Iteretation: 827\n",
      "Iteretation: 828\n",
      "Iteretation: 829\n",
      "Iteretation: 830\n",
      "Iteretation: 831\n",
      "Iteretation: 832\n",
      "Iteretation: 833\n",
      "Iteretation: 834\n",
      "Iteretation: 835\n",
      "Iteretation: 836\n",
      "Iteretation: 837\n",
      "Iteretation: 838\n",
      "Iteretation: 839\n",
      "Iteretation: 840\n",
      "Iteretation: 841\n",
      "Iteretation: 842\n",
      "Iteretation: 843\n",
      "Iteretation: 844\n",
      "Iteretation: 845\n",
      "Iteretation: 846\n",
      "Iteretation: 847\n",
      "Iteretation: 848\n",
      "Iteretation: 849\n",
      "Iteretation: 850\n",
      "Iteretation: 851\n",
      "Iteretation: 852\n",
      "Iteretation: 853\n",
      "Iteretation: 854\n",
      "Iteretation: 855\n",
      "Iteretation: 856\n",
      "Iteretation: 857\n",
      "Iteretation: 858\n",
      "Iteretation: 859\n",
      "Iteretation: 860\n",
      "Iteretation: 861\n",
      "Iteretation: 862\n",
      "Iteretation: 863\n",
      "Iteretation: 864\n",
      "Iteretation: 865\n",
      "Iteretation: 866\n",
      "Iteretation: 867\n",
      "Iteretation: 868\n",
      "Iteretation: 869\n",
      "Iteretation: 870\n",
      "Iteretation: 871\n",
      "Iteretation: 872\n",
      "Iteretation: 873\n",
      "Iteretation: 874\n",
      "Iteretation: 875\n",
      "Iteretation: 876\n",
      "Iteretation: 877\n",
      "Iteretation: 878\n",
      "Iteretation: 879\n",
      "Iteretation: 880\n",
      "Iteretation: 881\n",
      "Iteretation: 882\n",
      "Iteretation: 883\n",
      "Iteretation: 884\n",
      "Iteretation: 885\n",
      "Iteretation: 886\n",
      "Iteretation: 887\n",
      "Iteretation: 888\n",
      "Iteretation: 889\n",
      "Iteretation: 890\n",
      "Iteretation: 891\n",
      "Iteretation: 892\n",
      "Iteretation: 893\n",
      "Iteretation: 894\n",
      "Iteretation: 895\n",
      "Iteretation: 896\n",
      "Iteretation: 897\n",
      "Iteretation: 898\n",
      "Iteretation: 899\n",
      "Iteretation: 900\n",
      "Iteretation: 901\n",
      "Iteretation: 902\n",
      "Iteretation: 903\n",
      "Iteretation: 904\n",
      "Iteretation: 905\n",
      "Iteretation: 906\n",
      "Iteretation: 907\n",
      "Iteretation: 908\n",
      "Iteretation: 909\n",
      "Iteretation: 910\n",
      "Iteretation: 911\n",
      "Iteretation: 912\n",
      "Iteretation: 913\n",
      "Iteretation: 914\n",
      "Iteretation: 915\n",
      "Iteretation: 916\n",
      "Iteretation: 917\n",
      "Iteretation: 918\n",
      "Iteretation: 919\n",
      "Iteretation: 920\n",
      "Iteretation: 921\n",
      "Iteretation: 922\n",
      "Iteretation: 923\n",
      "Iteretation: 924\n",
      "Iteretation: 925\n",
      "Iteretation: 926\n",
      "Iteretation: 927\n",
      "Iteretation: 928\n",
      "Iteretation: 929\n",
      "Iteretation: 930\n",
      "Iteretation: 931\n",
      "Iteretation: 932\n",
      "Iteretation: 933\n",
      "Iteretation: 934\n",
      "Iteretation: 935\n",
      "Iteretation: 936\n",
      "Iteretation: 937\n",
      "Iteretation: 938\n",
      "Iteretation: 939\n",
      "Iteretation: 940\n",
      "Iteretation: 941\n",
      "Iteretation: 942\n",
      "Iteretation: 943\n",
      "Iteretation: 944\n",
      "Iteretation: 945\n",
      "Iteretation: 946\n",
      "Iteretation: 947\n",
      "Iteretation: 948\n",
      "Iteretation: 949\n",
      "Iteretation: 950\n",
      "Iteretation: 951\n",
      "Iteretation: 952\n",
      "Iteretation: 953\n",
      "Iteretation: 954\n",
      "Iteretation: 955\n",
      "Iteretation: 956\n",
      "Iteretation: 957\n",
      "Iteretation: 958\n",
      "Iteretation: 959\n",
      "Iteretation: 960\n",
      "Iteretation: 961\n",
      "Iteretation: 962\n",
      "Iteretation: 963\n",
      "Iteretation: 964\n",
      "Iteretation: 965\n",
      "Iteretation: 966\n",
      "Iteretation: 967\n",
      "Iteretation: 968\n",
      "Iteretation: 969\n",
      "Iteretation: 970\n",
      "Iteretation: 971\n",
      "Iteretation: 972\n",
      "Iteretation: 973\n",
      "Iteretation: 974\n",
      "Iteretation: 975\n",
      "Iteretation: 976\n",
      "Iteretation: 977\n",
      "Iteretation: 978\n",
      "Iteretation: 979\n",
      "Iteretation: 980\n",
      "Iteretation: 981\n",
      "Iteretation: 982\n",
      "Iteretation: 983\n",
      "Iteretation: 984\n",
      "Iteretation: 985\n",
      "Iteretation: 986\n",
      "Iteretation: 987\n",
      "Iteretation: 988\n",
      "Iteretation: 989\n",
      "Iteretation: 990\n",
      "Iteretation: 991\n",
      "Iteretation: 992\n",
      "Iteretation: 993\n",
      "Iteretation: 994\n",
      "Iteretation: 995\n",
      "Iteretation: 996\n",
      "Iteretation: 997\n",
      "Iteretation: 998\n",
      "Iteretation: 999\n",
      "Iteretation: 1000\n",
      "Iteretation: 1001\n",
      "Iteretation: 1002\n",
      "Iteretation: 1003\n",
      "Iteretation: 1004\n",
      "Iteretation: 1005\n",
      "Iteretation: 1006\n",
      "Iteretation: 1007\n",
      "Iteretation: 1008\n",
      "Iteretation: 1009\n",
      "Iteretation: 1010\n",
      "Iteretation: 1011\n",
      "Iteretation: 1012\n",
      "Iteretation: 1013\n",
      "Iteretation: 1014\n",
      "Iteretation: 1015\n",
      "Iteretation: 1016\n",
      "Iteretation: 1017\n",
      "Iteretation: 1018\n",
      "Iteretation: 1019\n",
      "Iteretation: 1020\n",
      "Iteretation: 1021\n",
      "Iteretation: 1022\n",
      "Iteretation: 1023\n",
      "Iteretation: 1024\n",
      "Iteretation: 1025\n",
      "Iteretation: 1026\n",
      "Iteretation: 1027\n",
      "Iteretation: 1028\n",
      "Iteretation: 1029\n",
      "Iteretation: 1030\n",
      "Iteretation: 1031\n",
      "Iteretation: 1032\n",
      "Iteretation: 1033\n",
      "Iteretation: 1034\n",
      "Iteretation: 1035\n",
      "Iteretation: 1036\n",
      "Iteretation: 1037\n",
      "Iteretation: 1038\n",
      "Iteretation: 1039\n",
      "Iteretation: 1040\n",
      "Iteretation: 1041\n",
      "Iteretation: 1042\n",
      "Iteretation: 1043\n",
      "Iteretation: 1044\n",
      "Iteretation: 1045\n",
      "Iteretation: 1046\n",
      "Iteretation: 1047\n",
      "Iteretation: 1048\n",
      "Iteretation: 1049\n",
      "Iteretation: 1050\n",
      "Iteretation: 1051\n",
      "Iteretation: 1052\n",
      "Iteretation: 1053\n",
      "Iteretation: 1054\n",
      "Iteretation: 1055\n",
      "Iteretation: 1056\n",
      "Iteretation: 1057\n",
      "Iteretation: 1058\n",
      "Iteretation: 1059\n",
      "Iteretation: 1060\n",
      "Iteretation: 1061\n",
      "Iteretation: 1062\n",
      "Iteretation: 1063\n",
      "Iteretation: 1064\n",
      "Iteretation: 1065\n",
      "Iteretation: 1066\n",
      "Iteretation: 1067\n",
      "Iteretation: 1068\n",
      "Iteretation: 1069\n",
      "Iteretation: 1070\n",
      "Iteretation: 1071\n",
      "Iteretation: 1072\n",
      "Iteretation: 1073\n",
      "Iteretation: 1074\n",
      "Iteretation: 1075\n",
      "Iteretation: 1076\n",
      "Iteretation: 1077\n",
      "Iteretation: 1078\n",
      "Iteretation: 1079\n",
      "Iteretation: 1080\n",
      "Iteretation: 1081\n",
      "Iteretation: 1082\n",
      "Iteretation: 1083\n",
      "Iteretation: 1084\n",
      "Iteretation: 1085\n",
      "Iteretation: 1086\n",
      "Iteretation: 1087\n",
      "Iteretation: 1088\n",
      "Iteretation: 1089\n",
      "Iteretation: 1090\n",
      "Iteretation: 1091\n",
      "Iteretation: 1092\n",
      "Iteretation: 1093\n",
      "Iteretation: 1094\n",
      "Iteretation: 1095\n",
      "Iteretation: 1096\n",
      "Iteretation: 1097\n",
      "Iteretation: 1098\n",
      "Iteretation: 1099\n",
      "Iteretation: 1100\n",
      "Iteretation: 1101\n",
      "Iteretation: 1102\n",
      "Iteretation: 1103\n",
      "Iteretation: 1104\n",
      "Iteretation: 1105\n",
      "Iteretation: 1106\n",
      "Iteretation: 1107\n",
      "Iteretation: 1108\n",
      "Iteretation: 1109\n",
      "Iteretation: 1110\n",
      "Iteretation: 1111\n",
      "Iteretation: 1112\n",
      "Iteretation: 1113\n",
      "Iteretation: 1114\n",
      "Iteretation: 1115\n",
      "Iteretation: 1116\n",
      "Iteretation: 1117\n",
      "Iteretation: 1118\n",
      "Iteretation: 1119\n",
      "Iteretation: 1120\n",
      "Iteretation: 1121\n",
      "Iteretation: 1122\n",
      "Iteretation: 1123\n",
      "Iteretation: 1124\n",
      "Iteretation: 1125\n",
      "Iteretation: 1126\n",
      "Iteretation: 1127\n",
      "Iteretation: 1128\n",
      "Iteretation: 1129\n",
      "Iteretation: 1130\n",
      "Iteretation: 1131\n",
      "Iteretation: 1132\n",
      "Iteretation: 1133\n",
      "Iteretation: 1134\n",
      "Iteretation: 1135\n",
      "Iteretation: 1136\n",
      "Iteretation: 1137\n",
      "Iteretation: 1138\n",
      "Iteretation: 1139\n",
      "Iteretation: 1140\n",
      "Iteretation: 1141\n",
      "Iteretation: 1142\n",
      "Iteretation: 1143\n",
      "Iteretation: 1144\n",
      "Iteretation: 1145\n",
      "Iteretation: 1146\n",
      "Iteretation: 1147\n",
      "Iteretation: 1148\n",
      "Iteretation: 1149\n",
      "Iteretation: 1150\n",
      "Iteretation: 1151\n",
      "Iteretation: 1152\n",
      "Iteretation: 1153\n",
      "Iteretation: 1154\n",
      "Iteretation: 1155\n",
      "Iteretation: 1156\n",
      "Iteretation: 1157\n",
      "Iteretation: 1158\n",
      "Iteretation: 1159\n",
      "Iteretation: 1160\n",
      "Iteretation: 1161\n",
      "Iteretation: 1162\n",
      "Iteretation: 1163\n",
      "Iteretation: 1164\n",
      "Iteretation: 1165\n",
      "Iteretation: 1166\n",
      "Iteretation: 1167\n",
      "Iteretation: 1168\n",
      "Iteretation: 1169\n",
      "Iteretation: 1170\n",
      "Iteretation: 1171\n",
      "Iteretation: 1172\n",
      "Iteretation: 1173\n",
      "Iteretation: 1174\n",
      "Iteretation: 1175\n",
      "Iteretation: 1176\n",
      "Iteretation: 1177\n",
      "Iteretation: 1178\n",
      "Iteretation: 1179\n",
      "Iteretation: 1180\n",
      "Iteretation: 1181\n",
      "Iteretation: 1182\n",
      "Iteretation: 1183\n",
      "Iteretation: 1184\n",
      "Iteretation: 1185\n",
      "Iteretation: 1186\n",
      "Iteretation: 1187\n",
      "Iteretation: 1188\n",
      "Iteretation: 1189\n",
      "Iteretation: 1190\n",
      "Iteretation: 1191\n",
      "Iteretation: 1192\n",
      "Iteretation: 1193\n",
      "Iteretation: 1194\n",
      "Iteretation: 1195\n",
      "Iteretation: 1196\n",
      "Iteretation: 1197\n",
      "Iteretation: 1198\n",
      "Iteretation: 1199\n",
      "Iteretation: 1200\n",
      "Iteretation: 1201\n",
      "Iteretation: 1202\n",
      "Iteretation: 1203\n",
      "Iteretation: 1204\n",
      "Iteretation: 1205\n",
      "Iteretation: 1206\n",
      "Iteretation: 1207\n",
      "Iteretation: 1208\n",
      "Iteretation: 1209\n",
      "Iteretation: 1210\n",
      "Iteretation: 1211\n",
      "Iteretation: 1212\n",
      "Iteretation: 1213\n",
      "Iteretation: 1214\n",
      "Iteretation: 1215\n",
      "Iteretation: 1216\n",
      "Iteretation: 1217\n",
      "Iteretation: 1218\n",
      "Iteretation: 1219\n",
      "Iteretation: 1220\n",
      "Iteretation: 1221\n",
      "Iteretation: 1222\n",
      "Iteretation: 1223\n",
      "Iteretation: 1224\n",
      "Iteretation: 1225\n",
      "Iteretation: 1226\n",
      "Iteretation: 1227\n",
      "Iteretation: 1228\n",
      "Iteretation: 1229\n",
      "Iteretation: 1230\n",
      "Iteretation: 1231\n",
      "Iteretation: 1232\n",
      "Iteretation: 1233\n",
      "Iteretation: 1234\n",
      "Iteretation: 1235\n",
      "Iteretation: 1236\n",
      "Iteretation: 1237\n",
      "Iteretation: 1238\n",
      "Iteretation: 1239\n",
      "Iteretation: 1240\n",
      "Iteretation: 1241\n",
      "Iteretation: 1242\n",
      "Iteretation: 1243\n",
      "Iteretation: 1244\n",
      "Iteretation: 1245\n",
      "Iteretation: 1246\n",
      "Iteretation: 1247\n",
      "Iteretation: 1248\n",
      "Iteretation: 1249\n",
      "Iteretation: 1250\n",
      "Iteretation: 1251\n",
      "Iteretation: 1252\n",
      "Iteretation: 1253\n",
      "Iteretation: 1254\n",
      "Iteretation: 1255\n",
      "Iteretation: 1256\n",
      "Iteretation: 1257\n",
      "Iteretation: 1258\n",
      "Iteretation: 1259\n",
      "Iteretation: 1260\n",
      "Iteretation: 1261\n",
      "Iteretation: 1262\n",
      "Iteretation: 1263\n",
      "Iteretation: 1264\n",
      "Iteretation: 1265\n",
      "Iteretation: 1266\n",
      "Iteretation: 1267\n",
      "Iteretation: 1268\n",
      "Iteretation: 1269\n",
      "Iteretation: 1270\n",
      "Iteretation: 1271\n",
      "Iteretation: 1272\n",
      "Iteretation: 1273\n",
      "Iteretation: 1274\n",
      "Iteretation: 1275\n",
      "Iteretation: 1276\n",
      "Iteretation: 1277\n",
      "Iteretation: 1278\n",
      "Iteretation: 1279\n",
      "Iteretation: 1280\n",
      "Iteretation: 1281\n",
      "Iteretation: 1282\n",
      "Iteretation: 1283\n",
      "Iteretation: 1284\n",
      "Iteretation: 1285\n",
      "Iteretation: 1286\n",
      "Iteretation: 1287\n",
      "Iteretation: 1288\n",
      "Iteretation: 1289\n",
      "Iteretation: 1290\n",
      "Iteretation: 1291\n",
      "Iteretation: 1292\n",
      "Iteretation: 1293\n",
      "Iteretation: 1294\n",
      "Iteretation: 1295\n",
      "Iteretation: 1296\n",
      "Iteretation: 1297\n",
      "Iteretation: 1298\n",
      "Iteretation: 1299\n",
      "Iteretation: 1300\n",
      "Iteretation: 1301\n",
      "Iteretation: 1302\n",
      "Iteretation: 1303\n",
      "Iteretation: 1304\n",
      "Iteretation: 1305\n",
      "Iteretation: 1306\n",
      "Iteretation: 1307\n",
      "Iteretation: 1308\n",
      "Iteretation: 1309\n",
      "Iteretation: 1310\n",
      "Iteretation: 1311\n",
      "Iteretation: 1312\n",
      "Iteretation: 1313\n",
      "Iteretation: 1314\n",
      "Iteretation: 1315\n",
      "Iteretation: 1316\n",
      "Iteretation: 1317\n",
      "Iteretation: 1318\n",
      "Iteretation: 1319\n",
      "Iteretation: 1320\n",
      "Iteretation: 1321\n",
      "Iteretation: 1322\n",
      "Iteretation: 1323\n",
      "Iteretation: 1324\n",
      "Iteretation: 1325\n",
      "Iteretation: 1326\n",
      "Iteretation: 1327\n",
      "Iteretation: 1328\n",
      "Iteretation: 1329\n",
      "Iteretation: 1330\n",
      "Iteretation: 1331\n",
      "Iteretation: 1332\n",
      "Iteretation: 1333\n",
      "Iteretation: 1334\n",
      "Iteretation: 1335\n",
      "Iteretation: 1336\n",
      "Iteretation: 1337\n",
      "Iteretation: 1338\n",
      "Iteretation: 1339\n",
      "Iteretation: 1340\n",
      "Iteretation: 1341\n",
      "Iteretation: 1342\n",
      "Iteretation: 1343\n",
      "Iteretation: 1344\n",
      "Iteretation: 1345\n",
      "Iteretation: 1346\n",
      "Iteretation: 1347\n",
      "Iteretation: 1348\n",
      "Iteretation: 1349\n",
      "Iteretation: 1350\n",
      "Iteretation: 1351\n",
      "Iteretation: 1352\n",
      "Iteretation: 1353\n",
      "Iteretation: 1354\n",
      "Iteretation: 1355\n",
      "Iteretation: 1356\n",
      "Iteretation: 1357\n",
      "Iteretation: 1358\n",
      "Iteretation: 1359\n",
      "Iteretation: 1360\n",
      "Iteretation: 1361\n",
      "Iteretation: 1362\n",
      "Iteretation: 1363\n",
      "Iteretation: 1364\n",
      "Iteretation: 1365\n",
      "Iteretation: 1366\n",
      "Iteretation: 1367\n",
      "Iteretation: 1368\n",
      "Iteretation: 1369\n",
      "Iteretation: 1370\n",
      "Iteretation: 1371\n",
      "Iteretation: 1372\n",
      "Iteretation: 1373\n",
      "Iteretation: 1374\n",
      "Iteretation: 1375\n",
      "Iteretation: 1376\n",
      "Iteretation: 1377\n",
      "Iteretation: 1378\n",
      "Iteretation: 1379\n",
      "Iteretation: 1380\n",
      "Iteretation: 1381\n",
      "Iteretation: 1382\n",
      "Iteretation: 1383\n",
      "Iteretation: 1384\n",
      "Iteretation: 1385\n",
      "Iteretation: 1386\n",
      "Iteretation: 1387\n",
      "Iteretation: 1388\n",
      "Iteretation: 1389\n",
      "Iteretation: 1390\n",
      "Iteretation: 1391\n",
      "Iteretation: 1392\n",
      "Iteretation: 1393\n",
      "Iteretation: 1394\n",
      "Iteretation: 1395\n",
      "Iteretation: 1396\n",
      "Iteretation: 1397\n",
      "Iteretation: 1398\n",
      "Iteretation: 1399\n",
      "Iteretation: 1400\n",
      "Iteretation: 1401\n",
      "Iteretation: 1402\n",
      "Iteretation: 1403\n",
      "Iteretation: 1404\n",
      "Iteretation: 1405\n",
      "Iteretation: 1406\n",
      "Iteretation: 1407\n",
      "Iteretation: 1408\n",
      "Iteretation: 1409\n",
      "Iteretation: 1410\n",
      "Iteretation: 1411\n",
      "Iteretation: 1412\n",
      "Iteretation: 1413\n",
      "Iteretation: 1414\n",
      "Iteretation: 1415\n",
      "Iteretation: 1416\n",
      "Iteretation: 1417\n",
      "Iteretation: 1418\n",
      "Iteretation: 1419\n",
      "Iteretation: 1420\n",
      "Iteretation: 1421\n",
      "Iteretation: 1422\n",
      "Iteretation: 1423\n",
      "Iteretation: 1424\n",
      "Iteretation: 1425\n",
      "Iteretation: 1426\n",
      "Iteretation: 1427\n",
      "Iteretation: 1428\n",
      "Iteretation: 1429\n",
      "Iteretation: 1430\n",
      "Iteretation: 1431\n",
      "Iteretation: 1432\n",
      "Iteretation: 1433\n",
      "Iteretation: 1434\n",
      "Iteretation: 1435\n",
      "Iteretation: 1436\n",
      "Iteretation: 1437\n",
      "Iteretation: 1438\n",
      "Iteretation: 1439\n",
      "Iteretation: 1440\n",
      "Iteretation: 1441\n",
      "Iteretation: 1442\n",
      "Iteretation: 1443\n",
      "Iteretation: 1444\n",
      "Iteretation: 1445\n",
      "Iteretation: 1446\n",
      "Iteretation: 1447\n",
      "Iteretation: 1448\n",
      "Iteretation: 1449\n",
      "Iteretation: 1450\n",
      "Iteretation: 1451\n",
      "Iteretation: 1452\n",
      "Iteretation: 1453\n",
      "Iteretation: 1454\n",
      "Iteretation: 1455\n",
      "Iteretation: 1456\n",
      "Iteretation: 1457\n",
      "Iteretation: 1458\n",
      "Iteretation: 1459\n",
      "Iteretation: 1460\n",
      "Iteretation: 1461\n",
      "Iteretation: 1462\n",
      "Iteretation: 1463\n",
      "Iteretation: 1464\n",
      "Iteretation: 1465\n",
      "Iteretation: 1466\n",
      "Iteretation: 1467\n",
      "Iteretation: 1468\n",
      "Iteretation: 1469\n",
      "Iteretation: 1470\n",
      "Iteretation: 1471\n",
      "Iteretation: 1472\n",
      "Iteretation: 1473\n",
      "Iteretation: 1474\n",
      "Iteretation: 1475\n",
      "Iteretation: 1476\n",
      "Iteretation: 1477\n",
      "Iteretation: 1478\n",
      "Iteretation: 1479\n",
      "Iteretation: 1480\n",
      "Iteretation: 1481\n",
      "Iteretation: 1482\n",
      "Iteretation: 1483\n",
      "Iteretation: 1484\n",
      "Iteretation: 1485\n",
      "Iteretation: 1486\n",
      "Iteretation: 1487\n",
      "Iteretation: 1488\n",
      "Iteretation: 1489\n",
      "Iteretation: 1490\n",
      "Iteretation: 1491\n",
      "Iteretation: 1492\n",
      "Iteretation: 1493\n",
      "Iteretation: 1494\n",
      "Iteretation: 1495\n",
      "Iteretation: 1496\n",
      "Iteretation: 1497\n",
      "Iteretation: 1498\n",
      "Iteretation: 1499\n",
      "Iteretation: 1500\n",
      "Iteretation: 1501\n",
      "Iteretation: 1502\n",
      "Iteretation: 1503\n",
      "Iteretation: 1504\n",
      "Iteretation: 1505\n",
      "Iteretation: 1506\n",
      "Iteretation: 1507\n",
      "Iteretation: 1508\n",
      "Iteretation: 1509\n",
      "Iteretation: 1510\n",
      "Iteretation: 1511\n",
      "Iteretation: 1512\n",
      "Iteretation: 1513\n",
      "Iteretation: 1514\n",
      "Iteretation: 1515\n",
      "Iteretation: 1516\n",
      "Iteretation: 1517\n",
      "Iteretation: 1518\n",
      "Iteretation: 1519\n",
      "Iteretation: 1520\n",
      "Iteretation: 1521\n",
      "Iteretation: 1522\n",
      "Iteretation: 1523\n",
      "Iteretation: 1524\n",
      "Iteretation: 1525\n",
      "Iteretation: 1526\n",
      "Iteretation: 1527\n",
      "Iteretation: 1528\n",
      "Iteretation: 1529\n",
      "Iteretation: 1530\n",
      "Iteretation: 1531\n",
      "Iteretation: 1532\n",
      "Iteretation: 1533\n",
      "Iteretation: 1534\n",
      "Iteretation: 1535\n",
      "Iteretation: 1536\n",
      "Iteretation: 1537\n",
      "Iteretation: 1538\n",
      "Iteretation: 1539\n",
      "Iteretation: 1540\n",
      "Iteretation: 1541\n",
      "Iteretation: 1542\n",
      "Iteretation: 1543\n",
      "Iteretation: 1544\n",
      "Iteretation: 1545\n",
      "Iteretation: 1546\n",
      "Iteretation: 1547\n",
      "Iteretation: 1548\n",
      "Iteretation: 1549\n",
      "Iteretation: 1550\n",
      "Iteretation: 1551\n",
      "Iteretation: 1552\n",
      "Iteretation: 1553\n",
      "Iteretation: 1554\n",
      "Iteretation: 1555\n",
      "Iteretation: 1556\n",
      "Iteretation: 1557\n",
      "Iteretation: 1558\n",
      "Iteretation: 1559\n",
      "Iteretation: 1560\n",
      "Iteretation: 1561\n",
      "Iteretation: 1562\n",
      "Iteretation: 1563\n",
      "Iteretation: 1564\n",
      "Iteretation: 1565\n",
      "Iteretation: 1566\n",
      "Iteretation: 1567\n",
      "Iteretation: 1568\n",
      "Iteretation: 1569\n",
      "Iteretation: 1570\n",
      "Iteretation: 1571\n",
      "Iteretation: 1572\n",
      "Iteretation: 1573\n",
      "Iteretation: 1574\n",
      "Iteretation: 1575\n",
      "Iteretation: 1576\n",
      "Iteretation: 1577\n",
      "Iteretation: 1578\n",
      "Iteretation: 1579\n",
      "Iteretation: 1580\n",
      "Iteretation: 1581\n",
      "Iteretation: 1582\n",
      "Iteretation: 1583\n",
      "Iteretation: 1584\n",
      "Iteretation: 1585\n",
      "Iteretation: 1586\n",
      "Iteretation: 1587\n",
      "Iteretation: 1588\n",
      "Iteretation: 1589\n",
      "Iteretation: 1590\n",
      "Iteretation: 1591\n",
      "Iteretation: 1592\n",
      "Iteretation: 1593\n",
      "Iteretation: 1594\n",
      "Iteretation: 1595\n",
      "Iteretation: 1596\n",
      "Iteretation: 1597\n",
      "Iteretation: 1598\n",
      "Iteretation: 1599\n",
      "Iteretation: 1600\n",
      "Iteretation: 1601\n",
      "Iteretation: 1602\n",
      "Iteretation: 1603\n",
      "Iteretation: 1604\n",
      "Iteretation: 1605\n",
      "Iteretation: 1606\n",
      "Iteretation: 1607\n",
      "Iteretation: 1608\n",
      "Iteretation: 1609\n",
      "Iteretation: 1610\n",
      "Iteretation: 1611\n",
      "Iteretation: 1612\n",
      "Iteretation: 1613\n",
      "Iteretation: 1614\n",
      "Iteretation: 1615\n",
      "Iteretation: 1616\n",
      "Iteretation: 1617\n",
      "Iteretation: 1618\n",
      "Iteretation: 1619\n",
      "Iteretation: 1620\n",
      "Iteretation: 1621\n",
      "Iteretation: 1622\n",
      "Iteretation: 1623\n",
      "Iteretation: 1624\n",
      "Iteretation: 1625\n",
      "Iteretation: 1626\n",
      "Iteretation: 1627\n",
      "Iteretation: 1628\n",
      "Iteretation: 1629\n",
      "Iteretation: 1630\n",
      "Iteretation: 1631\n",
      "Iteretation: 1632\n",
      "Iteretation: 1633\n",
      "Iteretation: 1634\n",
      "Iteretation: 1635\n",
      "Iteretation: 1636\n",
      "Iteretation: 1637\n",
      "Iteretation: 1638\n",
      "Iteretation: 1639\n",
      "Iteretation: 1640\n",
      "Iteretation: 1641\n",
      "Iteretation: 1642\n",
      "Iteretation: 1643\n",
      "Iteretation: 1644\n",
      "Iteretation: 1645\n",
      "Iteretation: 1646\n",
      "Iteretation: 1647\n",
      "Iteretation: 1648\n",
      "Iteretation: 1649\n",
      "Iteretation: 1650\n",
      "Iteretation: 1651\n",
      "Iteretation: 1652\n",
      "Iteretation: 1653\n",
      "Iteretation: 1654\n",
      "Iteretation: 1655\n",
      "Iteretation: 1656\n",
      "Iteretation: 1657\n",
      "Iteretation: 1658\n",
      "Iteretation: 1659\n",
      "Iteretation: 1660\n",
      "Iteretation: 1661\n",
      "Iteretation: 1662\n",
      "Iteretation: 1663\n",
      "Iteretation: 1664\n",
      "Iteretation: 1665\n",
      "Iteretation: 1666\n",
      "Iteretation: 1667\n",
      "Iteretation: 1668\n",
      "Iteretation: 1669\n",
      "Iteretation: 1670\n",
      "Iteretation: 1671\n",
      "Iteretation: 1672\n",
      "Iteretation: 1673\n",
      "Iteretation: 1674\n",
      "Iteretation: 1675\n",
      "Iteretation: 1676\n",
      "Iteretation: 1677\n",
      "Iteretation: 1678\n",
      "Iteretation: 1679\n",
      "Iteretation: 1680\n",
      "Iteretation: 1681\n",
      "Iteretation: 1682\n",
      "Iteretation: 1683\n",
      "Iteretation: 1684\n",
      "Iteretation: 1685\n",
      "Iteretation: 1686\n",
      "Iteretation: 1687\n",
      "Iteretation: 1688\n",
      "Iteretation: 1689\n",
      "Iteretation: 1690\n",
      "Iteretation: 1691\n",
      "Iteretation: 1692\n",
      "Iteretation: 1693\n",
      "Iteretation: 1694\n",
      "Iteretation: 1695\n",
      "Iteretation: 1696\n",
      "Iteretation: 1697\n",
      "Iteretation: 1698\n",
      "Iteretation: 1699\n",
      "Iteretation: 1700\n",
      "Iteretation: 1701\n",
      "Iteretation: 1702\n",
      "Iteretation: 1703\n",
      "Iteretation: 1704\n",
      "Iteretation: 1705\n",
      "Iteretation: 1706\n",
      "Iteretation: 1707\n",
      "Iteretation: 1708\n",
      "Iteretation: 1709\n",
      "Iteretation: 1710\n",
      "Iteretation: 1711\n",
      "Iteretation: 1712\n",
      "Iteretation: 1713\n",
      "Iteretation: 1714\n",
      "Iteretation: 1715\n",
      "Iteretation: 1716\n",
      "Iteretation: 1717\n",
      "Iteretation: 1718\n",
      "Iteretation: 1719\n",
      "Iteretation: 1720\n",
      "Iteretation: 1721\n",
      "Iteretation: 1722\n",
      "Iteretation: 1723\n",
      "Iteretation: 1724\n",
      "Iteretation: 1725\n",
      "Iteretation: 1726\n",
      "Iteretation: 1727\n",
      "Iteretation: 1728\n",
      "Iteretation: 1729\n",
      "Iteretation: 1730\n",
      "Iteretation: 1731\n",
      "Iteretation: 1732\n",
      "Iteretation: 1733\n",
      "Iteretation: 1734\n",
      "Iteretation: 1735\n",
      "Iteretation: 1736\n",
      "Iteretation: 1737\n",
      "Iteretation: 1738\n",
      "Iteretation: 1739\n",
      "Iteretation: 1740\n",
      "Iteretation: 1741\n",
      "Iteretation: 1742\n",
      "Iteretation: 1743\n",
      "Iteretation: 1744\n",
      "Iteretation: 1745\n",
      "Iteretation: 1746\n",
      "Iteretation: 1747\n",
      "Iteretation: 1748\n",
      "Iteretation: 1749\n",
      "Iteretation: 1750\n",
      "Iteretation: 1751\n",
      "Iteretation: 1752\n",
      "Iteretation: 1753\n",
      "Iteretation: 1754\n",
      "Iteretation: 1755\n",
      "Iteretation: 1756\n",
      "Iteretation: 1757\n",
      "Iteretation: 1758\n",
      "Iteretation: 1759\n",
      "Iteretation: 1760\n",
      "Iteretation: 1761\n",
      "Iteretation: 1762\n",
      "Iteretation: 1763\n",
      "Iteretation: 1764\n",
      "Iteretation: 1765\n",
      "Iteretation: 1766\n",
      "Iteretation: 1767\n",
      "Iteretation: 1768\n",
      "Iteretation: 1769\n",
      "Iteretation: 1770\n",
      "Iteretation: 1771\n",
      "Iteretation: 1772\n",
      "Iteretation: 1773\n",
      "Iteretation: 1774\n",
      "Iteretation: 1775\n",
      "Iteretation: 1776\n",
      "Iteretation: 1777\n",
      "Iteretation: 1778\n",
      "Iteretation: 1779\n",
      "Iteretation: 1780\n",
      "Iteretation: 1781\n",
      "Iteretation: 1782\n",
      "Iteretation: 1783\n",
      "Iteretation: 1784\n",
      "Iteretation: 1785\n",
      "Iteretation: 1786\n",
      "Iteretation: 1787\n",
      "Iteretation: 1788\n",
      "Iteretation: 1789\n",
      "Iteretation: 1790\n",
      "Iteretation: 1791\n",
      "Iteretation: 1792\n",
      "Iteretation: 1793\n",
      "Iteretation: 1794\n",
      "Iteretation: 1795\n",
      "Iteretation: 1796\n",
      "Iteretation: 1797\n",
      "Iteretation: 1798\n",
      "Iteretation: 1799\n",
      "Iteretation: 1800\n",
      "Iteretation: 1801\n",
      "Iteretation: 1802\n",
      "Iteretation: 1803\n",
      "Iteretation: 1804\n",
      "Iteretation: 1805\n",
      "Iteretation: 1806\n",
      "Iteretation: 1807\n",
      "Iteretation: 1808\n",
      "Iteretation: 1809\n",
      "Iteretation: 1810\n",
      "Iteretation: 1811\n",
      "Iteretation: 1812\n",
      "Iteretation: 1813\n",
      "Iteretation: 1814\n",
      "Iteretation: 1815\n",
      "Iteretation: 1816\n",
      "Iteretation: 1817\n",
      "Iteretation: 1818\n",
      "Iteretation: 1819\n",
      "Iteretation: 1820\n",
      "Iteretation: 1821\n",
      "Iteretation: 1822\n",
      "Iteretation: 1823\n",
      "Iteretation: 1824\n",
      "Iteretation: 1825\n",
      "Iteretation: 1826\n",
      "Iteretation: 1827\n",
      "Iteretation: 1828\n",
      "Iteretation: 1829\n",
      "Iteretation: 1830\n",
      "Iteretation: 1831\n",
      "Iteretation: 1832\n",
      "Iteretation: 1833\n",
      "Iteretation: 1834\n",
      "Iteretation: 1835\n",
      "Iteretation: 1836\n",
      "Iteretation: 1837\n",
      "Iteretation: 1838\n",
      "Iteretation: 1839\n",
      "Iteretation: 1840\n",
      "Iteretation: 1841\n",
      "Iteretation: 1842\n",
      "Iteretation: 1843\n",
      "Iteretation: 1844\n",
      "Iteretation: 1845\n",
      "Iteretation: 1846\n",
      "Iteretation: 1847\n",
      "Iteretation: 1848\n",
      "Iteretation: 1849\n",
      "Iteretation: 1850\n",
      "Iteretation: 1851\n",
      "Iteretation: 1852\n",
      "Iteretation: 1853\n",
      "Iteretation: 1854\n",
      "Iteretation: 1855\n",
      "Iteretation: 1856\n",
      "Iteretation: 1857\n",
      "Iteretation: 1858\n",
      "Iteretation: 1859\n",
      "Iteretation: 1860\n",
      "Iteretation: 1861\n",
      "Iteretation: 1862\n",
      "Iteretation: 1863\n",
      "Iteretation: 1864\n",
      "Iteretation: 1865\n",
      "Iteretation: 1866\n",
      "Iteretation: 1867\n",
      "Iteretation: 1868\n",
      "Iteretation: 1869\n",
      "Iteretation: 1870\n",
      "Iteretation: 1871\n",
      "Iteretation: 1872\n",
      "Iteretation: 1873\n",
      "Iteretation: 1874\n",
      "Iteretation: 1875\n",
      "Iteretation: 1876\n",
      "Iteretation: 1877\n",
      "Iteretation: 1878\n",
      "Iteretation: 1879\n",
      "Iteretation: 1880\n",
      "Iteretation: 1881\n",
      "Iteretation: 1882\n",
      "Iteretation: 1883\n",
      "Iteretation: 1884\n",
      "Iteretation: 1885\n",
      "Iteretation: 1886\n",
      "Iteretation: 1887\n",
      "Iteretation: 1888\n",
      "Iteretation: 1889\n",
      "Iteretation: 1890\n",
      "Iteretation: 1891\n",
      "Iteretation: 1892\n",
      "Iteretation: 1893\n",
      "Iteretation: 1894\n",
      "Iteretation: 1895\n",
      "Iteretation: 1896\n",
      "Iteretation: 1897\n",
      "Iteretation: 1898\n",
      "Iteretation: 1899\n",
      "Iteretation: 1900\n",
      "Iteretation: 1901\n",
      "Iteretation: 1902\n",
      "Iteretation: 1903\n",
      "Iteretation: 1904\n",
      "Iteretation: 1905\n",
      "Iteretation: 1906\n",
      "Iteretation: 1907\n",
      "Iteretation: 1908\n",
      "Iteretation: 1909\n",
      "Iteretation: 1910\n",
      "Iteretation: 1911\n",
      "Iteretation: 1912\n",
      "Iteretation: 1913\n",
      "Iteretation: 1914\n",
      "Iteretation: 1915\n",
      "Iteretation: 1916\n",
      "Iteretation: 1917\n",
      "Iteretation: 1918\n",
      "Iteretation: 1919\n",
      "Iteretation: 1920\n",
      "Iteretation: 1921\n",
      "Iteretation: 1922\n",
      "Iteretation: 1923\n",
      "Iteretation: 1924\n",
      "Iteretation: 1925\n",
      "Iteretation: 1926\n",
      "Iteretation: 1927\n",
      "Iteretation: 1928\n",
      "Iteretation: 1929\n",
      "Iteretation: 1930\n",
      "Iteretation: 1931\n",
      "Iteretation: 1932\n",
      "Iteretation: 1933\n",
      "Iteretation: 1934\n",
      "Iteretation: 1935\n",
      "Iteretation: 1936\n",
      "Iteretation: 1937\n",
      "Iteretation: 1938\n",
      "Iteretation: 1939\n",
      "Iteretation: 1940\n",
      "Iteretation: 1941\n",
      "Iteretation: 1942\n",
      "Iteretation: 1943\n",
      "Iteretation: 1944\n",
      "Iteretation: 1945\n",
      "Iteretation: 1946\n",
      "Iteretation: 1947\n",
      "Iteretation: 1948\n",
      "Iteretation: 1949\n",
      "Iteretation: 1950\n",
      "Iteretation: 1951\n",
      "Iteretation: 1952\n",
      "Iteretation: 1953\n",
      "Iteretation: 1954\n",
      "Iteretation: 1955\n",
      "Iteretation: 1956\n",
      "Iteretation: 1957\n",
      "Iteretation: 1958\n",
      "Iteretation: 1959\n",
      "Iteretation: 1960\n",
      "Iteretation: 1961\n",
      "Iteretation: 1962\n",
      "Iteretation: 1963\n",
      "Iteretation: 1964\n",
      "Iteretation: 1965\n",
      "Iteretation: 1966\n",
      "Iteretation: 1967\n",
      "Iteretation: 1968\n",
      "Iteretation: 1969\n",
      "Iteretation: 1970\n",
      "Iteretation: 1971\n",
      "Iteretation: 1972\n",
      "Iteretation: 1973\n",
      "Iteretation: 1974\n",
      "Iteretation: 1975\n",
      "Iteretation: 1976\n",
      "Iteretation: 1977\n",
      "Iteretation: 1978\n",
      "Iteretation: 1979\n",
      "Iteretation: 1980\n",
      "Iteretation: 1981\n",
      "Iteretation: 1982\n",
      "Iteretation: 1983\n",
      "Iteretation: 1984\n",
      "Iteretation: 1985\n",
      "Iteretation: 1986\n",
      "Iteretation: 1987\n",
      "Iteretation: 1988\n",
      "Iteretation: 1989\n",
      "Iteretation: 1990\n",
      "Iteretation: 1991\n",
      "Iteretation: 1992\n",
      "Iteretation: 1993\n",
      "Iteretation: 1994\n",
      "Iteretation: 1995\n",
      "Iteretation: 1996\n",
      "Iteretation: 1997\n",
      "Iteretation: 1998\n",
      "Iteretation: 1999\n",
      "            Date  SecuritiesCode  Rank\n",
      "0     2021-12-07            1301   856\n",
      "1     2021-12-07            1332   904\n",
      "2     2021-12-07            1333  1305\n",
      "3     2021-12-07            1375  1138\n",
      "4     2021-12-07            1376   551\n",
      "...          ...             ...   ...\n",
      "1995  2021-12-07            9990  1735\n",
      "1996  2021-12-07            9991  1212\n",
      "1997  2021-12-07            9993   397\n",
      "1998  2021-12-07            9994  1113\n",
      "1999  2021-12-07            9997  1471\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove scalers\n",
    "trained_model = NeuralNetwork(\n",
    "    in_features=TS_IN_FEATURES - 3, \n",
    "    units=UNITS,\n",
    "    out_features=1, \n",
    "    categorical_dim=CAT_FEATURES,\n",
    "    no_embedding=NO_EMBEDDING, \n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    n_blocks=BLOCKS,\n",
    "    n_stacks=STACKS,\n",
    "    dropout=0.1,\n",
    "    pooling_sizes=3\n",
    ")\n",
    "\n",
    "trained_model.load_state_dict(torch.load('/kaggle/working/trained_model.pt'))\n",
    "trained_model.eval()\n",
    "\n",
    "counter = 0\n",
    "for (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n",
    "    sample_prediction_df = pd.DataFrame()\n",
    "    date = np.unique(pd.to_datetime(prices['Date']).dt.strftime('%Y-%m-%d'))[-1]\n",
    "#     prices['Date'] = pd.to_datetime(prices['Date']).dt.strftime('%Y%m%d').astype(int)\n",
    "    df = get_data(root_path=ROOT_PATH, prices=prices)\n",
    "    pred_df = pd.DataFrame()\n",
    "\n",
    "    for count, stock in enumerate(stocks):\n",
    "        try:\n",
    "            print('Iteretation:', count)\n",
    "            scaler = scaler_dict[stock]\n",
    "            test_dataloader, idx = dataloader_test_by_stock(\n",
    "                df, \n",
    "                stock, \n",
    "                transformer=scaler,\n",
    "                batch_size=BATCH_SIZE, \n",
    "                continous_cols=CONT_COLS,\n",
    "                target_col=None\n",
    "            )\n",
    "            pred_list = run_pred_step(test_dataloader, trained_model, x_cat=True)\n",
    "            df_pred = pd.DataFrame({'SecuritiesCode': stock, 'Target': pred_list}, index=[date]) # maybe index should only be idx\n",
    "            df_pred.index.rename('Date', inplace=True)\n",
    "            pred_df = pd.concat([pred_df, df_pred]) \n",
    "        except Exception as e:\n",
    "            print(f'Exception {e}')\n",
    "        \n",
    "    sample_prediction_df = sample_prediction.copy()\n",
    "    pred_df['Rank'] = np.int64(pred_df['Target'].rank(method='first',ascending=False).values - 1)\n",
    "    feature_map = pred_df.set_index('SecuritiesCode')['Rank'].to_dict()\n",
    "    sample_prediction_df['Rank'] = sample_prediction_df['SecuritiesCode'].map(feature_map)\n",
    "    sample_prediction_df.Rank = np.int64(sample_prediction_df.Rank)\n",
    "\n",
    "    assert sample_prediction_df.Rank.nunique() == 2000\n",
    "    assert sample_prediction_df.Rank.notna().all()\n",
    "    assert sample_prediction_df.Rank.min() == 0\n",
    "    assert sample_prediction_df.Rank.max() == len(sample_prediction_df.Rank) - 1\n",
    "    print(sample_prediction_df)\n",
    "\n",
    "    sample_prediction_df.reset_index(inplace=True)\n",
    "\n",
    "    sample_prediction_df = sample_prediction_df[['Date', 'SecuritiesCode', 'Rank']]\n",
    "    env.predict(sample_prediction_df)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab1434a",
   "metadata": {
    "papermill": {
     "duration": 0.811001,
     "end_time": "2022-07-04T15:57:25.639401",
     "exception": false,
     "start_time": "2022-07-04T15:57:24.828400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fce7e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T15:57:27.285441Z",
     "iopub.status.busy": "2022-07-04T15:57:27.284344Z",
     "iopub.status.idle": "2022-07-04T15:57:27.289138Z",
     "shell.execute_reply": "2022-07-04T15:57:27.288254Z",
     "shell.execute_reply.started": "2022-07-04T10:45:14.087064Z"
    },
    "papermill": {
     "duration": 0.830571,
     "end_time": "2022-07-04T15:57:27.289458",
     "exception": false,
     "start_time": "2022-07-04T15:57:26.458887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999, 1999, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_prediction_df.Rank) - 1, sample_prediction_df.Rank.max(), sample_prediction_df.Rank.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deb469a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T15:57:28.949658Z",
     "iopub.status.busy": "2022-07-04T15:57:28.948886Z",
     "iopub.status.idle": "2022-07-04T15:57:28.952699Z",
     "shell.execute_reply": "2022-07-04T15:57:28.952033Z",
     "shell.execute_reply.started": "2022-07-04T10:45:14.09581Z"
    },
    "papermill": {
     "duration": 0.843432,
     "end_time": "2022-07-04T15:57:28.952843",
     "exception": false,
     "start_time": "2022-07-04T15:57:28.109411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999, 1999)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_prediction_df.Rank) - 1, sample_prediction_df.Rank.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d32ec28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T15:57:30.596847Z",
     "iopub.status.busy": "2022-07-04T15:57:30.596131Z",
     "iopub.status.idle": "2022-07-04T15:57:30.600579Z",
     "shell.execute_reply": "2022-07-04T15:57:30.599991Z",
     "shell.execute_reply.started": "2022-07-04T10:45:14.110182Z"
    },
    "papermill": {
     "duration": 0.827902,
     "end_time": "2022-07-04T15:57:30.600726",
     "exception": false,
     "start_time": "2022-07-04T15:57:29.772824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, array([ 856,  904, 1305, ...,  397, 1113, 1471]), 0, 1999)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prediction_df.Rank.nunique(), sample_prediction_df.Rank.unique() ,sample_prediction_df.Rank.min(), sample_prediction_df.Rank.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20563dfc",
   "metadata": {
    "papermill": {
     "duration": 0.841053,
     "end_time": "2022-07-04T15:57:32.270934",
     "exception": false,
     "start_time": "2022-07-04T15:57:31.429881",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17963.202413,
   "end_time": "2022-07-04T15:57:36.772927",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-04T10:58:13.570514",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
